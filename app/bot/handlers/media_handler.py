#!/usr/bin/env python3
# coding: utf-8

"""
Media handlers for video, audio, and image generation.
"""

from aiogram import Router, F
from aiogram.types import CallbackQuery, Message, FSInputFile, BufferedInputFile
from aiogram.fsm.context import FSMContext
import os
from pathlib import Path
from PIL import Image
import io

from app.bot.keyboards.inline import (
    back_to_main_keyboard,
    kling_choice_keyboard,
    nano_banana_keyboard,
    nano_format_keyboard,
    nano_multi_images_keyboard
)
from app.bot.states import MediaState
from app.bot.utils.notifications import (
    format_generation_message,
    create_action_keyboard,
    CONTENT_TYPES,
    MODEL_ACTIONS,
)
from app.database.models.user import User
from app.database.database import async_session_maker
from app.core.logger import get_logger
from app.core.exceptions import InsufficientTokensError
from app.core.cost_guard import cost_guard
from app.core.temp_files import get_temp_file_path, cleanup_temp_file
from app.services.video import VeoService, SoraService, LumaService, HailuoService, KlingService
from app.services.image import DalleService, GeminiImageService, StabilityService, RemoveBgService, NanoBananaService, KlingImageService, RecraftService
from app.services.audio import SunoService, OpenAIAudioService
from app.services.ai.vision_service import VisionService
from app.services.subscription.subscription_service import SubscriptionService

logger = get_logger(__name__)

router = Router(name="media")


# ======================
# UTILITY FUNCTIONS
# ======================

async def cleanup_temp_images(state: FSMContext):
    """Clean up temporary image files from state."""
    data = await state.get_data()
    for key in ["image_path", "reference_image_path"]:
        file_path = data.get(key)
        if file_path:
            cleanup_temp_file(file_path)


def resize_image_if_needed(image_path: str, max_size_mb: float = 2.0, max_dimension: int = 2048) -> str:
    """
    Resize image if it's too large.

    Args:
        image_path: Path to the image file
        max_size_mb: Maximum file size in MB
        max_dimension: Maximum width or height in pixels

    Returns:
        Path to the resized image (same as input if no resize needed)
    """
    try:
        file_size_mb = os.path.getsize(image_path) / (1024 * 1024)

        img = Image.open(image_path)
        needs_resize = False

        # Check if file size is too large
        if file_size_mb > max_size_mb:
            needs_resize = True
            logger.info("image_too_large", size_mb=file_size_mb)

        # Check if dimensions are too large
        if img.width > max_dimension or img.height > max_dimension:
            needs_resize = True
            logger.info("image_dimensions_too_large", width=img.width, height=img.height)

        if not needs_resize:
            return image_path

        # Calculate new dimensions maintaining aspect ratio
        ratio = min(max_dimension / img.width, max_dimension / img.height, 1.0)
        new_width = int(img.width * ratio)
        new_height = int(img.height * ratio)

        # Convert RGBA to RGB if needed
        if img.mode in ("RGBA", "LA", "P"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode == "P":
                img = img.convert("RGBA")
            background.paste(
                img,
                mask=img.split()[-1] if img.mode == "RGBA" else None
            )
            img = background

        # Resize image
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # Save with optimization
        img_resized.save(image_path, "JPEG", quality=85, optimize=True)

        new_size_mb = os.path.getsize(image_path) / (1024 * 1024)
        logger.info(
            "image_resized",
            old_size_mb=file_size_mb,
            new_size_mb=new_size_mb,
            old_dimensions=f"{img.width}x{img.height}",
            new_dimensions=f"{new_width}x{new_height}"
        )

        return image_path

    except Exception as e:
        logger.error("image_resize_failed", error=str(e))
        return image_path


# ======================
# VIDEO SERVICES
# ======================

@router.callback_query(F.data == "bot.veo")
async def start_veo(callback: CallbackQuery, state: FSMContext, user: User):
    # Get user's total tokens
    total_tokens = user.get_total_tokens()
    videos_available = int(total_tokens / 98000) if total_tokens > 0 else 0

    text = (
        "üåä Veo 3.1 ¬∑ –ª—É—á—à–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ\n\n"
        "‚úèÔ∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ–∑–¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ 8 —Å–µ–∫—É–Ω–¥–Ω—ã–µ –≤–∏–¥–µ–æ, –º–æ–∂–µ—Ç –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–∞, "
        "—Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å –≤–∏–¥–µ–æ –∑–≤—É–∫–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–æ–π –∏ —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–∞—à–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è.\n\n"
        "üì∏ –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å 1 —Ñ–æ—Ç–æ —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏ —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ.\n\n"
        "üì∑ 1Ô∏è‚É£:2Ô∏è‚É£ (–Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä / –∑–∞–≤–µ—Ä—à–∞—é—â–∏–π –∫–∞–¥—Ä). –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ –¥–≤–∞ —Ñ–æ—Ç–æ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ "
        "–∏ –ø–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ. –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ.\n\n"
        "#Ô∏è‚É£ –ò–∑—É—á–∏—Ç–µ –≥–∞–π–¥ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ –∏ –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n\n"
        "‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n"
        "–ú–æ–¥–µ–ª—å: Veo 3.1 Fast\n"
        "–§–æ—Ä–º–∞—Ç: 16:9\n"
        "–°–∏–¥: 0\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –≤–∏–¥–µ–æ. –°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: 98 000 —Ç–æ–∫–µ–Ω–æ–≤"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="veo", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.sora")
async def start_sora(callback: CallbackQuery, state: FSMContext, user: User):
    total_tokens = user.get_total_tokens()
    videos_available = int(total_tokens / 43000) if total_tokens > 0 else 0

    text = (
        "‚òÅÔ∏è Sora 2 ¬∑ –≤–∏—Ä—É—Å–Ω—ã–µ —Ä–æ–ª–∏–∫–∏ —Å –æ–∑–≤—É—á–∫–æ–π\n\n"
        "‚úèÔ∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ–∑–¥–∞–µ—Ç –≤–∏–¥–µ–æ –¥–ª–∏–Ω–æ–π –¥–æ 15 —Å–µ–∫—É–Ω–¥, –≤ –∫–æ—Ç–æ—Ä–æ–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–≤—É–∫, "
        "–≤–æ–∑–º–æ–∂–Ω–∞ –æ–∑–≤—É—á–∫–∞ —Å—Ü–µ–Ω –∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–∞–¥—Ä–µ, —Å–º–µ–Ω–∞ –ª–æ–∫–∞—Ü–∏–π –∏ —Ç.–¥.\n\n"
        "üì∏ –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å 1 —Ñ–æ—Ç–æ —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏ —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ.\n\n"
        "‚õîÔ∏è Sora –Ω–µ –º–æ–∂–µ—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å –ª—é–¥–µ–π –Ω–∞ —Ñ–æ—Ç–æ –∏ –¥–µ–ª–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ –∫–∞–¥—Ä–µ. "
        "–û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ñ–æ—Ç–æ –±–µ–∑ –ª—é–¥–µ–π –≤ –∫–∞–¥—Ä–µ.\n\n"
        "‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n"
        "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 10 —Å–µ–∫.\n"
        "–ö–∞—á–µ—Å—Ç–≤–æ: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ\n"
        "–§–æ—Ä–º–∞—Ç: 16:9\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –≤–∏–¥–µ–æ. –°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ (10 —Å–µ–∫—É–Ω–¥): 43 000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "‚ö†Ô∏è –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ."
    )

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.luma")
async def start_luma(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üåô **Luma Dream Machine**\n\n"
        "Luma —Å–æ–∑–¥–∞—ë—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ –ø–æ –≤–∞—à–µ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** –°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: 85 000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Video:** –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ\n"
        "‚Ä¢ **Image-to-Video:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ –ò–õ–ò —Ñ–æ—Ç–æ**"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    # Clear old data when starting fresh session
    await state.update_data(service="luma", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.hailuo")
async def start_hailuo(callback: CallbackQuery, state: FSMContext, user: User):
    total_tokens = user.get_total_tokens()
    videos_available = int(total_tokens / 90000) if total_tokens > 0 else 0

    text = (
        "üé• Hailuo ¬∑ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –Ω–∞ –≤–∞—à–µ–º –≤–∏–¥–µ–æ. "
        "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚îî –û–Ω–∞ —Å–ª–æ–≤–Ω–æ —Å–æ—à–ª–∞ —Å –∫–∏—Å—Ç–∏ –í–µ—Ä–º–µ–µ—Ä–∞, –µ–µ –∂–µ–º—á—É–∂–Ω–∞—è —Å–µ—Ä—å–≥–∞ –ø–æ–±–ª–µ—Å–∫–∏–≤–∞–µ—Ç. "
        "–≠—Ç–∏ –∑–∞–≥–∞–¥–æ—á–Ω—ã–µ –≥–ª–∞–∑–∞ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Ö–æ–ª—Å—Ç–∞, –≥—É–±—ã –∏–∑–≥–∏–±–∞—é—Ç—Å—è –≤ —Ç–æ–Ω–∫–æ–π, —ç–ª–µ–≥–∞–Ω—Ç–Ω–æ–π —É–ª—ã–±–∫–µ, –æ–±—Ä–∞—â–µ–Ω–Ω–æ–π –∫–æ –º–Ω–µ.\n"
        "‚îî –°–∏–Ω–µ–µ –ø–ª—é—à–µ–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –ø–æ–º–µ—à–∏–≤–∞–µ—Ç —Å—É–ø –≤ –∫–∞—Å—Ç—Ä—é–ª–µ, –æ—Ç –∫–æ—Ç–æ—Ä–æ–≥–æ –∏–¥–µ—Ç –ø–∞—Ä, "
        "–ø–æ—Å–ª–µ —á–µ–≥–æ —Ç–∞—Ä–µ–ª–∫–∞ —Å—É–ø–∞ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –ª—ë–¥, –∞ —Å–∏–Ω–µ–µ –ø–ª—é—à–µ–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–æ —É–¥–∏–≤–ª—è–µ—Ç—Å—è —ç—Ç–æ–º—É.\n\n"
        "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\n"
        "–í–µ—Ä—Å–∏—è: t2v-01\n"
        "–ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥: –≤–∫–ª—é—á–µ–Ω\n\n"
        "üìù –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –≤—ã –º–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–Ω—Ä–∞–≤–∏–≤—à—É—é—Å—è "
        "–∏–ª–∏ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–æ—Ç–æ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ —è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–º–µ–Ω—é –º–æ–¥–µ–ª—å –Ω–∞ t2v-01-director.\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –∑–∞–ø—Ä–æ—Å–æ–≤. 1 –∑–∞–ø—Ä–æ—Å = 90,000 —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="hailuo", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.kling_effects")
async def start_kling_effects(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Kling Effects\n\n"
        "–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏ –æ—Ç Kling AI.\n\n"
        "–°—Ç–æ–∏–º–æ—Å—Ç—å: ~10,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –≤–∏–¥–µ–æ\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å —ç—Ñ—Ñ–µ–∫—Ç–æ–º."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    # Clear old data when starting fresh session
    await state.update_data(service="kling_effects", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# Handler for when user clicks "Kling" from main menu - show choice
@router.callback_query(F.data == "bot.kling_main")
async def start_kling_choice(callback: CallbackQuery, state: FSMContext, user: User):
    """Show Kling AI choice menu (photo or video)."""
    text = (
        "üéû **Kling AI**\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n\n"
        "üåÑ **–°–æ–∑–¥–∞—Ç—å —Ñ–æ—Ç–æ** - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
        "üé¨ **–°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ** - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ\n\n"
        "Kling AI —Å–æ–∑–¥–∞—ë—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –ø–æ–º–æ—â—å—é –ø–µ—Ä–µ–¥–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤."
    )

    await state.clear()  # Clear any previous state
    await callback.message.answer(text, reply_markup=kling_choice_keyboard())
    await callback.answer()


# Handler for Kling Image generation
@router.callback_query(F.data == "bot.kling_image")
async def start_kling_image(callback: CallbackQuery, state: FSMContext, user: User):
    """Start Kling image generation - currently under development."""
    text = (
        "üéû **Kling AI - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "‚ö†Ô∏è **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ**\n\n"
        "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Kling Image –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.\n"
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n\n"
        "‚Ä¢ üçå Nano Banana (Gemini 2.5 Flash)\n"
        "‚Ä¢ üçå‚ú® Banana PRO (Gemini 3 Pro)\n"
        "‚Ä¢ üñº DALL¬∑E 3\n\n"
        "–°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏!"
    )

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("‚ö†Ô∏è –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ", show_alert=False)


# Handler for Kling Video generation (renamed from bot.kling)
@router.callback_query(F.data == "bot.kling_video")
async def start_kling_video(callback: CallbackQuery, state: FSMContext, user: User):
    """Start Kling video generation."""
    total_tokens = user.get_total_tokens()
    videos_available = int(total_tokens / 80000) if total_tokens > 0 else 0

    text = (
        "üéû Kling ¬∑ –º–µ–Ω—è–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –Ω–∞ –≤–∞—à–µ–º –≤–∏–¥–µ–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚îî –û–∂–∏–≤–∏ –º–æ—ë —Ñ–æ—Ç–æ –∏ —Å–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã —è —É–ª—ã–±–∞–ª—Å—è –∏ –º–∞—Ö–∞–ª —Ä—É–∫–æ–π –≤ –∫–∞–º–µ—Ä—É. (–ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–≤–æ—ë —Ñ–æ—Ç–æ –∏–ª–∏ —Ñ–æ—Ç–æ –±–ª–∏–∑–∫–æ–≥–æ).\n"
        "‚îî –ù–µ–æ–Ω–æ–≤–æ–µ –∏–∞–π–¥–∑—é—Ü—É: –∫–∏–±–µ—Ä–ø–∞–Ω–∫-—Å–∞–º—É—Ä–∞–π –≤ –¥–µ–π—Å—Ç–≤–∏–∏. (–ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–≤–æ—ë —Ñ–æ—Ç–æ).\n\n"
        "üì∑ –í—ã –≤—ã–±—Ä–∞–ª–∏ –≤–µ—Ä—Å–∏—é 2.5 Turbo: —ç—Ç–∞ –≤–µ—Ä—Å–∏—è –º–æ–∂–µ—Ç –ø—Ä–∏–Ω—è—Ç—å –¥–æ –¥–≤—É—Ö —Ñ–æ—Ç–æ —Å –ø—Ä–æ–º–ø—Ç–æ–º –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ. "
        "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä / –∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä.\n\n"
        "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\n"
        "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 5 —Å–µ–∫—É–Ω–¥\n"
        "–§–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ: 1:1\n"
        "–í–µ—Ä—Å–∏—è: 2.5\n"
        "–ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥: –≤–∫–ª—é—á–µ–Ω\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –∑–∞–ø—Ä–æ—Å–æ–≤. 1 –∑–∞–ø—Ä–æ—Å = 80,000.0 —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="kling", image_path=None, photo_caption_prompt=None)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# IMAGE GENERATION
# ======================

@router.callback_query(F.data == "bot.gpt_image")
async def start_gpt_image(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "**GPT Image (DALL-E 3)**\n\n"
        "–°–æ–∑–¥–∞–π—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n\n"
        "üìä **–ú–æ–¥–µ–ª–∏:**\n"
        "‚Ä¢ DALL-E 3 (HD –∫–∞—á–µ—Å—Ç–≤–æ)\n"
        "‚Ä¢ DALL-E 3 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)\n"
        "‚Ä¢ DALL-E 2\n\n"
        "**–†–∞–∑–º–µ—Ä—ã:** 1024x1024, 1792x1024, 1024x1792\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: 8 500 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ**\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Image Variation (DALL-E 2):** –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–π\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ**"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="dalle", reference_image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.nano")
async def start_nano(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "üçå **Nano Banana (Gemini 2.5 Flash Image)**\n\n"
        "Gemini 2.5 Flash Image —Å–æ–∑–¥–∞—ë—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n\n"
        "üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: 1:1, 16:9, 9:16, 3:4, 4:3\n"
        "‚Ä¢ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~3,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Image-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ **–æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ** + –æ–ø–∏—Å–∞–Ω–∏–µ\n"
        "‚Ä¢ **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –ö–Ω–æ–ø–∫–∞ \"üé® –°–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\" (2-10 —à—Ç.)\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)**\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã text-to-image:**\n"
        "‚Ä¢ \"–ö–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ —Å—Ä–µ–¥–∏ –∑–≤—ë–∑–¥\"\n"
        "‚Ä¢ \"–ó–∞–∫–∞—Ç –Ω–∞ –±–µ—Ä–µ–≥—É –æ–∫–µ–∞–Ω–∞ —Å –ø–∞–ª—å–º–∞–º–∏\"\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã image-to-image:**\n"
        "‚Ä¢ –§–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–Ω–∏–º–µ —Å—Ç–∏–ª—å —Å —è—Ä–∫–∏–º–∏ –∫—Ä–∞—Å–∫–∞–º–∏\"\n"
        "‚Ä¢ –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ + \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –º–∞—Å–ª—è–Ω–æ–π –∂–∏–≤–æ–ø–∏—Å–∏ –í–∞–Ω –ì–æ–≥–∞\"\n"
        "‚Ä¢ –§–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ —Ñ—ç–Ω—Ç–µ–∑–∏ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é —Å –º–∞–≥–∏—á–µ—Å–∫–∏–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)

    # Get existing data or set defaults
    data = await state.get_data()
    current_ratio = data.get("nano_aspect_ratio", "auto")

    await state.update_data(
        service="nano_banana",
        nano_is_pro=False,
        reference_image_path=None,
        reference_image_paths=[],
        photo_caption_prompt=None,
        multi_images_count=0,
        nano_aspect_ratio=current_ratio  # Preserve existing format or set default
    )

    await callback.message.answer(text, reply_markup=nano_banana_keyboard(is_pro=False), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.nano_pro")
async def start_nano_pro(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "üçå‚ú® **Banana PRO (Gemini 3 Pro Image)**\n\n"
        "Gemini 3 Pro Image - —ç—Ç–æ –Ω–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n\n"
        "üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: 1:1, 16:9, 9:16, 4:3, 3:4 –∏ –¥—Ä—É–≥–∏–µ\n"
        "‚Ä¢ –†–∞–∑–º–µ—Ä—ã: 2K, 4K\n"
        "‚Ä¢ –í—ã—Å–æ—á–∞–π—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
        "‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~3,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Image-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ **–æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ** + –æ–ø–∏—Å–∞–Ω–∏–µ\n"
        "‚Ä¢ **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –ö–Ω–æ–ø–∫–∞ \"üé® –°–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\" (2-10 —à—Ç.)\n"
        "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Google Search –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)**\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ò–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞ –æ —Ç–µ–∫—É—â–µ–π –ø–æ–≥–æ–¥–µ –≤ –¢–æ–∫–∏–æ\"\n"
        "‚Ä¢ \"–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –∫–æ—Ç–∞ –≤ –∫–æ—Å–º–æ—Å–µ –≤ 4K\"\n"
        "‚Ä¢ –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)

    # Get existing data or set defaults
    data = await state.get_data()
    current_ratio = data.get("nano_aspect_ratio", "auto")

    await state.update_data(
        service="nano_banana",
        nano_is_pro=True,
        reference_image_path=None,
        reference_image_paths=[],
        photo_caption_prompt=None,
        multi_images_count=0,
        nano_aspect_ratio=current_ratio  # Preserve existing format or set default
    )

    await callback.message.answer(text, reply_markup=nano_banana_keyboard(is_pro=True), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.midjourney")
async def start_midjourney(callback: CallbackQuery):
    """Midjourney stub - under development."""
    text = (
        "üåÜ **Midjourney**\n\n"
        "‚ö†Ô∏è **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ**\n\n"
        "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Midjourney –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.\n"
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n\n"
        "‚Ä¢ üçå Nano Banana (Gemini 2.5 Flash)\n"
        "‚Ä¢ üñº DALL¬∑E 3\n\n"
        "–°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏!"
    )
    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("‚ö†Ô∏è –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ", show_alert=False)


@router.callback_query(F.data == "bot_stable_diffusion")
async def start_stable_diffusion(callback: CallbackQuery):
    """Stable Diffusion stub - under development."""
    text = (
        "üñå **Stable Diffusion**\n\n"
        "‚ö†Ô∏è **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ**\n\n"
        "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Stable Diffusion –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.\n"
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n\n"
        "‚Ä¢ üçå Nano Banana (Gemini 2.5 Flash)\n"
        "‚Ä¢ üñº DALL¬∑E 3\n\n"
        "–°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏!"
    )
    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("‚ö†Ô∏è –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ", show_alert=False)


@router.callback_query(F.data == "bot.recraft")
async def start_recraft(callback: CallbackQuery, state: FSMContext, user: User):
    """Recraft AI image generation."""
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "üé® **Recraft AI - Image Generation**\n\n"
        "Recraft —Å–æ–∑–¥–∞—ë—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö.\n\n"
        "üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "‚Ä¢ –ú–æ–¥–µ–ª—å: Recraft V2 (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ)\n"
        "‚Ä¢ –°—Ç–∏–ª–∏: —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ, –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏, –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –≥—Ä–∞—Ñ–∏–∫–∞, –∏–∫–æ–Ω–∫–∏\n"
        "‚Ä¢ –†–∞–∑–º–µ—Ä—ã: 1024x1024 –∏ –¥—Ä—É–≥–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~2,200 —Ç–æ–∫–µ–Ω–æ–≤ (–¥–µ—à–µ–≤–ª–µ DALL-E 3)\n\n"
        "üé® **–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–∏–ª–∏:**\n"
        "‚Ä¢ **Realistic Image** (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) - —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Digital Illustration** - —Ü–∏—Ñ—Ä–æ–≤—ã–µ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏\n"
        "‚Ä¢ **Vector Illustration** - –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –≥—Ä–∞—Ñ–∏–∫–∞\n"
        "‚Ä¢ **Icon** - –∏–∫–æ–Ω–∫–∏ –∏ —Å–∏–º–≤–æ–ª—ã\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è**\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –∫–æ—Ç–∞ –≤ –∫–æ—Å–º–æ—Å–µ\"\n"
        "‚Ä¢ \"–¶–∏—Ñ—Ä–æ–≤–∞—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è –¥—Ä–∞–∫–æ–Ω–∞ –≤ —Å—Ç–∏–ª–µ —Ñ—ç–Ω—Ç–µ–∑–∏\"\n"
        "‚Ä¢ \"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –∏–∫–æ–Ω–∫–∞ –¥–æ–º–∞ –≤ –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–æ–º —Å—Ç–∏–ª–µ\"\n"
        "‚Ä¢ \"–ó–∞–∫–∞—Ç –Ω–∞ –±–µ—Ä–µ–≥—É –æ–∫–µ–∞–Ω–∞ —Å –ø–∞–ª—å–º–∞–º–∏\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="recraft", reference_image_path=None, photo_caption_prompt=None)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


# ======================
# AUDIO SERVICES
# ======================

# Note: Suno handler moved to suno_handler.py for better organization and step-by-step creation


@router.callback_query(F.data == "bot.whisper")
async def start_whisper(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üéô **Whisper - –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–∞**\n\n"
        "OpenAI Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –µ—ë –≤ —Ç–µ–∫—Å—Ç.\n\n"
        "üìä **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        "‚Ä¢ –¢–æ—á–Ω–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö\n"
        "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤\n"
        "‚Ä¢ –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~1,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ\n\n"
        "üéµ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ**"
    )

    await state.set_state(MediaState.waiting_for_whisper_audio)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.whisper_tts")
async def start_tts(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üó£ **OpenAI TTS ‚Äì Text to Speech**\n\n"
        "–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ—á—å.\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~200 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å\n\n"
        "üé§ **–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞:**\n"
        "‚Ä¢ alloy - –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ echo - –ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ fable - –ë—Ä–∏—Ç–∞–Ω—Å–∫–∏–π –∞–∫—Ü–µ–Ω—Ç\n"
        "‚Ä¢ onyx - –ì–ª—É–±–æ–∫–∏–π –º—É–∂—Å–∫–æ–π\n"
        "‚Ä¢ nova - –ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ shimmer - –ú—è–≥–∫–∏–π –∂–µ–Ω—Å–∫–∏–π\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏**"
    )

    await state.set_state(MediaState.waiting_for_audio_prompt)
    await state.update_data(service="tts")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.gpt_vision")
async def start_gpt_vision(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üëÅ **GPT Image 1 - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "GPT-4 Vision –º–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∏—Ö.\n\n"
        "üìä **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        "‚Ä¢ –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
        "‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞\n"
        "‚Ä¢ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n"
        "‚Ä¢ –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~1,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å\n\n"
        "üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞**"
    )

    await state.set_state(MediaState.waiting_for_vision_image)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# IMAGE PROCESSING
# ======================

@router.callback_query(F.data == "bot.pi_upscale")
async def start_upscale(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ\n\n"
        "–£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏ —É–ª—É—á—à–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "–°—Ç–æ–∏–º–æ—Å—Ç—å: ~2,000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
    )

    await state.set_state(MediaState.waiting_for_upscale_image)
    await state.update_data(service="upscale")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_remb")
async def start_remove_bg(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞\n\n"
        "–°—Ç–æ–∏–º–æ—Å—Ç—å: ~500 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞."
    )

    await state.set_state(MediaState.waiting_for_image)
    await state.update_data(service="remove_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_repb")
async def start_replace_bg(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "üñº **–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash Image)**\n\n"
        "–£–º–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ —Å –ø–æ–º–æ—â—å—é –ò–ò Gemini.\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~2,000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "üìù **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ\n"
        "2. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–æ–Ω–∞\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ë–µ–ª—ã–π —Ñ–æ–Ω\"\n"
        "‚Ä¢ \"–ü–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏ –Ω–∞ –∑–∞–∫–∞—Ç–µ\"\n"
        "‚Ä¢ \"–ì–æ—Ä–æ–¥—Å–∫–∞—è —É–ª–∏—Ü–∞ –Ω–æ—á—å—é\"\n"
        "‚Ä¢ \"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç –æ—Ç —Å–∏–Ω–µ–≥–æ –∫ —Ñ–∏–æ–ª–µ—Ç–æ–≤–æ–º—É\"\n\n"
        "üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞**"
    )

    await state.set_state(MediaState.waiting_for_replace_bg_image)
    await state.update_data(service="replace_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


# ======================
# FSM HANDLERS - VIDEO
# ======================

@router.message(MediaState.waiting_for_video_prompt, F.photo)
async def process_video_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-video generation."""
    data = await state.get_data()
    service_name = data.get("service", "veo")

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º TempFileManager –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
    # –≤–º–µ—Å—Ç–æ file_id –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
    temp_path = get_temp_file_path(prefix="video_input", suffix=".jpg", user_id=user.id)

    await message.bot.download_file(file.file_path, temp_path)

    # Save absolute image path to state
    await state.update_data(image_path=str(temp_path))

    # Check if photo has caption (description)
    if message.caption and message.caption.strip():
        # User sent photo with description - process immediately
        # Save caption as prompt in state
        await state.update_data(photo_caption_prompt=message.caption.strip())

        # Route to appropriate video service
        if service_name == "veo":
            await process_veo_video(message, user, state)
        elif service_name == "sora":
            await process_sora_video(message, user, state)
        elif service_name == "luma":
            await process_luma_video(message, user, state)
        elif service_name == "hailuo":
            await process_hailuo_video(message, user, state)
        elif service_name == "kling":
            await process_kling_video(message, user, state)
        elif service_name == "kling_effects":
            await process_kling_effects(message, user, state)
    else:
        # No caption - ask for description
        await message.answer(
            "‚úÖ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
            "üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
            "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
            "‚Ä¢ \"–û–∂–∏–≤–∏ —ç—Ç–æ —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤—å –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ\"\n"
            "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã –≤–æ–ª–æ—Å—ã —Ä–∞–∑–≤–µ–≤–∞–ª–∏—Å—å –Ω–∞ –≤–µ—Ç—Ä—É\"\n"
            "‚Ä¢ \"–î–æ–±–∞–≤—å –ø–∞–¥–∞—é—â–∏–µ —Å–Ω–µ–∂–∏–Ω–∫–∏ –∏ –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã\""
        )


@router.message(MediaState.waiting_for_video_prompt, F.text)
async def process_video_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    # Commands should NOT be processed as prompts
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    # Check message length (max 2000 characters)
    if message.text and len(message.text) > 2000:
        await message.answer(
            "‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 2000 —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    data = await state.get_data()
    service_name = data.get("service", "sora")

    display_names = {
        "veo": "Veo 3.1",
        "sora": "Sora 2",
        "luma": "Luma Dream Machine",
        "hailuo": "Hailuo",
        "kling": "Kling AI",
        "kling_effects": "Kling Effects"
    }
    display = display_names.get(service_name, service_name)

    # Route to appropriate video service
    if service_name == "veo":
        await process_veo_video(message, user, state)
    elif service_name == "sora":
        await process_sora_video(message, user, state)
    elif service_name == "luma":
        await process_luma_video(message, user, state)
    elif service_name == "hailuo":
        await process_hailuo_video(message, user, state)
    elif service_name == "kling" or service_name == "kling_effects":
        await process_kling_video(message, user, state, is_effects=(service_name == "kling_effects"))
    else:
        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


async def process_veo_video(message: Message, user: User, state: FSMContext):
    """Process Veo video generation with cost-guard protection."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    # COST-GUARD: –æ—Ü–µ–Ω–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å —ç–∫–æ–Ω–æ–º-—Ä–µ–∂–∏–º–æ–º (4 —Å–µ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å duration, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –º–∏–Ω–∏–º—É–º
    duration = data.get("duration", None)  # None = –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω default –∏–∑ cost_guard
    cost_estimate = cost_guard.estimate_cost("veo-3.1", duration=duration)

    # COST-GUARD: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å rate limit
    allowed, rate_error = await cost_guard.check_rate_limit(user.id, "veo-3.1")
    if not allowed:
        # Clean up image if exists
        cleanup_temp_file(image_path)
        await message.answer(rate_error)
        await state.clear()
        return

    estimated_tokens = cost_estimate.estimated_tokens
    actual_duration = cost_estimate.duration_seconds

    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    cost_warning = (
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Veo 3.1:**\n\n"
        f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {actual_duration} —Å–µ–∫\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ~{estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤ (‚âà${cost_estimate.estimated_cost_usd:.2f})\n\n"
    )

    if cost_estimate.warning_message:
        cost_warning += f"{cost_estimate.warning_message}\n\n"

    # COST-GUARD: —Ç—Ä–µ–±–æ–≤–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è –¥–æ—Ä–æ–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if cost_estimate.requires_confirmation:
        # TODO: –í –±—É–¥—É—â–µ–º –¥–æ–±–∞–≤–∏—Ç—å inline –∫–Ω–æ–ø–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        cost_warning += "‚ö†Ô∏è –≠—Ç–æ –¥–æ—Ä–æ–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è! –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø—Ä–æ–º–ø—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.\n\n"

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            cleanup_temp_file(image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ!\n\n"
                f"{cost_warning}"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send improved progress message with cost info
    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(
        f"üé¨ –°–æ–∑–¥–∞—é –≤–∏–¥–µ–æ –≤ Veo 3.1 ({mode_text})...\n\n"
        f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {actual_duration} —Å–µ–∫\n"
        f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: ~{estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        f"‚è± –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~2-10 –º–∏–Ω—É—Ç.\n"
        f"‚ö°Ô∏è –û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–µ—Ä–≤–∏—Å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –ø–æ—è–≤–∏—Ç—å—Å—è –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ."
    )

    # Create service
    veo_service = VeoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º actual_duration –∏–∑ cost_estimate (—ç–∫–æ–Ω–æ–º-—Ä–µ–∂–∏–º)
    # Generate video
    result = await veo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress,
        duration=actual_duration,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º duration –∏–∑ cost_guard
        aspect_ratio="16:9",
        resolution="720p",
        image_path=image_path
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        mode_info = "image-to-video" if image_path else "text-to-video"
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Veo 3.1",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_info
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["veo"]["text"],
            action_callback=MODEL_ACTIONS["veo"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )

        # Clean up
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        cleanup_temp_file(image_path)

        # COST-GUARD: –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        await cost_guard.log_generation(
            user_id=user.id,
            model="veo-3.1",
            prompt=prompt,
            estimated_tokens=estimated_tokens,
            actual_tokens=result.tokens_used,
            estimated_cost_usd=cost_estimate.estimated_cost_usd,
            actual_cost_usd=(result.tokens_used / 1000) * 0.01,
            duration_seconds=actual_duration,
            status="success",
            mode=mode_info
        )

        await progress_msg.delete()

        # Clear image_path from state but keep service to allow new generation
        await state.update_data(image_path=None, photo_caption_prompt=None)
    else:
        # Clean up input image if exists
        cleanup_temp_file(image_path)

        # COST-GUARD: –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É
        await cost_guard.log_generation(
            user_id=user.id,
            model="veo-3.1",
            prompt=prompt,
            estimated_tokens=estimated_tokens,
            actual_tokens=0,
            estimated_cost_usd=cost_estimate.estimated_cost_usd,
            actual_cost_usd=0.0,
            duration_seconds=actual_duration,
            status="error",
            error=result.error
        )

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

        # Clear image_path from state but keep service to allow retry
        await state.update_data(image_path=None, photo_caption_prompt=None)


async def process_sora_video(message: Message, user: User, state: FSMContext):
    """Process Sora 2 video generation."""
    # Get state data
    data = await state.get_data()
    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    estimated_tokens = 15000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–¥–µ–æ...")
    sora_service = SoraService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await sora_service.generate_video(
        prompt=prompt,
        model="sora-2",
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Sora 2",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["sora"]["text"],
            action_callback=MODEL_ACTIONS["sora"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))
        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_luma_video(message: Message, user: User, state: FSMContext):
    """Process Luma Dream Machine video generation."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    estimated_tokens = 8000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path:
                cleanup_temp_file(image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Luma Dream Machine ({mode_text})...")
    luma_service = LumaService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Prepare keyframes if image provided
    # NOTE: Luma API —Ç—Ä–µ–±—É–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    # "You should upload and use your own cdn image urls, currently this is the only way to pass an image"
    # –î–ª—è —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º—ã –æ—Ç–∫–ª—é—á–∞–µ–º image-to-video –¥–ª—è Luma
    if image_path:
        # Clean up
        cleanup_temp_file(image_path)
        await progress_msg.edit_text(
            "‚ö†Ô∏è **Image-to-Video –¥–ª—è Luma –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
            "Luma API —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ CDN —Å–µ—Ä–≤–µ—Ä, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ text-to-video —Ä–µ–∂–∏–º –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n"
            "‚Ä¢ üåä Veo 3.1 (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)\n"
            "‚Ä¢ üé• Hailuo (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)",
            parse_mode="Markdown"
        )
        await state.clear()
        return

    # Text-to-video mode (no keyframes needed)
    result = await luma_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        mode_info = "image-to-video" if image_path else "text-to-video"
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Luma Dream Machine",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_info
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["luma"]["text"],
            action_callback=MODEL_ACTIONS["luma"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_hailuo_video(message: Message, user: User, state: FSMContext):
    """Process Hailuo (MiniMax) video generation."""
    # Get state data
    data = await state.get_data()
    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    estimated_tokens = 7000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Hailuo AI...")
    hailuo_service = HailuoService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await hailuo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Hailuo AI",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["hailuo"]["text"],
            action_callback=MODEL_ACTIONS["hailuo"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))
        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_kling_video(message: Message, user: User, state: FSMContext, is_effects: bool = False):
    """Process Kling AI video generation."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    estimated_tokens = 10000 if is_effects else 9000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path:
                cleanup_temp_file(image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    service_name = "Kling Effects" if is_effects else "Kling AI"
    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è {service_name} ({mode_text})...")
    kling_service = KlingService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # For Kling, we would need to upload the image first or provide URL
    # For simplicity, we'll pass image_path and let service handle upload if needed
    kwargs = {}
    if image_path:
        # Note: Kling API expects image_url, so service needs to handle upload
        # For now, we'll pass the local path as image_url parameter
        kwargs["image_url"] = image_path

    result = await kling_service.generate_video(
        prompt=prompt,
        model="kling-v1.6-pro",
        progress_callback=update_progress,
        **kwargs
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        mode_info = "image-to-video" if image_path else "text-to-video"
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name=service_name,  # "Kling AI" or "Kling Effects"
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_info
        )

        # Create action keyboard
        callback_key = "kling_effects" if is_effects else "kling"
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS[callback_key]["text"],
            action_callback=MODEL_ACTIONS[callback_key]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE GENERATION
# ======================

@router.message(MediaState.waiting_for_image_prompt, F.photo)
async def process_image_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-image generation (supports multiple photos for multi-image generation)."""
    data = await state.get_data()
    service_name = data.get("service", "nano_banana")
    multi_images_count = data.get("multi_images_count", 0)

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="image_input", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Resize image if needed (before sending to API)
    resize_image_if_needed(str(temp_path), max_size_mb=2.0, max_dimension=2048)

    # Check if we're in multi-image mode
    if multi_images_count > 0:
        # Multi-image mode: add photo to list
        reference_image_paths = data.get("reference_image_paths", [])
        reference_image_paths.append(str(temp_path))
        await state.update_data(reference_image_paths=reference_image_paths)

        photos_count = len(reference_image_paths)
        service_display = {
            "nano_banana": "Nano Banana",
            "dalle": "DALL-E"
        }.get(service_name, service_name)

        # Check if photo has caption (description) - if yes, process immediately
        if message.caption and message.caption.strip():
            await state.update_data(photo_caption_prompt=message.caption.strip())

            # Route to appropriate image service
            if service_name == "nano_banana":
                await process_nano_image(message, user, state)
            elif service_name == "dalle":
                await process_dalle_image(message, user, state)
        else:
            # No caption - show status and ask for more photos or prompt
            await message.answer(
                f"‚úÖ –§–æ—Ç–æ {photos_count} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
                f"üì∏ –í—ã –º–æ–∂–µ—Ç–µ:\n"
                f"‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë —Ñ–æ—Ç–æ (–≤—Å–µ–≥–æ: {photos_count}/{multi_images_count}+)\n"
                f"‚Ä¢ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è {service_display}:**\n"
                "‚Ä¢ \"–°–æ–∑–¥–∞–π –ø–æ—Ä—Ç—Ä–µ—Ç –∫–∞–∂–¥–æ–≥–æ –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —ç—Ç–æ–π —Å—Ü–µ–Ω—ã\"\n"
                "‚Ä¢ \"–ü—Ä–∏–º–µ–Ω–∏ —ç—Ç–æ—Ç —Å—Ç–∏–ª—å –∫ –∫–∞–∂–¥–æ–º—É —Ñ–æ—Ç–æ\""
            )
    else:
        # Single-image mode (backward compatibility)
        # Clean up old reference image if exists
        old_reference_path = data.get("reference_image_path")
        if old_reference_path:
            cleanup_temp_file(old_reference_path)

        # Save NEW image path to state
        await state.update_data(reference_image_path=str(temp_path))

        service_display = {
            "nano_banana": "Nano Banana",
            "dalle": "DALL-E"
        }.get(service_name, service_name)

        # Check if photo has caption (description)
        if message.caption and message.caption.strip():
            # User sent photo with description - process immediately
            # Save caption as prompt in state
            await state.update_data(photo_caption_prompt=message.caption.strip())

            # Route to appropriate image service
            if service_name == "dalle":
                await process_dalle_image(message, user, state)
            elif service_name == "gemini_image":
                await process_gemini_image(message, user, state)
            elif service_name == "nano_banana":
                await process_nano_image(message, user, state)
        else:
            # No caption - ask for description
            await message.answer(
                f"‚úÖ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
                f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è {service_display}:**\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n"
                "‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–∫–≤–∞—Ä–µ–ª—å–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫\"\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ñ–æ–Ω –∫–æ—Å–º–∏—á–µ—Å–∫–∏–º\"\n"
                "‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ —Å—Ç–∏–ª—å –í–∞–Ω –ì–æ–≥–∞\""
            )


@router.message(MediaState.waiting_for_image_prompt, F.text)
async def process_image_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    # Check message length (max 2000 characters)
    if message.text and len(message.text) > 2000:
        await message.answer(
            "‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 2000 —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    data = await state.get_data()
    service_name = data.get("service", "dalle")

    if service_name == "dalle":
        await process_dalle_image(message, user, state)
    elif service_name == "gemini_image":
        await process_gemini_image(message, user, state)
    elif service_name == "nano_banana":
        await process_nano_image(message, user, state)
    elif service_name == "kling_image":
        await process_kling_image(message, user, state)
    elif service_name == "recraft":
        await process_recraft_image(message, user, state)
    else:
        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


async def process_dalle_image(message: Message, user: User, state: FSMContext):
    """Process DALL-E image generation or variation."""
    # Get state data (check if reference image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)

    # Check and use tokens
    estimated_tokens = 2000 if reference_image_path else 4000  # Variations are cheaper

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up reference image if exists
            if reference_image_path:
                cleanup_temp_file(reference_image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Create service
    dalle_service = DalleService()

    # Determine operation mode
    if reference_image_path:
        # Image variation mode (DALL-E 2 only)
        progress_msg = await message.answer("üé® –°–æ–∑–¥–∞—é –≤–∞—Ä–∏–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å DALL-E 2...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Create variation
        result = await dalle_service.create_variation(
            image_path=reference_image_path,
            progress_callback=update_progress,
            model="dall-e-2",
            size="1024x1024"
        )
    else:
        # Text-to-image mode
        progress_msg = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å DALL-E 3...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Generate image
        result = await dalle_service.generate_image(
            prompt=prompt,
            progress_callback=update_progress,
            model="dall-e-3",
            size="1024x1024",
            quality="standard",
            style="vivid"
        )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Build caption in unified format
        image_type = "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ" if not reference_image_path else "–≤–∞—Ä–∏–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        model_name = "DALL¬∑E 3" if not reference_image_path else "DALL¬∑E 2"

        caption_text = format_generation_message(
            content_type=image_type,
            model_name=model_name,
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["gpt_image"]["text"],
            action_callback=MODEL_ACTIONS["gpt_image"]["callback"],
            file_path=result.image_path,
            file_type="image"
        )

        # Send image
        image_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=image_file,
            caption=caption_text,
            reply_markup=builder.as_markup()
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        # Clean up reference image if exists
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        await progress_msg.delete()
    else:
        # Clean up reference image if exists
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    # Clear state after generation (success or failure)
    await state.clear()


async def process_gemini_image(message: Message, user: User, state: FSMContext):
    """Process Gemini/Imagen image generation."""
    # Get state data
    data = await state.get_data()
    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text

    # Check and use tokens
    estimated_tokens = 3000  # Imagen 3

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Create service
    gemini_service = GeminiImageService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await gemini_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        aspect_ratio="1:1"
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Send image
        image_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=image_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!\n\n"
                    f"–ü—Ä–æ–º–ø—Ç: {prompt[:200]}\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used:,}"
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_nano_image(message: Message, user: User, state: FSMContext):
    """Process Nano Banana (Gemini 2.5 Flash Image or Gemini 3 Pro Image) image generation.

    Supports both single and multiple image generation modes.
    """
    data = await state.get_data()

    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)
    reference_image_paths = data.get("reference_image_paths", [])
    multi_images_count = data.get("multi_images_count", 0)
    nano_is_pro = data.get("nano_is_pro", False)
    aspect_ratio = data.get("nano_aspect_ratio", "auto")

    # Select model based on PRO flag
    model = "gemini-3-pro-image-preview" if nano_is_pro else "gemini-2.5-flash-image"

    # Determine generation count
    if multi_images_count > 0:
        # Multi-image mode
        images_to_generate = multi_images_count
    else:
        # Single-image mode (backward compatibility)
        images_to_generate = 1

    # Calculate cost
    cost_per_image = 3000  # Nano Banana cost per image
    estimated_tokens = cost_per_image * images_to_generate

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Cleanup any reference images
            if reference_image_path:
                cleanup_temp_file(reference_image_path)
            for ref_path in reference_image_paths:
                cleanup_temp_file(ref_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤ ({images_to_generate} √ó {cost_per_image:,})\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    model_display = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"

    if images_to_generate > 1:
        # Multi-image mode
        progress_msg = await message.answer(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é {images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å {model_display}...\n"
            f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ..."
        )
    else:
        # Single-image mode
        mode_text = "image-to-image" if (reference_image_path or reference_image_paths) else "text-to-image"
        progress_msg = await message.answer(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å {model_display} ({mode_text})..."
        )

    nano_service = NanoBananaService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate images
    if images_to_generate > 1:
        # Multi-image generation mode: create multiple images in parallel
        import asyncio
        import re

        def create_unique_prompts(base_prompt: str, count: int) -> list[str]:
            """Create unique prompts for each image to ensure variety.

            Analyzes the prompt and creates variations for each generation.
            """
            # Check if prompt contains numbered scenes or variations
            # Pattern: "1. scene1, 2. scene2, 3. scene3" or "scene1, scene2, scene3"

            # Try to detect numbered list (handles multi-line scenes with commas)
            # Pattern: "1. scene text\n2. next scene" or "1) scene, more details\n2) next"
            numbered_pattern = r'(\d+)[\.\)]\s*(.*?)(?=\n\s*\d+[\.\)]|\Z)'
            numbered_matches = re.findall(numbered_pattern, base_prompt, re.MULTILINE | re.DOTALL)

            if numbered_matches and len(numbered_matches) >= count:
                # Extract base context (text before first numbered item)
                first_num_pos = re.search(r'\d+[\.\)]', base_prompt)
                base_context = base_prompt[:first_num_pos.start()].strip() if first_num_pos else ""

                # Define radically different camera and lighting setups for each scene
                # This forces variation even when user prompts are similar
                camera_setups = [
                    "Camera: Wide angle (24mm), natural soft daylight, centered composition, eye-level perspective",
                    "Camera: Macro lens (100mm), shallow depth of field, soft diffused backlight, 45-degree angle",
                    "Camera: Top-down view (bird's eye), dramatic side lighting with shadows, overhead perspective",
                    "Camera: Medium telephoto (85mm), three-quarter view, warm golden hour lighting, slightly tilted",
                    "Camera: Extreme close-up macro, bokeh background, bright key light from left, Dutch angle tilt",
                    "Camera: Ultra-wide angle (16mm), low angle looking up, cool morning light, dynamic composition",
                    "Camera: Standard lens (50mm), straight-on frontal view, high-key lighting, perfectly centered",
                    "Camera: Telephoto zoom (135mm), compressed perspective, backlit rim lighting, diagonal framing",
                    "Camera: Fish-eye lens, distorted perspective, colorful accent lighting, off-center placement",
                    "Camera: Tilt-shift lens, selective focus plane, sunset warm tones, asymmetric balance"
                ]

                # Use numbered scenes directly
                prompts = []
                for idx, (num, scene_text) in enumerate(numbered_matches[:count], 1):
                    scene = scene_text.strip()

                    # Get specific camera setup for this scene
                    camera_setup = camera_setups[idx % len(camera_setups)]

                    # Add strong technical specifications to force variation
                    technical_spec = (
                        f"\n\n[TECHNICAL REQUIREMENTS - Scene {idx}/{count}]:\n"
                        f"{camera_setup}\n"
                        f"CRITICAL: This scene MUST be visually DISTINCT from all other scenes. "
                        f"Different angle, different lighting direction, different composition style. "
                        f"Ignore any repetitive patterns from other scenes."
                    )

                    # Combine base context with specific scene
                    if base_context:
                        full_prompt = f"{base_context}. {scene}{technical_spec}"
                    else:
                        full_prompt = f"{scene}{technical_spec}"
                    prompts.append(full_prompt)
                return prompts

            # Try to detect comma-separated scenes (if more than 2 commas)
            comma_parts = [p.strip() for p in base_prompt.split(',') if p.strip()]
            if len(comma_parts) >= count:
                # Use comma-separated parts as separate scenes
                return comma_parts[:count]

            # Detect keywords that suggest multiple scenes
            scene_keywords = ['–Ω–∞ –∫–∞—Ñ–µ–ª–µ', '–Ω–∞ –≤–∞–Ω–Ω–æ–π', '–ª–µ–∂–∏—Ç', '—Å—Ç–æ–∏—Ç', '—Ä—è–¥–æ–º', '–¥–µ—Ä–∂–∏—Ç', '–ª—å–µ—Ç—Å—è']
            detected_scenes = []

            # Split by common separators
            separators = ['. ', ', ', '; ']
            parts = [base_prompt]
            for sep in separators:
                new_parts = []
                for part in parts:
                    new_parts.extend(part.split(sep))
                parts = new_parts

            # Extract scene descriptions
            for part in parts:
                part = part.strip()
                if any(keyword in part.lower() for keyword in scene_keywords):
                    detected_scenes.append(part)

            if detected_scenes and len(detected_scenes) >= count:
                # Use detected scenes
                base_instructions = base_prompt.split('.')[0] if '.' in base_prompt else ""
                prompts = []
                for scene in detected_scenes[:count]:
                    if base_instructions:
                        prompts.append(f"{base_instructions}. {scene}")
                    else:
                        prompts.append(scene)
                return prompts

            # Fallback: create variations by adding diversity instructions
            variations = []
            variation_angles = [
                "top-down aerial view with dramatic overhead lighting",
                "low angle close-up with shallow depth of field",
                "45-degree side angle with natural soft lighting",
                "extreme macro detail shot with bokeh background",
                "wide environmental shot showing full context",
                "dramatic side lighting with strong shadows",
                "backlit silhouette with rim lighting",
                "Dutch angle (tilted) perspective for dynamic feel",
                "straight-on centered composition with symmetry",
                "diagonal composition with leading lines"
            ]

            for i in range(count):
                angle_instruction = variation_angles[i % len(variation_angles)]
                variation = (
                    f"{base_prompt}\n\n"
                    f"VARIATION {i+1}: Use {angle_instruction}. "
                    f"Make this COMPLETELY DIFFERENT from other variations. "
                    f"UNIQUE angle, DIFFERENT background, DISTINCT atmosphere."
                )
                variations.append(variation)

            return variations

        # Create unique prompts for each image
        unique_prompts = create_unique_prompts(prompt, images_to_generate)

        # Log unique prompts for debugging
        logger.info(
            "nano_multi_prompts_created",
            count=len(unique_prompts),
            original_prompt=prompt[:200],
            prompts_lengths=[len(p) for p in unique_prompts],
            prompts_preview=[p[:300] for p in unique_prompts]
        )

        # Log each prompt separately for better visibility
        for idx, up in enumerate(unique_prompts, 1):
            logger.info(
                "nano_multi_prompt_detail",
                scene_index=idx,
                prompt_length=len(up),
                prompt_start=up[:400]
            )

        async def generate_single_image(index: int, image_prompt: str, ref_image: str = None):
            """Generate a single image with unique prompt."""
            try:
                result = await nano_service.generate_image(
                    prompt=image_prompt,
                    model=model,
                    progress_callback=None,  # Disable individual progress for parallel generation
                    aspect_ratio=aspect_ratio,
                    reference_image_path=ref_image
                )
                return (index, result, ref_image)
            except Exception as e:
                logger.error("nano_multi_image_generation_failed", index=index, error=str(e))
                return (index, None, ref_image)

        # Update progress: generating
        await update_progress(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é {images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...\n"
            f"‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-60 —Å–µ–∫—É–Ω–¥..."
        )

        # Create tasks for parallel generation
        # Use reference image for ALL generations to maintain consistent product design
        tasks = []
        if reference_image_paths:
            # Use same reference for all images to keep bottle/product identical
            ref_path = reference_image_paths[0]
            for idx in range(images_to_generate):
                task_prompt = unique_prompts[idx] if idx < len(unique_prompts) else prompt
                tasks.append(generate_single_image(idx, task_prompt, ref_path))
        else:
            # No reference images: generate all as text-to-image with unique prompts
            for idx in range(images_to_generate):
                task_prompt = unique_prompts[idx] if idx < len(unique_prompts) else prompt
                tasks.append(generate_single_image(idx, task_prompt, None))

        # Execute all tasks in parallel
        results_with_indices = await asyncio.gather(*tasks)

        # Process results
        successful_results = []
        failed_count = 0

        for idx, result, ref_path in results_with_indices:
            if result and result.success:
                successful_results.append((idx, result))
            else:
                failed_count += 1
                logger.warning("nano_multi_image_failed", index=idx, error=result.error if result else "Unknown error")

        # Cleanup reference images
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        # Send results
        if successful_results:
            await update_progress(
                f"‚úÖ –ì–æ—Ç–æ–≤–æ: {len(successful_results)}/{images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
                f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã..."
            )

            total_tokens_used = sum(r.metadata.get("tokens_used", cost_per_image) for _, r in successful_results)

            async with async_session_maker() as session:
                sub_service = SubscriptionService(session)
                user_tokens = await sub_service.get_user_total_tokens(user.id)

            # Send summary message first
            model_name = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"
            summary_text = (
                f"‚úÖ **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n\n"
                f"üçå –ú–æ–¥–µ–ª—å: {model_name}\n"
                f"üé® –°–æ–∑–¥–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(successful_results)}/{images_to_generate}\n"
                f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens_used:,}\n"
                f"üíé –û—Å—Ç–∞–ª–æ—Å—å —Ç–æ–∫–µ–Ω–æ–≤: {user_tokens:,}\n\n"
                f"üìù –ü—Ä–æ–º–ø—Ç: {prompt[:150]}{'...' if len(prompt) > 150 else ''}"
            )

            if failed_count > 0:
                summary_text += f"\n\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å: {failed_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

            await message.answer(summary_text, parse_mode="Markdown")

            # Send each image individually
            nano_callback = "bot.nano_pro" if nano_is_pro else "bot.nano"
            for idx, result in successful_results:
                try:
                    image_file = FSInputFile(result.image_path)
                    builder = create_action_keyboard(
                        action_text=MODEL_ACTIONS["nano_banana"]["text"],
                        action_callback=nano_callback,
                        file_path=result.image_path,
                        file_type="image"
                    )
                    await message.answer_photo(
                        photo=image_file,
                        caption=f"üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}/{images_to_generate}",
                        reply_markup=builder.as_markup()
                    )
                except Exception as send_error:
                    logger.error("nano_multi_image_send_failed", index=idx, error=str(send_error))

            await progress_msg.delete()
        else:
            # All failed
            for ref_path in reference_image_paths:
                cleanup_temp_file(ref_path)

            await progress_msg.edit_text(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.",
                parse_mode=None
            )

        await state.clear()
        return

    # Single-image generation mode (original code)
    result = await nano_service.generate_image(
        prompt=prompt,
        model=model,
        progress_callback=update_progress,
        aspect_ratio=aspect_ratio,
        reference_image_path=reference_image_path or (reference_image_paths[0] if reference_image_paths else None)
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        model_name = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name=model_name,
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard - use correct callback based on PRO mode
        nano_callback = "bot.nano_pro" if nano_is_pro else "bot.nano"
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["nano_banana"]["text"],
            action_callback=nano_callback,
            file_path=result.image_path,
            file_type="image"
        )

        try:
            file_size = os.path.getsize(result.image_path)
            logger.info("nano_image_file_size", path=result.image_path, size=file_size)

            if file_size > 2 * 1024 * 1024:
                logger.info("nano_image_optimizing", original_size=file_size)

                img = Image.open(result.image_path)

                if img.mode in ("RGBA", "LA", "P"):
                    background = Image.new("RGB", img.size, (255, 255, 255))
                    if img.mode == "P":
                        img = img.convert("RGBA")
                    background.paste(
                        img,
                        mask=img.split()[-1] if img.mode == "RGBA" else None
                    )
                    img = background

                buffer = io.BytesIO()
                img.save(buffer, format="JPEG", quality=85, optimize=True)
                buffer.seek(0)

                photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                await message.answer_photo(
                    photo=photo,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            else:
                try:
                    image_file = FSInputFile(result.image_path)
                    await message.answer_photo(
                        photo=image_file,
                        caption=info_text,
                        reply_markup=builder.as_markup()
                    )
                except Exception:
                    img = Image.open(result.image_path)

                    if img.mode in ("RGBA", "LA", "P"):
                        background = Image.new("RGB", img.size, (255, 255, 255))
                        if img.mode == "P":
                            img = img.convert("RGBA")
                        background.paste(
                            img,
                            mask=img.split()[-1] if img.mode == "RGBA" else None
                        )
                        img = background

                    buffer = io.BytesIO()
                    img.save(buffer, format="JPEG", quality=90, optimize=True)
                    buffer.seek(0)

                    photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                    await message.answer_photo(
                        photo=photo,
                        caption=info_text,
                        reply_markup=builder.as_markup()
                    )

        except Exception as send_error:
            logger.error("nano_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("nano_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("nano_image_cleanup_failed", error=str(e))

        # Cleanup reference images (both single and multiple)
        if reference_image_path:
            cleanup_temp_file(reference_image_path)
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        await progress_msg.delete()

    else:
        # Cleanup reference images on failure
        if reference_image_path:
            cleanup_temp_file(reference_image_path)
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    # Clear state after generation (success or failure)
    await state.clear()


async def process_kling_image(message: Message, user: User, state: FSMContext):
    """Process Kling AI image generation."""
    data = await state.get_data()

    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)

    estimated_tokens = 5000 if reference_image_path else 3000  # Kling image cost

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            if reference_image_path:
                cleanup_temp_file(reference_image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    mode_text = "image-to-image" if reference_image_path else "text-to-image"
    progress_msg = await message.answer(
        f"üéû –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Kling AI ({mode_text})..."
    )

    kling_service = KlingImageService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await kling_service.generate_image(
        prompt=prompt,
        model="kling-v1",  # Default model
        progress_callback=update_progress,
        aspect_ratio="1:1",  # Default aspect ratio
        resolution="1k"  # Default resolution
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="Kling AI",
            mode="text-to-image" if not reference_image_path else "image-to-image",
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text="üéû –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            action_callback="bot.kling_image",
            file_path=result.image_path,
            file_type="image"
        )

        try:
            photo = FSInputFile(result.image_path)
            await message.answer_photo(
                photo=photo,
                caption=info_text,
                reply_markup=builder.as_markup()
            )

        except Exception as send_error:
            logger.error("kling_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("kling_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("kling_image_cleanup_failed", error=str(e))

        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        await progress_msg.delete()

    else:
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    await state.clear()


async def process_recraft_image(message: Message, user: User, state: FSMContext):
    """Process Recraft AI image generation."""
    data = await state.get_data()
    prompt = data.get("photo_caption_prompt") or message.text

    estimated_tokens = 2200  # Recraft V2 cost (cheaper than DALL-E 3)

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    progress_msg = await message.answer(
        "üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Recraft AI..."
    )

    recraft_service = RecraftService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await recraft_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        model="recraftv2",  # Use V2 for better price
        style="realistic_image",  # Default style
        size="1024x1024"
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="Recraft AI",
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text="üé® –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            action_callback="bot.recraft",
            file_path=result.image_path,
            file_type="image"
        )

        try:
            photo = FSInputFile(result.image_path)
            await message.answer_photo(
                photo=photo,
                caption=info_text,
                reply_markup=builder.as_markup()
            )

        except Exception as send_error:
            logger.error("recraft_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("recraft_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("recraft_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
        await state.update_data(photo_caption_prompt=None)

    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    # Don't clear state - keep service so user can generate more images
    await state.update_data(photo_caption_prompt=None)


# ======================
# FSM HANDLERS - AUDIO
# ======================

@router.message(MediaState.waiting_for_audio_prompt, F.text)
async def process_audio_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    service_name = data.get("service", "suno")

    if service_name == "suno":
        await process_suno_audio(message, user, state)
    elif service_name == "tts":
        await process_tts_audio(message, user, state)
    else:
        display = {
            "suno": "Suno AI",
            "tts": "OpenAI TTS"
        }.get(service_name, service_name)

        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à —Ç–µ–∫—Å—Ç –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


async def process_suno_audio(message: Message, user: User, state: FSMContext):
    """Process Suno AI music generation."""
    prompt = message.text

    # Check and use tokens
    estimated_tokens = 5000  # Suno AI cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üéµ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –º—É–∑—ã–∫–∏ —Å Suno AI...")

    # Create service
    suno_service = SunoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate music
    result = await suno_service.generate_audio(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["audio"],
            model_name="Suno AI",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=caption,
            title=f"Suno AI - {prompt[:50]}"
        )

        # Clean up
        try:
            pass  # os.remove(result.audio_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("suno_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE PROCESSING
# ======================

@router.message(MediaState.waiting_for_replace_bg_image, F.photo)
async def process_replace_bg_image(message: Message, state: FSMContext, user: User):
    """Process image for background replacement."""
    # Get the largest photo
    photo = message.photo[-1]

    # Download photo
    file = await message.bot.get_file(photo.file_id)
    temp_path = get_temp_file_path(prefix="replace_bg", suffix=".jpg", user_id=user.id)
    await message.bot.download_file(file.file_path, temp_path)

    # Resize if needed
    temp_path = resize_image_if_needed(temp_path, max_size_mb=3.0, max_dimension=2048)

    # Save to state
    await state.update_data(replace_bg_image_path=str(temp_path))

    # Ask for background description
    await message.answer(
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "üìù –¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏—Ç–µ –Ω–æ–≤—ã–π —Ñ–æ–Ω:\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ë–µ–ª—ã–π —Ñ–æ–Ω\"\n"
        "‚Ä¢ \"–ü–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏ –Ω–∞ –∑–∞–∫–∞—Ç–µ\"\n"
        "‚Ä¢ \"–ì–æ—Ä–æ–¥—Å–∫–∞—è —É–ª–∏—Ü–∞ –Ω–æ—á—å—é\"\n"
        "‚Ä¢ \"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç –æ—Ç —Å–∏–Ω–µ–≥–æ –∫ —Ñ–∏–æ–ª–µ—Ç–æ–≤–æ–º—É\"",
        parse_mode="Markdown"
    )

    await state.set_state(MediaState.waiting_for_replace_bg_prompt)


@router.message(MediaState.waiting_for_replace_bg_prompt, F.text)
async def process_replace_bg_prompt(message: Message, state: FSMContext, user: User):
    """Process background replacement with new background description."""
    # CRITICAL FIX: Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    image_path = data.get("replace_bg_image_path")
    background_description = message.text.strip()

    if not image_path:
        await message.answer("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ —Å /start")
        await state.clear()
        return

    # Check tokens
    estimated_tokens = 2000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            cleanup_temp_file(image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ó–∞–º–µ–Ω—è—é —Ñ–æ–Ω...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Use Nano Banana service with image-to-image
    nano_service = NanoBananaService()

    # Create prompt for background replacement
    prompt = f"–ó–∞–º–µ–Ω–∏ —Ñ–æ–Ω –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∞: {background_description}. –°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏ —Ñ–æ–Ω."

    # Generate with reference image
    result = await nano_service.generate_image(
        prompt=prompt,
        reference_image_path=image_path,
        progress_callback=update_progress
    )

    # Clean up original image
    cleanup_temp_file(image_path)

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate caption
        caption = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash)",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=background_description,
            mode="background-replacement"
        )

        # Send image
        await message.answer_photo(
            photo=FSInputFile(result.image_path),
            caption=caption,
            reply_markup=create_action_keyboard(
                action_text="üîÑ –ó–∞–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω –µ—â–µ —Ä–∞–∑",
                action_callback="bot.pi_repb",
                file_path=result.image_path,
                file_type="image"
            ).as_markup()
        )

        await progress_msg.delete()

        # Clean up generated image
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("replace_bg_cleanup_failed", error=str(e))

        logger.info(
            "replace_bg_completed",
            user_id=user.id,
            background=background_description[:50],
            tokens=estimated_tokens
        )
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

        logger.error("replace_bg_failed", user_id=user.id, error=result.error)

    await state.clear()


@router.message(MediaState.waiting_for_image, F.photo)
async def process_image(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service = data.get("service", "remove_bg")

    display = {
        "remove_bg": "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞",
        "replace_bg": "–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞"
    }.get(service, service)

    await message.answer(
        f"–§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!"
    )
    await state.clear()


@router.message(MediaState.waiting_for_upscale_image, F.photo)
async def process_upscale(message: Message, state: FSMContext, user: User):
    """Process image upscaling."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 2000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="upscale", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    stability_service = StabilityService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Upscale image
    result = await stability_service.upscale_image(
        image_path=str(temp_path),
        scale_factor=2,
        progress_callback=update_progress
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:

        # Send upscaled image
        upscaled_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=upscaled_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–æ!\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("upscale_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - WHISPER (VOICE TRANSCRIPTION)
# ======================

@router.message(MediaState.waiting_for_whisper_audio, F.voice | F.audio)
async def process_whisper_audio(message: Message, state: FSMContext, user: User):
    """Process Whisper audio transcription."""

    # Check and use tokens
    estimated_tokens = 1000  # Whisper cost per minute

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ...")

    # Download audio
    if message.voice:
        file = await message.bot.get_file(message.voice.file_id)
        file_ext = "ogg"
    else:
        file = await message.bot.get_file(message.audio.file_id)
        file_ext = "mp3"

    # Create temp path
    temp_path = get_temp_file_path(prefix="audio", suffix=f".{file_ext}")

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    whisper_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    await update_progress("üéôÔ∏è –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –∞—É–¥–∏–æ...")

    # Transcribe audio
    result = await whisper_service.transcribe(
        audio_path=str(temp_path),
        language="ru"  # Russian language
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:
        # Send transcription
        await message.answer(
            f"‚úÖ **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ—Ç–æ–≤–∞!**\n\n"
            f"üìù **–¢–µ–∫—Å—Ç:**\n{result.text}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - TTS UPDATE
# ======================

async def process_tts_audio(message: Message, user: User, state: FSMContext):
    """Process OpenAI TTS generation."""
    text = message.text

    if len(text) > 4096:
        await message.answer("‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π! –ú–∞–∫—Å–∏–º—É–º 4096 —Å–∏–º–≤–æ–ª–æ–≤.")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 200  # TTS cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∫—Å—Ç–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üéôÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–µ—á—å...")

    # Create service
    tts_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate audio (default voice: alloy)
    result = await tts_service.generate_audio(
        prompt=text,
        voice="alloy",
        model="tts-1",
        progress_callback=update_progress
    )

    if result.success:
        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=f"‚úÖ –û–∑–≤—É—á–∫–∞ –≥–æ—Ç–æ–≤–∞!\n\n"
                    f"–ì–æ–ª–æ—Å: alloy\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}",
            title="OpenAI TTS"
        )

        # Clean up
        try:
            pass  # os.remove(result.audio_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("tts_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - GPT VISION (IMAGE ANALYSIS)
# ======================

@router.message(MediaState.waiting_for_vision_image, F.photo)
async def process_vision_image(message: Message, state: FSMContext, user: User):
    """Receive image and ask for analysis prompt."""
    # Get the largest photo
    photo = message.photo[-1]

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="vision", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Store image path in state
    await state.update_data(image_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_vision_prompt)

    await progress_msg.edit_text(
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ –ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ?\n"
        "‚Ä¢ –û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ\n"
        "‚Ä¢ –ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –µ—Å—Ç—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?\n"
        "‚Ä¢ –ß—Ç–æ –∑–∞ –æ–±—ä–µ–∫—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã?"
    )


@router.message(MediaState.waiting_for_vision_prompt, F.text)
async def process_vision_prompt(message: Message, state: FSMContext, user: User):
    """Process GPT Vision image analysis."""
    data = await state.get_data()
    image_path = data.get("image_path")
    prompt = message.text

    if not image_path or not os.path.exists(image_path):
        await message.answer("‚ùå –û—à–∏–±–∫–∞: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 1000  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up temp file
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üëÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1000,
        detail="auto"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        # Send analysis
        await message.answer(
            f"‚úÖ **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤!**\n\n"
            f"üìù **–û—Ç–≤–µ—Ç:**\n{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# PHOTO TOOLS HANDLERS
# ======================

@router.message(MediaState.waiting_for_photo_upscale, F.photo)
async def process_photo_upscale(message: Message, state: FSMContext, user: User):
    """Process photo quality improvement using PIL image enhancement."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens (basic image processing is cheap)
    estimated_tokens = 500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="enhance", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    try:
        # Progress update
        await progress_msg.edit_text("üé® –£–ª—É—á—à–∞—é –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", parse_mode=None)

        # Open image with PIL
        from PIL import Image, ImageEnhance, ImageFilter

        img = Image.open(temp_path)

        # Convert to RGB if needed
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            if img.mode in ('RGBA', 'LA'):
                background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = background

        # 1. Enhance sharpness
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.5)  # Increase sharpness by 50%

        # 2. Enhance contrast
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.2)  # Increase contrast by 20%

        # 3. Enhance color
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(1.1)  # Increase color saturation by 10%

        # 4. Enhance brightness slightly
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(1.05)  # Increase brightness by 5%

        # 5. Apply subtle unsharp mask for additional sharpness
        img = img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))

        # Save enhanced image
        enhanced_path = get_temp_file_path(prefix="enhanced", suffix=".jpg")

        # Save with high quality
        img.save(str(enhanced_path), 'JPEG', quality=95, optimize=True)

        # Check file size and optimize if needed
        file_size = os.path.getsize(enhanced_path)
        max_size = 10 * 1024 * 1024  # 10 MB Telegram limit

        if file_size > max_size:
            logger.info("enhanced_image_too_large", size=file_size, max_size=max_size)
            # Reduce quality gradually until it fits
            quality = 90
            while file_size > max_size and quality > 60:
                img.save(str(enhanced_path), 'JPEG', quality=quality, optimize=True)
                file_size = os.path.getsize(enhanced_path)
                quality -= 5
                logger.info("enhanced_image_compressed", new_size=file_size, quality=quality)

        # Clean up original temp file
        cleanup_temp_file(temp_path)

        # Send enhanced image
        enhanced_file = FSInputFile(enhanced_path)
        await message.answer_photo(
            photo=enhanced_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–æ!\n\n"
                    f"–ü—Ä–∏–º–µ–Ω–µ–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è: —Ä–µ–∑–∫–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç, —Ü–≤–µ—Ç–∞, —è—Ä–∫–æ—Å—Ç—å.\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        # Clean up enhanced file
        cleanup_temp_file(enhanced_path)

        await progress_msg.delete()

    except Exception as e:
        # Clean up temp files on error
        cleanup_temp_file(temp_path)

        logger.error("photo_quality_improvement_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{str(e)}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_replace_bg, F.photo)
async def process_photo_replace_bg(message: Message, state: FSMContext, user: User):
    """Process background replacement."""
    # First, save the photo and ask for background description
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    # Save to state
    await state.update_data(saved_image_path=image_path)

    # Ask for background description
    await message.answer(
        "üì§ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "‚úèÔ∏è –¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫–æ–π —Ñ–æ–Ω –≤—ã —Ö–æ—Ç–∏—Ç–µ:\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ –ì–æ—Ä–Ω—ã–π –ø–µ–π–∑–∞–∂ —Å –∑–∞—Å–Ω–µ–∂–µ–Ω–Ω—ã–º–∏ –≤–µ—Ä—à–∏–Ω–∞–º–∏\n"
        "‚Ä¢ –¢—Ä–æ–ø–∏—á–µ—Å–∫–∏–π –ø–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏\n"
        "‚Ä¢ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ—Ñ–∏—Å\n"
        "‚Ä¢ –ö–æ—Å–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å –∑–≤–µ–∑–¥–∞–º–∏",
        reply_markup=back_to_main_keyboard()
    )


@router.message(MediaState.waiting_for_photo_replace_bg, F.text)
async def process_photo_replace_bg_prompt(message: Message, state: FSMContext, user: User):
    """Process background replacement with Gemini (NanoBananaService)."""
    # CRITICAL FIX: Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    image_path = data.get("saved_image_path")

    if not image_path or not os.path.exists(image_path):
        await message.answer("‚ùå –û—à–∏–±–∫–∞: —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        await state.clear()
        return

    bg_description = message.text

    # Check and use tokens (Gemini image-to-image: ~3000 tokens)
    estimated_tokens = 3000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up saved image
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ó–∞–º–µ–Ω—è—é —Ñ–æ–Ω —Å Gemini 2.5 Flash...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Use Nano Banana service with image-to-image
    nano_service = NanoBananaService()

    # Create prompt for background replacement
    prompt = f"–ó–∞–º–µ–Ω–∏ —Ñ–æ–Ω –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∞: {bg_description}. –°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏ —Ñ–æ–Ω."

    # Generate with reference image using Gemini 2.5 Flash Image
    result = await nano_service.generate_image(
        prompt=prompt,
        model="gemini-2.5-flash-image",
        reference_image_path=image_path,
        progress_callback=update_progress
    )

    # Clean up original image
    cleanup_temp_file(image_path)

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_user_total_tokens(user.id)

        # Generate caption
        caption = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash)",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=bg_description,
            mode="background-replacement"
        )

        # Send image
        await message.answer_photo(
            photo=FSInputFile(result.image_path),
            caption=caption,
            reply_markup=create_action_keyboard(
                action_text="üîÑ –ó–∞–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω –µ—â–µ —Ä–∞–∑",
                action_callback="bot.pi_repb",
                file_path=result.image_path,
                file_type="image"
            ).as_markup()
        )

        await progress_msg.delete()

        # Clean up generated image
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("replace_bg_cleanup_failed", error=str(e))

        logger.info(
            "photo_replace_bg_completed",
            user_id=user.id,
            background=bg_description[:50],
            tokens=estimated_tokens
        )
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

        logger.error("photo_replace_bg_failed", user_id=user.id, error=result.error)

    await state.clear()


@router.message(MediaState.waiting_for_photo_remove_bg, F.photo)
async def process_photo_remove_bg(message: Message, state: FSMContext, user: User):
    """Process background removal using Remove.bg API."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="removebg", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Remove background
    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=str(temp_path),
        progress_callback=update_progress,
        size="auto",  # auto, preview, full
        type="auto"   # auto, person, product, car
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:
        # Send image with removed background
        result_file = FSInputFile(result.image_path)

        # Try sending as photo first
        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )
        except Exception:
            # If photo fails (transparent images sometimes do), send as document
            await message.answer_document(
                document=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n"
                        f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º (PNG).\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("removebg_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_vectorize, F.photo)
async def process_photo_vectorize(message: Message, state: FSMContext, user: User):
    """Process photo vectorization."""
    await _process_photo_tool(
        message, state, user,
        tool_name="–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è",
        prompt=(
            "Analyze this image and describe how to convert it to a vector format. "
            "Provide recommendations for: tracing method, color palette reduction, "
            "path simplification, and optimal settings for this specific image type. "
            "Suggest the best vectorization approach (outline, centerline, or full color)."
        ),
        emoji="üìê"
    )


async def _process_photo_tool(message: Message, state: FSMContext, user: User,
                              tool_name: str, prompt: str, emoji: str):
    """Helper function to process photo with GPT Vision."""
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    await _process_photo_with_path(message, state, user, image_path, tool_name, prompt, emoji)


async def _process_photo_with_path(message: Message, state: FSMContext, user: User,
                                   image_path: str, tool_name: str, prompt: str, emoji: str):
    """Process photo with given path."""
    # Check and use tokens
    estimated_tokens = 1500  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up temp file
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer(f"{emoji} –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–æ—Ç–æ...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        # Send analysis
        await message.answer(
            f"‚úÖ **{tool_name} - –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤!**\n\n"
            f"üìù **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()

# ======================
# SMART INPUT HANDLING - No model selected
# ======================

@router.message(F.photo, ~F.state(None))
async def handle_photo_in_wrong_state(message: Message, state: FSMContext):
    """Handle photo sent in unsupported state - redirect to correct handler."""
    current_state = await state.get_state()

    # If in video/image prompt state, pass to existing handlers
    if current_state in [MediaState.waiting_for_video_prompt, MediaState.waiting_for_image_prompt]:
        return  # Let other handlers process it

    # Otherwise, clear state and treat as new photo
    await state.clear()
    await handle_photo_no_model(message, state)


@router.message(F.photo)
async def handle_photo_no_model(message: Message, state: FSMContext):
    """Handle photo sent without selecting a model first."""
    # Download and save photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="unsorted", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Save to state
    await state.update_data(saved_photo_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_photo_action_choice)

    # Create inline keyboard for choosing action
    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ", callback_data="photo_action:video"),
            InlineKeyboardButton(text="üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="photo_action:image")
        ],
        [
            InlineKeyboardButton(text="üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ", callback_data="photo_action:vision"),
            InlineKeyboardButton(text="üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ", callback_data="photo_action:tools")
        ],
        [
            InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="photo_action:cancel")
        ]
    ])

    await message.answer_photo(
        photo=photo.file_id,
        caption="üì∏ **–§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!**\n\n"
                "–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ?\n\n"
                "üé¨ **–°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ** - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ç–æ\n"
                "üñº **–°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ** - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Ñ–æ—Ç–æ –≤ –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
                "üëÅ **–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ** - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
                "üé® **–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ** - —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, —É–ª—É—á—à–µ–Ω–∏–µ –∏ —Ç.–¥.",
        reply_markup=keyboard
    )


@router.callback_query(F.data.startswith("photo_action:"))
async def handle_photo_action_choice(callback: CallbackQuery, state: FSMContext):
    """Handle user's choice of what to do with the photo."""
    action = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if action == "cancel":
        # Clean up photo
        if saved_photo_path:
            cleanup_temp_file(saved_photo_path)
        await state.clear()
        await callback.message.edit_caption(
            caption="‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞."
        )
        await callback.answer()
        return

    if action == "video":
        # Show video models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üåä Veo 3.1", callback_data="photo_video:veo"),
                InlineKeyboardButton(text="üåô Luma", callback_data="photo_video:luma")
            ],
            [
                InlineKeyboardButton(text="‚ú® Kling AI", callback_data="photo_video:kling")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="üé¨ **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ:**\n\n"
                    "‚Ä¢ **Veo 3.1** - Google, HD –∫–∞—á–µ—Å—Ç–≤–æ (~15,000 —Ç–æ–∫–µ–Ω–æ–≤)\n"
                    "‚Ä¢ **Luma** - Dream Machine (~8,000 —Ç–æ–∫–µ–Ω–æ–≤)\n"
                    "‚Ä¢ **Kling AI** - –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (~9,000 —Ç–æ–∫–µ–Ω–æ–≤)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "image":
        # Show image models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üçå Nano Banana", callback_data="photo_image:nano"),
                InlineKeyboardButton(text="üñº DALL-E", callback_data="photo_image:dalle")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="üñº **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n"
                    "‚Ä¢ **Nano Banana** - Gemini 2.5 Flash, image-to-image (~3,000 —Ç–æ–∫–µ–Ω–æ–≤)\n"
                    "‚Ä¢ **DALL-E** - Image variation (~2,000 —Ç–æ–∫–µ–Ω–æ–≤)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "vision":
        # Move photo to vision state and start analysis
        if saved_photo_path:
            # Actually process vision directly
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    # Default prompt for analysis
                    prompt = "Provide a detailed analysis of this image. Describe what you see, including objects, people, scenery, colors, composition, and any notable details."
                    await _process_vision_with_path(callback.message, state, user, saved_photo_path, prompt)
                else:
                    await callback.message.edit_caption("‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    await state.clear()
        else:
            await callback.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", show_alert=True)
            await state.clear()

    elif action == "tools":
        # Show photo tools
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üö´ –£–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω", callback_data="photo_tool:remove_bg")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="üé® **–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n\n"
                    "‚Ä¢ **–£–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω** - –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω (~1,000 —Ç–æ–∫–µ–Ω–æ–≤)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "back":
        # Go back to main choice - resend the photo with choices
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ", callback_data="photo_action:video"),
                InlineKeyboardButton(text="üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="photo_action:image")
            ],
            [
                InlineKeyboardButton(text="üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ", callback_data="photo_action:vision"),
                InlineKeyboardButton(text="üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ", callback_data="photo_action:tools")
            ],
            [
                InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="photo_action:cancel")
            ]
        ])

        await callback.message.edit_caption(
            caption="üì∏ **–§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!**\n\n"
                    "–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ?\n\n"
                    "üé¨ **–°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ** - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ç–æ\n"
                    "üñº **–°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ** - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Ñ–æ—Ç–æ –≤ –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
                    "üëÅ **–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ** - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
                    "üé® **–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ** - —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, —É–ª—É—á—à–µ–Ω–∏–µ –∏ —Ç.–¥.",
            reply_markup=keyboard
        )
        await callback.answer()


@router.callback_query(F.data.startswith("photo_video:"))
async def handle_photo_video_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle video model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Move photo to image_path for video generation
    await state.update_data(image_path=saved_photo_path, service=model)
    await state.set_state(MediaState.waiting_for_video_prompt)

    model_names = {
        "veo": "Veo 3.1",
        "luma": "Luma Dream Machine",
        "kling": "Kling AI"
    }

    await callback.message.edit_caption(
        caption=f"‚úÖ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
                f"üé¨ **{model_names.get(model, model)}**\n\n"
                f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã:**\n"
                f"‚Ä¢ \"–û–∂–∏–≤–∏ —ç—Ç–æ —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤—å –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ\"\n"
                f"‚Ä¢ \"–°–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã –≤–æ–ª–æ—Å—ã —Ä–∞–∑–≤–µ–≤–∞–ª–∏—Å—å –Ω–∞ –≤–µ—Ç—Ä—É\"\n"
                f"‚Ä¢ \"–î–æ–±–∞–≤—å –ø–∞–¥–∞—é—â–∏–µ —Å–Ω–µ–∂–∏–Ω–∫–∏ –∏ –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã\""
    )
    await callback.answer()


@router.callback_query(F.data.startswith("photo_image:"))
async def handle_photo_image_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle image model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Map service names
    service_map = {
        "nano": "nano_banana",
        "dalle": "dalle"
    }

    # Move photo to reference_image_path for image generation
    await state.update_data(reference_image_path=saved_photo_path, service=service_map.get(model, model))
    await state.set_state(MediaState.waiting_for_image_prompt)

    model_names = {
        "nano": "Nano Banana",
        "dalle": "DALL-E"
    }

    examples = {
        "nano": "‚Ä¢ \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–∫–≤–∞—Ä–µ–ª—å–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫\"\n‚Ä¢ \"–°–¥–µ–ª–∞–π —Ñ–æ–Ω –∫–æ—Å–º–∏—á–µ—Å–∫–∏–º\"",
        "dalle": "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–∏"
    }

    await callback.message.edit_caption(
        caption=f"‚úÖ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
                f"üñº **{model_names.get(model, model)}**\n\n"
                f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã:**\n{examples.get(model, '')}"
    )
    await callback.answer()


@router.callback_query(F.data.startswith("photo_tool:"))
async def handle_photo_tool_choice(callback: CallbackQuery, state: FSMContext):
    """Handle photo tool choice."""
    tool = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if tool == "remove_bg":
        # Trigger processing with saved photo
        if saved_photo_path and os.path.exists(saved_photo_path):
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    await _process_remove_bg_with_path(callback.message, state, user, saved_photo_path)
                else:
                    await callback.message.edit_caption("‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    await state.clear()
        else:
            await callback.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", show_alert=True)
            await state.clear()

    await callback.answer()


async def _process_remove_bg_with_path(message: Message, state: FSMContext, user: User, image_path: str):
    """Process background removal with given path."""
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üö´ –£–¥–∞–ª—è—é —Ñ–æ–Ω...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=image_path,
        progress_callback=update_progress,
        size="auto",
        type="auto"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        result_file = FSInputFile(result.image_path)

        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )
        except Exception:
            await message.answer_document(
                document=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º (PNG).\n\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )

        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception:
            pass

        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞:\n{result.error}")

    await state.clear()


async def _process_vision_with_path(message: Message, state: FSMContext, user: User, image_path: str, prompt: str):
    """Process vision analysis with given path."""
    estimated_tokens = 1500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            cleanup_temp_file(image_path)
            await state.clear()
            return

    progress_msg = await message.answer("üëÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    vision_service = VisionService()
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        await message.answer(
            f"‚úÖ **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤!**\n\n"
            f"{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )
        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:\n{result.error}")

    await state.clear()
