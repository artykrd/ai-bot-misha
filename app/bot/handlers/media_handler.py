#!/usr/bin/env python3
# coding: utf-8

"""
Media handlers for video, audio, and image generation.
"""

import asyncio

from aiogram import Router, F
from aiogram.exceptions import TelegramBadRequest
from aiogram.types import CallbackQuery, Message, FSInputFile, BufferedInputFile
from aiogram.fsm.context import FSMContext
import os
from pathlib import Path
from PIL import Image
import io

from app.bot.keyboards.inline import (
    back_to_main_keyboard,
    kling_choice_keyboard,
    kling_main_keyboard,
    kling_settings_keyboard,
    kling_aspect_ratio_keyboard,
    kling_duration_keyboard,
    kling_version_keyboard,
    kling_auto_translate_keyboard,
    kling_image_main_keyboard,
    kling_image_settings_keyboard,
    kling_image_aspect_ratio_keyboard,
    kling_image_model_keyboard,
    kling_image_resolution_keyboard,
    kling_image_auto_translate_keyboard,
    kling_effects_main_keyboard,
    kling_effects_categories_keyboard,
    kling_effects_list_keyboard,
    kling_effects_confirm_keyboard,
    nano_banana_keyboard,
    nano_format_keyboard,
    nano_multi_images_keyboard,
    seedream_keyboard,
    seedream_size_keyboard,
    seedream_batch_count_keyboard,
    seedream_back_keyboard,
    kling_motion_control_keyboard,
    kling_mc_settings_keyboard,
    kling_mc_mode_keyboard,
    kling_mc_orientation_keyboard,
    kling_mc_sound_keyboard,
)
from app.bot.states import MediaState
from app.bot.states.media import KlingSettings, KlingImageSettings
from app.bot.utils.notifications import (
    format_generation_message,
    create_action_keyboard,
    CONTENT_TYPES,
    MODEL_ACTIONS,
)
from app.database.models.user import User
from app.database.database import async_session_maker
from app.core.logger import get_logger
from app.core.exceptions import InsufficientTokensError
from app.core.cost_guard import cost_guard
from app.core.billing_config import (
    get_image_model_billing,
    get_video_model_billing,
    format_token_amount,
    get_kling_tokens_cost,
    get_kling_api_model,
)
from app.core.temp_files import get_temp_file_path, cleanup_temp_file
from app.services.video import VeoService, SoraService, LumaService, HailuoService, KlingService
from app.services.video.kling_effects_service import KlingEffectsService
from app.services.image import DalleService, GeminiImageService, StabilityService, RemoveBgService, NanoBananaService, KlingImageService, RecraftService, SeedreamService, MidjourneyService
from app.services.audio import SunoService, OpenAIAudioService
from app.services.ai.vision_service import VisionService
from app.services.subscription.subscription_service import SubscriptionService

logger = get_logger(__name__)

router = Router(name="media")


# ======================
# UTILITY FUNCTIONS
# ======================

async def cleanup_temp_images(state: FSMContext):
    """Clean up temporary image files from state."""
    data = await state.get_data()
    for key in ["image_path", "reference_image_path"]:
        file_path = data.get(key)
        if file_path:
            cleanup_temp_file(file_path)


async def get_available_tokens(user_id: int) -> int:
    """Fetch available tokens for user from subscriptions."""
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        return await sub_service.get_available_tokens(user_id)


def resize_image_if_needed(image_path: str, max_size_mb: float = 2.0, max_dimension: int = 2048) -> str:
    """
    Resize image if it's too large.

    Args:
        image_path: Path to the image file
        max_size_mb: Maximum file size in MB
        max_dimension: Maximum width or height in pixels

    Returns:
        Path to the resized image (same as input if no resize needed)
    """
    try:
        file_size_mb = os.path.getsize(image_path) / (1024 * 1024)

        img = Image.open(image_path)
        needs_resize = False

        # Check if file size is too large
        if file_size_mb > max_size_mb:
            needs_resize = True
            logger.info("image_too_large", size_mb=file_size_mb)

        # Check if dimensions are too large
        if img.width > max_dimension or img.height > max_dimension:
            needs_resize = True
            logger.info("image_dimensions_too_large", width=img.width, height=img.height)

        if not needs_resize:
            return image_path

        # Calculate new dimensions maintaining aspect ratio
        ratio = min(max_dimension / img.width, max_dimension / img.height, 1.0)
        new_width = int(img.width * ratio)
        new_height = int(img.height * ratio)

        # Convert RGBA to RGB if needed
        if img.mode in ("RGBA", "LA", "P"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode == "P":
                img = img.convert("RGBA")
            background.paste(
                img,
                mask=img.split()[-1] if img.mode == "RGBA" else None
            )
            img = background

        # Resize image
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # Save with optimization
        img_resized.save(image_path, "JPEG", quality=85, optimize=True)

        new_size_mb = os.path.getsize(image_path) / (1024 * 1024)
        logger.info(
            "image_resized",
            old_size_mb=file_size_mb,
            new_size_mb=new_size_mb,
            old_dimensions=f"{img.width}x{img.height}",
            new_dimensions=f"{new_width}x{new_height}"
        )

        return image_path

    except Exception as e:
        logger.error("image_resize_failed", error=str(e))
        return image_path


# ======================
# VIDEO SERVICES
# ======================

@router.callback_query(F.data == "bot.veo")
async def start_veo(callback: CallbackQuery, state: FSMContext, user: User):
    # Get user's total tokens
    total_tokens = await get_available_tokens(user.id)
    veo_billing = get_video_model_billing("veo-3.1-fast")
    videos_available = int(total_tokens / veo_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üåä **Veo 3.1 ¬∑ –ª—É—á—à–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ**\n\n"
        "‚úèÔ∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ–∑–¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ 8 —Å–µ–∫—É–Ω–¥–Ω—ã–µ –≤–∏–¥–µ–æ, –º–æ–∂–µ—Ç –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–∞, "
        "—Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å –≤–∏–¥–µ–æ –∑–≤—É–∫–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–æ–π –∏ —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–∞—à–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è.\n\n"
        "üì∏ –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å 1 —Ñ–æ—Ç–æ —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏ —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ.\n\n"
        "üì∑ 1Ô∏è‚É£:2Ô∏è‚É£ (–Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä / –∑–∞–≤–µ—Ä—à–∞—é—â–∏–π –∫–∞–¥—Ä). –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ –¥–≤–∞ —Ñ–æ—Ç–æ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ "
        "–∏ –ø–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ. –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ.\n\n"
        "#Ô∏è‚É£ –ò–∑—É—á–∏—Ç–µ –≥–∞–π–¥ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ –∏ –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n\n"
        "‚öôÔ∏è **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**\n"
        "–ú–æ–¥–µ–ª—å: Veo 3.1 Fast\n"
        "–§–æ—Ä–º–∞—Ç: 16:9\n"
        "–°–∏–¥: 0\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –≤–∏–¥–µ–æ. 1 –≤–∏–¥–µ–æ = {format_token_amount(veo_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="veo", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.sora")
async def start_sora(callback: CallbackQuery, state: FSMContext, user: User):
    from app.bot.keyboards.inline import sora_main_keyboard
    from app.bot.states.media import SoraSettings
    from app.core.billing_config import get_sora_tokens_cost

    # Get or create Sora settings from FSM
    data = await state.get_data()
    sora_settings = SoraSettings.from_dict(data)

    total_tokens = await get_available_tokens(user.id)
    tokens_per_video = get_sora_tokens_cost(sora_settings.quality, sora_settings.duration)
    videos_available = int(total_tokens / tokens_per_video) if total_tokens > 0 else 0

    text = (
        "‚òÅÔ∏è **Sora 2 ¬∑ –≤–∏—Ä—É—Å–Ω—ã–µ —Ä–æ–ª–∏–∫–∏ —Å –æ–∑–≤—É—á–∫–æ–π**\n\n"
        "‚úèÔ∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ–∑–¥–∞–µ—Ç –≤–∏–¥–µ–æ –¥–ª–∏–Ω–æ–π –¥–æ 15 —Å–µ–∫—É–Ω–¥, –≤ –∫–æ—Ç–æ—Ä–æ–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–≤—É–∫, "
        "–≤–æ–∑–º–æ–∂–Ω–∞ –æ–∑–≤—É—á–∫–∞ —Å—Ü–µ–Ω –∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–∞–¥—Ä–µ, —Å–º–µ–Ω–∞ –ª–æ–∫–∞—Ü–∏–π –∏ —Ç.–¥.\n\n"
        "üì∏ –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å 1 —Ñ–æ—Ç–æ —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏ —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ.\n\n"
        "‚õîÔ∏è Sora –Ω–µ –º–æ–∂–µ—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å –ª—é–¥–µ–π –Ω–∞ —Ñ–æ—Ç–æ –∏ –¥–µ–ª–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ —É—á–∞–≤—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ –∫–∞–¥—Ä–µ. "
        "–û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ñ–æ—Ç–æ –±–µ–∑ –ª—é–¥–µ–π –≤ –∫–∞–¥—Ä–µ.\n\n"
        f"‚öôÔ∏è **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**\n"
        f"{sora_settings.get_display_settings()}\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** Sora 2 ‚Äî 7 000—Ç./1 —Å–µ–∫., Sora 2 Pro (720P) ‚Äî 20 000—Ç./1 —Å–µ–∫.\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –≤–∏–¥–µ–æ. "
        f"1 –≤–∏–¥–µ–æ = {format_token_amount(tokens_per_video)} —Ç–æ–∫–µ–Ω–æ–≤"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    settings_dict = sora_settings.to_dict()
    await state.update_data(service="sora", image_path=None, photo_caption_prompt=None, **settings_dict)

    try:
        await callback.message.edit_text(text, reply_markup=sora_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=sora_main_keyboard())
    await callback.answer()


# Sora 2 settings handlers
@router.callback_query(F.data == "sora.settings")
async def sora_settings_menu(callback: CallbackQuery, state: FSMContext, user: User):
    from app.bot.keyboards.inline import sora_settings_keyboard
    text = "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Sora 2**\n\n–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:"
    try:
        await callback.message.edit_text(text, reply_markup=sora_settings_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=sora_settings_keyboard())
    await callback.answer()


@router.callback_query(F.data == "sora.settings.duration")
async def sora_duration_setting(callback: CallbackQuery, state: FSMContext, user: User):
    from app.bot.keyboards.inline import sora_duration_keyboard
    from app.bot.states.media import SoraSettings
    data = await state.get_data()
    sora_settings = SoraSettings.from_dict(data)
    text = "üïì **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ**\n\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:"
    try:
        await callback.message.edit_text(text, reply_markup=sora_duration_keyboard(sora_settings.duration))
    except Exception:
        await callback.message.answer(text, reply_markup=sora_duration_keyboard(sora_settings.duration))
    await callback.answer()


@router.callback_query(F.data.startswith("sora.set.duration:"))
async def sora_set_duration(callback: CallbackQuery, state: FSMContext, user: User):
    duration = int(callback.data.split(":")[1])
    await state.update_data(sora_duration=duration)
    await start_sora(callback, state, user)


@router.callback_query(F.data == "sora.settings.quality")
async def sora_quality_setting(callback: CallbackQuery, state: FSMContext, user: User):
    from app.bot.keyboards.inline import sora_quality_keyboard
    from app.bot.states.media import SoraSettings
    data = await state.get_data()
    sora_settings = SoraSettings.from_dict(data)
    text = "üéØ **–ö–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ**\n\n–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ:"
    try:
        await callback.message.edit_text(text, reply_markup=sora_quality_keyboard(sora_settings.quality))
    except Exception:
        await callback.message.answer(text, reply_markup=sora_quality_keyboard(sora_settings.quality))
    await callback.answer()


@router.callback_query(F.data.startswith("sora.set.quality:"))
async def sora_set_quality(callback: CallbackQuery, state: FSMContext, user: User):
    quality = callback.data.split(":")[1]
    await state.update_data(sora_quality=quality)
    await start_sora(callback, state, user)


@router.callback_query(F.data == "sora.settings.aspect_ratio")
async def sora_aspect_ratio_setting(callback: CallbackQuery, state: FSMContext, user: User):
    from app.bot.keyboards.inline import sora_aspect_ratio_keyboard
    from app.bot.states.media import SoraSettings
    data = await state.get_data()
    sora_settings = SoraSettings.from_dict(data)
    text = "üìê **–§–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ**\n\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç:"
    try:
        await callback.message.edit_text(text, reply_markup=sora_aspect_ratio_keyboard(sora_settings.aspect_ratio))
    except Exception:
        await callback.message.answer(text, reply_markup=sora_aspect_ratio_keyboard(sora_settings.aspect_ratio))
    await callback.answer()


@router.callback_query(F.data.startswith("sora.set.aspect_ratio:"))
async def sora_set_aspect_ratio(callback: CallbackQuery, state: FSMContext, user: User):
    aspect_ratio = callback.data.split(":")[1]
    await state.update_data(sora_aspect_ratio=aspect_ratio)
    await start_sora(callback, state, user)


@router.callback_query(F.data == "bot.luma")
async def start_luma(callback: CallbackQuery, state: FSMContext, user: User):
    luma_billing = get_video_model_billing("luma")
    text = (
        "üåô **Luma Dream Machine**\n\n"
        "Luma —Å–æ–∑–¥–∞—ë—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ –ø–æ –≤–∞—à–µ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n\n"
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** –°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {format_token_amount(luma_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Video:** –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ\n"
        "‚Ä¢ **Image-to-Video:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ –ò–õ–ò —Ñ–æ—Ç–æ**"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    # Clear old data when starting fresh session
    await state.update_data(service="luma", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.hailuo")
async def start_hailuo(callback: CallbackQuery, state: FSMContext, user: User):
    total_tokens = await get_available_tokens(user.id)
    hailuo_billing = get_video_model_billing("hailuo")
    videos_available = int(total_tokens / hailuo_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üé• **Hailuo ¬∑ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ**\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –Ω–∞ –≤–∞—à–µ–º –≤–∏–¥–µ–æ. "
        "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚îî –û–Ω–∞ —Å–ª–æ–≤–Ω–æ —Å–æ—à–ª–∞ —Å –∫–∏—Å—Ç–∏ –í–µ—Ä–º–µ–µ—Ä–∞, –µ–µ –∂–µ–º—á—É–∂–Ω–∞—è —Å–µ—Ä—å–≥–∞ –ø–æ–±–ª–µ—Å–∫–∏–≤–∞–µ—Ç. "
        "–≠—Ç–∏ –∑–∞–≥–∞–¥–æ—á–Ω—ã–µ –≥–ª–∞–∑–∞ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Ö–æ–ª—Å—Ç–∞, –≥—É–±—ã –∏–∑–≥–∏–±–∞—é—Ç—Å—è –≤ —Ç–æ–Ω–∫–æ–π, —ç–ª–µ–≥–∞–Ω—Ç–Ω–æ–π —É–ª—ã–±–∫–µ, –æ–±—Ä–∞—â–µ–Ω–Ω–æ–π –∫–æ –º–Ω–µ..\n"
        "‚îî –°–∏–Ω–µ–µ –ø–ª—é—à–µ–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –ø–æ–º–µ—à–∏–≤–∞–µ—Ç —Å—É–ø –≤ –∫–∞—Å—Ç—Ä—é–ª–µ, –æ—Ç –∫–æ—Ç–æ—Ä–æ–≥–æ –∏–¥–µ—Ç –ø–∞—Ä, "
        "–ø–æ—Å–ª–µ —á–µ–≥–æ —Ç–∞—Ä–µ–ª–∫–∞ —Å—É–ø–∞ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –ª—ë–¥, –∞ —Å–∏–Ω–µ–µ –ø–ª—é—à–µ–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–æ  —É–¥–∏–≤–ª—è–µ—Ç—Å—è —ç—Ç–æ–º—É..\n\n"
        "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏:**\n"
        "–í–µ—Ä—Å–∏—è: t2v-01\n"
        "–ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥: –≤–∫–ª—é—á–µ–Ω\n\n"
        "üìù –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –≤—ã –º–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–Ω—Ä–∞–≤–∏–≤—à—É—é—Å—è "
        "–∏–ª–∏ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–æ—Ç–æ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ —è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–º–µ–Ω—é –º–æ–¥–µ–ª—å –Ω–∞ t2v-01-director.\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –∑–∞–ø—Ä–æ—Å–æ–≤. "
        f"1 –∑–∞–ø—Ä–æ—Å = {format_token_amount(hailuo_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="hailuo", image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.kling_effects")
async def start_kling_effects(callback: CallbackQuery, state: FSMContext, user: User):
    """Show Kling Effects main menu with instructions."""
    kling_effects_billing = get_video_model_billing("kling-effects")
    total_tokens = await get_available_tokens(user.id)
    videos_available = int(total_tokens / kling_effects_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "‚ú® **Kling –≠—Ñ—Ñ–µ–∫—Ç—ã**\n\n"
        "–°–æ–∑–¥–∞–≤–∞–π—Ç–µ –ø–æ—Ç—Ä—è—Å–∞—é—â–∏–µ –≤–∏–¥–µ–æ —Å 199+ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏!\n\n"
        "**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
        "1Ô∏è‚É£ –í—ã–±–µ—Ä–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n"
        "2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ (1 –∏–ª–∏ 2 –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∞)\n"
        "3Ô∏è‚É£ –ü–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ —Å —ç—Ñ—Ñ–µ–∫—Ç–æ–º!\n\n"
        "**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤:**\n"
        "‚Ä¢ ‚≠ê –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ ‚Äî –ª—É—á—à–∏–µ —ç—Ñ—Ñ–µ–∫—Ç—ã\n"
        "‚Ä¢ üíÉ –¢–∞–Ω—Ü—ã ‚Äî —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è\n"
        "‚Ä¢ üêæ –ü–∏—Ç–æ–º—Ü—ã ‚Äî –¥–ª—è –≤–∞—à–∏—Ö –ª—é–±–∏–º—Ü–µ–≤\n"
        "‚Ä¢ ü¶∏ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è\n"
        "‚Ä¢ ü™Ω –ö—Ä—ã–ª—å—è –∏ –º–∞–≥–∏—è ‚Äî —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞\n"
        "‚Ä¢ üé¨ –ö–∏–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç—ã ‚Äî bullet time –∏ –¥—Ä.\n"
        "‚Ä¢ üë´ –î–ª—è –¥–≤–æ–∏—Ö ‚Äî —ç—Ñ—Ñ–µ–∫—Ç—ã –¥–ª—è 2 —Ñ–æ—Ç–æ\n"
        "‚Ä¢ üé® –°—Ç–∏–ª–∏ ‚Äî –∞–Ω–∏–º–µ, –∫–æ–º–∏–∫—Å—ã, 3D\n"
        "‚Ä¢ üòÇ –ó–∞–±–∞–≤–Ω—ã–µ ‚Äî –≤–µ—Å—ë–ª—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã\n"
        "‚Ä¢ üéâ –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ ‚Äî –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –∏ –¥—Ä.\n"
        "‚Ä¢ üéÑ –†–æ–∂–¥–µ—Å—Ç–≤–æ ‚Äî –∑–∏–º–Ω—è—è —Ç–µ–º–∞—Ç–∏–∫–∞\n"
        "‚Ä¢ üé¨ –î–µ–π—Å—Ç–≤–∏—è ‚Äî —Å–ø–æ—Ä—Ç –∏ –¥–≤–∏–∂–µ–Ω–∏–µ\n\n"
        f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(kling_effects_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"üîπ –î–æ—Å—Ç—É–ø–Ω–æ: {videos_available} –≤–∏–¥–µ–æ"
    )

    await state.clear()
    await state.update_data(service="kling_effects")

    try:
        await callback.message.edit_text(text, reply_markup=kling_effects_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_effects_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "kling_effects.categories")
async def kling_effects_categories(callback: CallbackQuery, state: FSMContext, user: User):
    """Show effect categories."""
    text = (
        "üìÅ **–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é —ç—Ñ—Ñ–µ–∫—Ç–æ–≤**\n\n"
        "–≠—Ñ—Ñ–µ–∫—Ç—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ç–µ–º–∞–º –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞."
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_effects_categories_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_effects_categories_keyboard())
    await callback.answer()


@router.callback_query(F.data.startswith("kling_effects.category:"))
async def kling_effects_show_category(callback: CallbackQuery, state: FSMContext, user: User):
    """Show effects in a category."""
    from app.services.video.kling_effects_service import EFFECT_CATEGORIES

    category = callback.data.split(":")[1]
    cat_data = EFFECT_CATEGORIES.get(category, {})
    cat_name = cat_data.get("name", category)

    text = f"üé≠ **{cat_name}**\n\n–í—ã–±–µ—Ä–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç:"

    try:
        await callback.message.edit_text(text, reply_markup=kling_effects_list_keyboard(category, page=0))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_effects_list_keyboard(category, page=0))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_effects.page:"))
async def kling_effects_page(callback: CallbackQuery, state: FSMContext, user: User):
    """Navigate effect pages."""
    from app.services.video.kling_effects_service import EFFECT_CATEGORIES

    parts = callback.data.split(":")
    category = parts[1]
    page = int(parts[2])

    cat_data = EFFECT_CATEGORIES.get(category, {})
    cat_name = cat_data.get("name", category)

    text = f"üé≠ **{cat_name}**\n\n–í—ã–±–µ—Ä–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç:"

    try:
        await callback.message.edit_text(text, reply_markup=kling_effects_list_keyboard(category, page=page))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_effects_list_keyboard(category, page=page))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_effects.select:"))
async def kling_effects_select(callback: CallbackQuery, state: FSMContext, user: User):
    """Select an effect and show instructions."""
    from app.services.video.kling_effects_service import (
        is_dual_image_effect,
        get_effect_display_name,
        DUAL_IMAGE_EFFECTS
    )

    effect_id = callback.data.split(":")[1]
    effect_name = get_effect_display_name(effect_id)
    is_dual = is_dual_image_effect(effect_id)

    kling_effects_billing = get_video_model_billing("kling-effects")

    if is_dual:
        text = (
            f"üé≠ **–≠—Ñ—Ñ–µ–∫—Ç: {effect_name}**\n\n"
            f"‚ö†Ô∏è –≠—Ç–æ—Ç —ç—Ñ—Ñ–µ–∫—Ç —Ç—Ä–µ–±—É–µ—Ç **2 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏**!\n\n"
            f"–ü–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤—å—Ç–µ 2 —Ñ–æ—Ç–æ:\n"
            f"‚Ä¢ –ü–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ ‚Äî –ª–µ–≤–∞—è —Å—Ç–æ—Ä–æ–Ω–∞\n"
            f"‚Ä¢ –í—Ç–æ—Ä–æ–µ —Ñ–æ—Ç–æ ‚Äî –ø—Ä–∞–≤–∞—è —Å—Ç–æ—Ä–æ–Ω–∞\n\n"
            f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(kling_effects_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤"
        )
    else:
        text = (
            f"üé≠ **–≠—Ñ—Ñ–µ–∫—Ç: {effect_name}**\n\n"
            f"–ü–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤—å—Ç–µ **1 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é**.\n\n"
            f"üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–æ—Ç–æ:\n"
            f"‚Ä¢ –§–æ—Ä–º–∞—Ç: JPG, JPEG, PNG\n"
            f"‚Ä¢ –†–∞–∑–º–µ—Ä: –¥–æ 10 –ú–ë\n"
            f"‚Ä¢ –ú–∏–Ω. —Ä–∞–∑–º–µ—Ä: 300x300 px\n"
            f"‚Ä¢ –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω: –æ—Ç 1:2.5 –¥–æ 2.5:1\n\n"
            f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(kling_effects_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤"
        )

    # Save selected effect to state
    await state.update_data(
        service="kling_effects",
        kling_effect_id=effect_id,
        kling_effect_name=effect_name,
        kling_effect_is_dual=is_dual,
        kling_effect_images=[]
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_effects_confirm_keyboard(effect_id))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_effects_confirm_keyboard(effect_id))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_effects.confirm:"))
async def kling_effects_confirm(callback: CallbackQuery, state: FSMContext, user: User):
    """Confirm effect and wait for photo(s)."""
    from app.services.video.kling_effects_service import is_dual_image_effect, get_effect_display_name

    effect_id = callback.data.split(":")[1]
    effect_name = get_effect_display_name(effect_id)
    is_dual = is_dual_image_effect(effect_id)

    # Set state to wait for photos
    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(
        service="kling_effects",
        kling_effect_id=effect_id,
        kling_effect_name=effect_name,
        kling_effect_is_dual=is_dual,
        kling_effect_images=[]
    )

    if is_dual:
        text = (
            f"üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ 2 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏**\n\n"
            f"–≠—Ñ—Ñ–µ–∫—Ç: {effect_name}\n\n"
            f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ø–æ –æ–¥–Ω–æ–º—É. –ü–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ –±—É–¥–µ—Ç —Å–ª–µ–≤–∞, –≤—Ç–æ—Ä–æ–µ ‚Äî —Å–ø—Ä–∞–≤–∞."
        )
    else:
        text = (
            f"üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ 1 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é**\n\n"
            f"–≠—Ñ—Ñ–µ–∫—Ç: {effect_name}\n\n"
            f"–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—á–Ω—ë—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ."
        )

    try:
        await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# Handler for when user clicks "Kling" from main menu
@router.callback_query(F.data == "bot.kling_main")
async def start_kling_choice(callback: CallbackQuery, state: FSMContext, user: User):
    """Open Kling AI choice menu."""
    text = (
        "üéû Kling AI\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å:\n\n"
        "üåÑ –°–æ–∑–¥–∞—Ç—å —Ñ–æ—Ç–æ ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
        "üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç—É/—Ñ–æ—Ç–æ\n"
        "üï∫ Motion Control ‚Äî –ø–µ—Ä–µ–Ω–æ—Å –¥–≤–∏–∂–µ–Ω–∏–π —Å –≤–∏–¥–µ–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_choice_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_choice_keyboard())
    await callback.answer()


# Handler for Kling Image generation
@router.callback_query(F.data == "bot.kling_image")
async def start_kling_image(callback: CallbackQuery, state: FSMContext, user: User):
    """Start Kling image generation with settings display."""
    await callback.answer()

    # Get or create Kling Image settings from FSM
    data = await state.get_data()
    kling_image_settings = KlingImageSettings.from_dict(data)

    # Calculate available generations
    total_tokens = await get_available_tokens(user.id)
    kling_image_billing = get_image_model_billing("kling-image")
    tokens_per_request = kling_image_billing.tokens_per_generation
    images_available = int(total_tokens / tokens_per_request) if total_tokens > 0 else 0

    text = (
        "üéû **Kling AI - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "üì∑ –í—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ —Å –ø–æ–¥–ø–∏—Å—å—é –¥–ª—è —Ä–µ–∂–∏–º–∞ image-to-image.\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ –ó–∞–∫–∞—Ç –Ω–∞–¥ –æ–∫–µ–∞–Ω–æ–º –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\n"
        "‚Ä¢ –§—É—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –≥–æ—Ä–æ–¥ —Å –ª–µ—Ç–∞—é—â–∏–º–∏ –º–∞—à–∏–Ω–∞–º–∏\n"
        "‚Ä¢ –ü–æ—Ä—Ç—Ä–µ—Ç –∫–æ—Ç–∞ –≤ –∫–æ—Ä–æ–ª–µ–≤—Å–∫–æ–π –æ–¥–µ–∂–¥–µ\n\n"
        f"‚öôÔ∏è **–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**\n"
        f"{kling_image_settings.get_display_settings()}\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {images_available} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n"
        f"1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ = {format_token_amount(tokens_per_request)} —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    # Save settings to state
    settings_dict = kling_image_settings.to_dict()
    await state.update_data(
        service="kling_image",
        reference_image_path=None,
        **settings_dict
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_image_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_image_main_keyboard())


# Handler for Kling Video generation (renamed from bot.kling)
@router.callback_query(F.data == "bot.kling_video")
async def start_kling_video(callback: CallbackQuery, state: FSMContext, user: User):
    """Start Kling video generation with settings."""
    # Get or create Kling settings from FSM
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    total_tokens = await get_available_tokens(user.id)
    tokens_per_request = get_kling_tokens_cost(kling_settings.version, kling_settings.duration)
    videos_available = int(total_tokens / tokens_per_request) if total_tokens > 0 else 0

    # Build version info text
    if kling_settings.version == "2.5":
        version_info = (
            "üì∑ –í—ã –≤—ã–±—Ä–∞–ª–∏ –≤–µ—Ä—Å–∏—é 2.5 Turbo: —ç—Ç–∞ –≤–µ—Ä—Å–∏—è –º–æ–∂–µ—Ç –ø—Ä–∏–Ω—è—Ç—å –¥–æ –¥–≤—É—Ö —Ñ–æ—Ç–æ "
            "—Å –ø—Ä–æ–º–ø—Ç–æ–º –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä / –∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä."
        )
    else:
        version_info = f"üì∑ –í—ã –≤—ã–±—Ä–∞–ª–∏ –≤–µ—Ä—Å–∏—é {kling_settings.version}."

    text = (
        "üéû Kling ¬∑ –º–µ–Ω—è–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –Ω–∞ –≤–∞—à–µ–º –≤–∏–¥–µ–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚îî –û–∂–∏–≤–∏ –º–æ—ë —Ñ–æ—Ç–æ –∏ —Å–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã —è —É–ª—ã–±–∞–ª—Å—è –∏ –º–∞—Ö–∞–ª —Ä—É–∫–æ–π –≤ –∫–∞–º–µ—Ä—É. (–ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–≤–æ—ë —Ñ–æ—Ç–æ –∏–ª–∏ —Ñ–æ—Ç–æ –±–ª–∏–∑–∫–æ–≥–æ).\n"
        "‚îî –ù–µ–æ–Ω–æ–≤–æ–µ –∏–∞–π–¥–∑—é—Ü—É: –∫–∏–±–µ—Ä–ø–∞–Ω–∫-—Å–∞–º—É—Ä–∞–π –≤ –¥–µ–π—Å—Ç–≤–∏–∏. (–ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–≤–æ—ë —Ñ–æ—Ç–æ).\n\n"
        f"{version_info}\n\n"
        f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–≤—ã–±—Ä–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏):\n"
        f"{kling_settings.get_display_settings()}\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –∑–∞–ø—Ä–æ—Å–æ–≤.\n"
        f"1 –∑–∞–ø—Ä–æ—Å = {format_token_amount(tokens_per_request)} —Ç–æ–∫–µ–Ω–æ–≤."
    )

    await state.set_state(MediaState.kling_waiting_for_prompt)
    # Save Kling settings and reset images
    settings_dict = kling_settings.to_dict()
    settings_dict["kling_images"] = []  # Reset collected images
    await state.update_data(
        service="kling",
        image_path=None,
        photo_caption_prompt=None,
        **settings_dict
    )

    # Try to edit message, fall back to answer if it fails (e.g., message is a photo)
    try:
        await callback.message.edit_text(text, reply_markup=kling_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_main_keyboard())
    await callback.answer()


# ======================
# KLING SETTINGS HANDLERS
# ======================

@router.callback_query(F.data == "kling.settings")
async def kling_settings_menu(callback: CallbackQuery, state: FSMContext, user: User):
    """Show Kling settings menu."""
    text = (
        "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ Kling\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_settings_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_settings_keyboard())
    await callback.answer()


@router.callback_query(F.data == "kling.settings.aspect_ratio")
async def kling_settings_aspect_ratio(callback: CallbackQuery, state: FSMContext, user: User):
    """Show aspect ratio selection for Kling."""
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    text = (
        "üìê –í—ã–±–µ—Ä–∏—Ç–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω —É –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ –≤–∏–¥–µ–æ –≤ Kling.\n\n"
        "1:1 ‚Äî –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ, –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã–π –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ VK, "
        "–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –ø–æ—Å—Ç–æ–≤ –∏ —Ä–µ–∫–ª–∞–º—ã. –≠—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–∞–≤–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ø–æ —à–∏—Ä–∏–Ω–µ "
        "–∏ –≤—ã—Å–æ—Ç–µ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ —É–¥–æ–±–Ω—ã–º –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤.\n\n"
        "16:9 ‚Äî –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ –¥–ª—è –∫–∏–Ω–æ, "
        "YouTube –∏ VK Video.\n\n"
        "9:16 ‚Äî –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –∏–¥–µ–∞–ª—å–Ω—ã–π –¥–ª—è Stories –∏ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º."
    )

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_aspect_ratio_keyboard(kling_settings.aspect_ratio)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_aspect_ratio_keyboard(kling_settings.aspect_ratio)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling.set.aspect_ratio:"))
async def kling_set_aspect_ratio(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling aspect ratio."""
    aspect_ratio = callback.data.split(":")[1]

    await state.update_data(kling_aspect_ratio=aspect_ratio)

    await callback.answer(f"‚úÖ –§–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {aspect_ratio}")
    # Return to main Kling menu
    await start_kling_video(callback, state, user)


@router.callback_query(F.data == "kling.settings.duration")
async def kling_settings_duration(callback: CallbackQuery, state: FSMContext, user: User):
    """Show duration selection for Kling."""
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    text = "üïì –í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ –≤ Kling."

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_duration_keyboard(kling_settings.duration)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_duration_keyboard(kling_settings.duration)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling.set.duration:"))
async def kling_set_duration(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling duration."""
    duration = int(callback.data.split(":")[1])

    await state.update_data(kling_duration=duration)

    await callback.answer(f"‚úÖ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {duration} —Å–µ–∫—É–Ω–¥")
    # Return to main Kling menu
    await start_kling_video(callback, state, user)


@router.callback_query(F.data == "kling.settings.version")
async def kling_settings_version(callback: CallbackQuery, state: FSMContext, user: User):
    """Show version selection for Kling."""
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    text = "üî¢ –í—ã–±–µ—Ä–∏—Ç–µ –≤–µ—Ä—Å–∏—é Kling."

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_version_keyboard(kling_settings.version)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_version_keyboard(kling_settings.version)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling.set.version:"))
async def kling_set_version(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling version."""
    version = callback.data.split(":")[1]

    await state.update_data(kling_version=version)

    await callback.answer(f"‚úÖ –í–µ—Ä—Å–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {version}")
    # Return to main Kling menu
    await start_kling_video(callback, state, user)


@router.callback_query(F.data == "kling.settings.auto_translate")
async def kling_settings_auto_translate(callback: CallbackQuery, state: FSMContext, user: User):
    """Show auto-translate selection for Kling."""
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    text = "üî§ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Å –ª—é–±–æ–≥–æ —è–∑—ã–∫–∞?"

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_auto_translate_keyboard(kling_settings.auto_translate)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_auto_translate_keyboard(kling_settings.auto_translate)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling.set.auto_translate:"))
async def kling_set_auto_translate(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling auto-translate."""
    value = callback.data.split(":")[1] == "yes"

    await state.update_data(kling_auto_translate=value)

    status = "–≤–∫–ª—é—á–µ–Ω" if value else "–≤—ã–∫–ª—é—á–µ–Ω"
    await callback.answer(f"‚úÖ –ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥ {status}")
    # Return to main Kling menu
    await start_kling_video(callback, state, user)


# ======================
# KLING IMAGE SETTINGS HANDLERS
# ======================

@router.callback_query(F.data == "kling_image.settings")
async def kling_image_settings_menu(callback: CallbackQuery, state: FSMContext, user: User):
    """Show Kling image settings menu."""
    text = (
        "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Kling**\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_image_settings_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_image_settings_keyboard())
    await callback.answer()


@router.callback_query(F.data == "kling_image.settings.aspect_ratio")
async def kling_image_settings_aspect_ratio(callback: CallbackQuery, state: FSMContext, user: User):
    """Show aspect ratio selection for Kling image."""
    data = await state.get_data()
    kling_image_settings = KlingImageSettings.from_dict(data)

    text = (
        "üìê **–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è**\n\n"
        "‚Ä¢ 1:1 ‚Äî –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π\n"
        "‚Ä¢ 16:9 ‚Äî —à–∏—Ä–æ–∫–æ—Ñ–æ—Ä–º–∞—Ç–Ω—ã–π\n"
        "‚Ä¢ 9:16 ‚Äî –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π\n"
        "‚Ä¢ 4:3 ‚Äî –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π\n"
        "‚Ä¢ 3:4 ‚Äî –ø–æ—Ä—Ç—Ä–µ—Ç–Ω—ã–π"
    )

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_image_aspect_ratio_keyboard(kling_image_settings.aspect_ratio)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_image_aspect_ratio_keyboard(kling_image_settings.aspect_ratio)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling_image.set.aspect_ratio:"))
async def kling_image_set_aspect_ratio(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling image aspect ratio."""
    ratio = callback.data.split(":")[1]

    await state.update_data(kling_image_aspect_ratio=ratio)

    await callback.answer(f"‚úÖ –§–æ—Ä–º–∞—Ç: {ratio}")
    # Return to main Kling image menu
    await start_kling_image(callback, state, user)


@router.callback_query(F.data == "kling_image.settings.model")
async def kling_image_settings_model(callback: CallbackQuery, state: FSMContext, user: User):
    """Show model selection for Kling image."""
    data = await state.get_data()
    kling_image_settings = KlingImageSettings.from_dict(data)

    text = (
        "üî¢ **–í—ã–±–µ—Ä–∏—Ç–µ –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏**\n\n"
        "‚Ä¢ **Kling v1** ‚Äî –±–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è\n"
        "‚Ä¢ **Kling v1.5** ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ (–ª–∏—Ü–æ/–æ–±—ä–µ–∫—Ç)\n"
        "‚Ä¢ **Kling v2** ‚Äî —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
    )

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_image_model_keyboard(kling_image_settings.model)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_image_model_keyboard(kling_image_settings.model)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling_image.set.model:"))
async def kling_image_set_model(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling image model."""
    model = callback.data.split(":")[1]

    await state.update_data(kling_image_model=model)

    model_names = {
        "kling-v1": "Kling v1",
        "kling-v1-5": "Kling v1.5",
        "kling-v2": "Kling v2",
    }
    await callback.answer(f"‚úÖ –ú–æ–¥–µ–ª—å: {model_names.get(model, model)}")
    # Return to main Kling image menu
    await start_kling_image(callback, state, user)


@router.callback_query(F.data == "kling_image.settings.resolution")
async def kling_image_settings_resolution(callback: CallbackQuery, state: FSMContext, user: User):
    """Show resolution selection for Kling image."""
    data = await state.get_data()
    kling_image_settings = KlingImageSettings.from_dict(data)

    text = (
        "üìè **–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ**\n\n"
        "‚Ä¢ **1K** ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–±—ã—Å—Ç—Ä–µ–µ)\n"
        "‚Ä¢ **2K** ‚Äî –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π)"
    )

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_image_resolution_keyboard(kling_image_settings.resolution)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_image_resolution_keyboard(kling_image_settings.resolution)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling_image.set.resolution:"))
async def kling_image_set_resolution(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling image resolution."""
    resolution = callback.data.split(":")[1]

    await state.update_data(kling_image_resolution=resolution)

    res_names = {"1k": "1K", "2k": "2K"}
    await callback.answer(f"‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {res_names.get(resolution, resolution)}")
    # Return to main Kling image menu
    await start_kling_image(callback, state, user)


@router.callback_query(F.data == "kling_image.settings.auto_translate")
async def kling_image_settings_auto_translate(callback: CallbackQuery, state: FSMContext, user: User):
    """Show auto-translate selection for Kling image."""
    data = await state.get_data()
    kling_image_settings = KlingImageSettings.from_dict(data)

    text = "üî§ **–ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥**\n\n–ü–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏?"

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_image_auto_translate_keyboard(kling_image_settings.auto_translate)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_image_auto_translate_keyboard(kling_image_settings.auto_translate)
        )
    await callback.answer()


@router.callback_query(F.data.startswith("kling_image.set.auto_translate:"))
async def kling_image_set_auto_translate(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Kling image auto-translate."""
    value = callback.data.split(":")[1] == "yes"

    await state.update_data(kling_image_auto_translate=value)

    status = "–≤–∫–ª—é—á–µ–Ω" if value else "–≤—ã–∫–ª—é—á–µ–Ω"
    await callback.answer(f"‚úÖ –ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥ {status}")
    # Return to main Kling image menu
    await start_kling_image(callback, state, user)


# ======================
# IMAGE GENERATION
# ======================

@router.callback_query(F.data == "bot.gpt_image")
async def start_gpt_image(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)
    dalle_billing = get_image_model_billing("dalle3")
    total_tokens = await get_available_tokens(user.id)
    requests_available = int(total_tokens / dalle_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üí• **GPT Image 1.5 ¬∑ –ª—É—á—à–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "üìñ **–ü–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ:**\n"
        "‚Äì –≠—Ç–∞ –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∫–∞–∂–¥–æ–µ –≤–∞—à–µ —Å–ª–æ–≤–æ: –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏ –ª—é–±–æ–º —è–∑—ã–∫–µ;\n"
        "‚Äì –ü–æ–ø—Ä–æ—Å–∏—Ç–µ –µ—ë, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å—Ç–µ—Ä —Å –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ–º –Ω–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ (—É–∫–∞–∂–∏—Ç–µ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω—ë–º) –∏–ª–∏ –∫—Ä—É—Ç—ã—Ö –∫–æ—Ç–æ–≤ –≤ –æ—á–∫–∞—Ö (–∫–∞–∫ –ª—é–¥–∏ –≤ —á–µ—Ä–Ω–æ–º).\n\n"
        "üì∑ **–ú–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –¥–æ 3 —Ñ–æ—Ç–æ –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ c –∑–∞–ø—Ä–æ—Å–æ–º:**\n"
        "‚Äì –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ø—Ä–æ—Å–∏—Ç–µ –∏—Ö —Å–æ–µ–¥–∏–Ω–∏—Ç—å –≤–æ —á—Ç–æ-—Ç–æ.\n\n"
        "üíÖ **–£–∫–∞–∑—ã–≤–∞–π—Ç–µ —Å—Ç–∏–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ:**\n"
        "‚Äì –ù–∞–ø—Ä–∏–º–µ—Ä: —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Å—Ç–∏–ª—å, —Å—Ç–∏–ª—å —Å—Ç—É–¥–∏–∏ ghilbi (–º–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Å–≤–æ–µ —Ñ–æ—Ç–æ) –∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π;\n\n"
        "üìê **–§–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ:** 1:1\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {requests_available} –∑–∞–ø—Ä–æ—Å–æ–≤. 1 —Ñ–æ—Ç–æ = {format_token_amount(dalle_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ**"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="dalle", reference_image_path=None, photo_caption_prompt=None)

    await callback.message.answer(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.nano")
async def start_nano(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)
    nano_billing = get_image_model_billing("nano-banana-image")

    text = (
        "üçå **Nano Banana (Gemini 2.5 Flash Image)**\n\n"
        "Gemini 2.5 Flash Image —Å–æ–∑–¥–∞—ë—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n\n"
        "üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: 1:1, 16:9, 9:16, 3:4, 4:3\n"
        "‚Ä¢ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n"
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {format_token_amount(nano_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ**\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Image-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ **–æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ** + –æ–ø–∏—Å–∞–Ω–∏–µ\n"
        "‚Ä¢ **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –ö–Ω–æ–ø–∫–∞ \"üé® –°–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\" (2-10 —à—Ç.)\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)**\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã text-to-image:**\n"
        "‚Ä¢ \"–ö–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ —Å—Ä–µ–¥–∏ –∑–≤—ë–∑–¥\"\n"
        "‚Ä¢ \"–ó–∞–∫–∞—Ç –Ω–∞ –±–µ—Ä–µ–≥—É –æ–∫–µ–∞–Ω–∞ —Å –ø–∞–ª—å–º–∞–º–∏\"\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã image-to-image:**\n"
        "‚Ä¢ –§–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–Ω–∏–º–µ —Å—Ç–∏–ª—å —Å —è—Ä–∫–∏–º–∏ –∫—Ä–∞—Å–∫–∞–º–∏\"\n"
        "‚Ä¢ –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ + \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –º–∞—Å–ª—è–Ω–æ–π –∂–∏–≤–æ–ø–∏—Å–∏ –í–∞–Ω –ì–æ–≥–∞\"\n"
        "‚Ä¢ –§–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ —Ñ—ç–Ω—Ç–µ–∑–∏ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é —Å –º–∞–≥–∏—á–µ—Å–∫–∏–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)

    # Get existing data or set defaults
    data = await state.get_data()
    current_ratio = data.get("nano_aspect_ratio", "auto")

    await state.update_data(
        service="nano_banana",
        nano_is_pro=False,
        reference_image_path=None,
        reference_image_paths=[],
        photo_caption_prompt=None,
        multi_images_count=0,
        nano_aspect_ratio=current_ratio  # Preserve existing format or set default
    )

    await callback.message.answer(text, reply_markup=nano_banana_keyboard(is_pro=False), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.nano_pro")
async def start_nano_pro(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)
    banana_billing = get_image_model_billing("banana-pro")

    text = (
        "üçå‚ú® **Banana PRO (Gemini 3 Pro Image)**\n\n"
        "Gemini 3 Pro Image - —ç—Ç–æ –Ω–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n\n"
        "üìä **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: 1:1, 16:9, 9:16, 4:3, 3:4 –∏ –¥—Ä—É–≥–∏–µ\n"
        "‚Ä¢ –†–∞–∑–º–µ—Ä—ã: 2K, 4K\n"
        "‚Ä¢ –í—ã—Å–æ—á–∞–π—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
        "‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö\n\n"
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {format_token_amount(banana_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ**\n\n"
        "üé® **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**\n"
        "‚Ä¢ **Text-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"
        "‚Ä¢ **Image-to-Image:** –û—Ç–ø—Ä–∞–≤—å—Ç–µ **–æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ** + –æ–ø–∏—Å–∞–Ω–∏–µ\n"
        "‚Ä¢ **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –ö–Ω–æ–ø–∫–∞ \"üé® –°–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\" (2-10 —à—Ç.)\n"
        "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Google Search –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ò–õ–ò —Ñ–æ—Ç–æ (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)**\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ò–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞ –æ —Ç–µ–∫—É—â–µ–π –ø–æ–≥–æ–¥–µ –≤ –¢–æ–∫–∏–æ\"\n"
        "‚Ä¢ \"–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –∫–æ—Ç–∞ –≤ –∫–æ—Å–º–æ—Å–µ –≤ 4K\"\n"
        "‚Ä¢ –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ + \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)

    # Get existing data or set defaults
    data = await state.get_data()
    current_ratio = data.get("nano_aspect_ratio", "auto")

    await state.update_data(
        service="nano_banana",
        nano_is_pro=True,
        reference_image_path=None,
        reference_image_paths=[],
        photo_caption_prompt=None,
        multi_images_count=0,
        nano_aspect_ratio=current_ratio  # Preserve existing format or set default
    )

    await callback.message.answer(text, reply_markup=nano_banana_keyboard(is_pro=True), parse_mode="Markdown")
    await callback.answer()


@router.callback_query(F.data == "bot.midjourney")
async def start_midjourney(callback: CallbackQuery, state: FSMContext, user: User):
    """Midjourney image generation."""
    from app.bot.keyboards.inline import midjourney_main_keyboard

    await cleanup_temp_images(state)

    mj_billing = get_image_model_billing("midjourney")
    total_tokens = await get_available_tokens(user.id)
    images_available = int(total_tokens / mj_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üåÜ **Midjourney ¬∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å.\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ Futuristic cityscape at sunset, cinematic lighting, 8k\n"
        "‚Ä¢ A cute cat wearing a space helmet, floating in galaxy\n"
        "‚Ä¢ Portrait of a samurai in neon rain, cyberpunk style\n\n"
        "‚öôÔ∏è **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
        "–í–µ—Ä—Å–∏—è: 7\n"
        "–°–∫–æ—Ä–æ—Å—Ç—å: fast\n"
        "–§–æ—Ä–º–∞—Ç: 16:9\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {images_available} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. "
        f"1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ = {format_token_amount(mj_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="midjourney", reference_image_path=None, photo_caption_prompt=None)

    try:
        await callback.message.edit_text(text, reply_markup=midjourney_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=midjourney_main_keyboard())
    await callback.answer()


async def start_midjourney_video(callback: CallbackQuery, state: FSMContext, user: User):
    """Midjourney Video (image-to-video) generation."""
    from app.bot.keyboards.inline import midjourney_video_main_keyboard

    mj_billing = get_image_model_billing("midjourney")
    total_tokens = await get_available_tokens(user.id)
    images_available = int(total_tokens / mj_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üåÜ **Midjourney Video ¬∑ Image-to-Video**\n\n"
        "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ.\n\n"
        "**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
        "1. –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Ñ–æ—Ç–æ\n"
        "2. –î–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è/–¥–µ–π—Å—Ç–≤–∏—è –≤ –ø–æ–¥–ø–∏—Å–∏\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤:**\n"
        "‚Ä¢ Camera slowly zooms in, wind blows through hair\n"
        "‚Ä¢ The character turns and smiles at the camera\n\n"
        f"üîπ –ë–∞–ª–∞–Ω—Å–∞ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {images_available} –∑–∞–ø—Ä–æ—Å–æ–≤. "
        f"1 –∑–∞–ø—Ä–æ—Å = {format_token_amount(mj_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="midjourney_video", image_path=None, photo_caption_prompt=None)

    try:
        await callback.message.edit_text(text, reply_markup=midjourney_video_main_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=midjourney_video_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.recraft")
async def start_recraft(callback: CallbackQuery, state: FSMContext, user: User):
    """Recraft AI image generation."""
    # Clean up any old images
    await cleanup_temp_images(state)
    recraft_billing = get_image_model_billing("recraft")
    total_tokens = await get_available_tokens(user.id)
    requests_available = int(total_tokens / recraft_billing.tokens_per_generation) if total_tokens > 0 else 0

    text = (
        "üé® **Recraft ¬∑ –Ω–∞—Ä–∏—Å—É–µ–º —á—Ç–æ-–Ω–∏–±—É–¥—å?**\n\n"
        "–ù–∞–ø–∏—à–∏—Ç–µ –º–Ω–µ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –Ω–∞ –≤–∞—à–µ–º —Ñ–æ—Ç–æ. –≠—Ç–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –Ω–æ –µ—Å–ª–∏ –≤–∞–º —Ç–∞–∫ –Ω–µ –∫–∞–∂–µ—Ç—Å—è ‚Äî –≤–∫–ª—é—á–∏—Ç–µ –∞–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥.\n"
        "–í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–æ—Ç–æ –∫ –∑–∞–ø—Ä–æ—Å—É –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –µ–≥–æ –∏–∑–º–µ–Ω–∏—Ç—å —Å–æ–≥–ª–∞—Å–Ω–æ –≤–∞—à–µ–º—É –ø—Ä–æ–º–ø—Ç—É.\n\n"
        "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏**\n"
        "–°—Ç–∏–ª—å: –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
        "–†–∞–∑–º–µ—Ä: 1024x1024\n"
        "–ê–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥: –æ—Ç–∫–ª—é—á–µ–Ω\n\n"
        "üì∏ –í—ã –≤—ã–±—Ä–∞–ª–∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Å—Ç–∏–ª—å, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—É–¥—É—Ç –ø–æ–ª—É—á–∞—Ç—Å—è –±–æ–ª–µ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã–º–∏ –∫ —Ä–µ–∞–ª—å–Ω—ã–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º.\n\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {requests_available} –∑–∞–ø—Ä–æ—Å–æ–≤. 1 —Ñ–æ—Ç–æ = {format_token_amount(recraft_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤.\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è**"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="recraft", reference_image_path=None, photo_caption_prompt=None)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


# ======================
# AUDIO SERVICES
# ======================

# Note: Suno handler moved to suno_handler.py for better organization and step-by-step creation


@router.callback_query(F.data == "bot.whisper")
async def start_whisper(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üéô **Whisper - –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–∞**\n\n"
        "OpenAI Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –µ—ë –≤ —Ç–µ–∫—Å—Ç.\n\n"
        "üìä **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        "‚Ä¢ –¢–æ—á–Ω–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö\n"
        "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤\n"
        "‚Ä¢ –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~1,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ\n\n"
        "üéµ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ**"
    )

    await state.set_state(MediaState.waiting_for_whisper_audio)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.whisper_tts")
async def start_tts(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üó£ **OpenAI TTS ‚Äì Text to Speech**\n\n"
        "–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ—á—å.\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~200 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å\n\n"
        "üé§ **–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞:**\n"
        "‚Ä¢ alloy - –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ echo - –ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ fable - –ë—Ä–∏—Ç–∞–Ω—Å–∫–∏–π –∞–∫—Ü–µ–Ω—Ç\n"
        "‚Ä¢ onyx - –ì–ª—É–±–æ–∫–∏–π –º—É–∂—Å–∫–æ–π\n"
        "‚Ä¢ nova - –ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å\n"
        "‚Ä¢ shimmer - –ú—è–≥–∫–∏–π –∂–µ–Ω—Å–∫–∏–π\n\n"
        "‚úèÔ∏è **–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏**"
    )

    await state.set_state(MediaState.waiting_for_audio_prompt)
    await state.update_data(service="tts")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.gpt_vision")
async def start_gpt_vision(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "üëÅ **GPT Image 1 - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**\n\n"
        "GPT-4 Vision –º–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∏—Ö.\n\n"
        "üìä **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        "‚Ä¢ –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
        "‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞\n"
        "‚Ä¢ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n"
        "‚Ä¢ –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~1,000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å\n\n"
        "üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞**"
    )

    await state.set_state(MediaState.waiting_for_vision_image)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# IMAGE PROCESSING
# ======================

@router.callback_query(F.data == "bot.pi_upscale")
async def start_upscale(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ\n\n"
        "–£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏ —É–ª—É—á—à–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "–°—Ç–æ–∏–º–æ—Å—Ç—å: ~2,000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
    )

    await state.set_state(MediaState.waiting_for_upscale_image)
    await state.update_data(service="upscale")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_remb")
async def start_remove_bg(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞\n\n"
        "–°—Ç–æ–∏–º–æ—Å—Ç—å: ~500 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞."
    )

    await state.set_state(MediaState.waiting_for_image)
    await state.update_data(service="remove_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_repb")
async def start_replace_bg(callback: CallbackQuery, state: FSMContext, user: User):
    # Clean up any old images
    await cleanup_temp_images(state)

    text = (
        "üñº **–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash Image)**\n\n"
        "–£–º–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ —Å –ø–æ–º–æ—â—å—é –ò–ò Gemini.\n\n"
        "üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~2,000 —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        "üìù **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ\n"
        "2. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–æ–Ω–∞\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ë–µ–ª—ã–π —Ñ–æ–Ω\"\n"
        "‚Ä¢ \"–ü–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏ –Ω–∞ –∑–∞–∫–∞—Ç–µ\"\n"
        "‚Ä¢ \"–ì–æ—Ä–æ–¥—Å–∫–∞—è —É–ª–∏—Ü–∞ –Ω–æ—á—å—é\"\n"
        "‚Ä¢ \"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç –æ—Ç —Å–∏–Ω–µ–≥–æ –∫ —Ñ–∏–æ–ª–µ—Ç–æ–≤–æ–º—É\"\n\n"
        "üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞**"
    )

    await state.set_state(MediaState.waiting_for_replace_bg_image)
    await state.update_data(service="replace_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard(), parse_mode="Markdown")
    await callback.answer()


# ======================
# FSM HANDLERS - VIDEO
# ======================

@router.message(MediaState.waiting_for_video_prompt, F.photo)
async def process_video_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-video generation."""
    data = await state.get_data()
    service_name = data.get("service", "veo")

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º TempFileManager –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
    # –≤–º–µ—Å—Ç–æ file_id –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
    temp_path = get_temp_file_path(prefix="video_input", suffix=".jpg", user_id=user.id)

    await message.bot.download_file(file.file_path, temp_path)

    # Save absolute image path to state
    await state.update_data(image_path=str(temp_path))

    # Check if photo has caption (description)
    if message.caption and message.caption.strip():
        # User sent photo with description - process immediately
        # Save caption as prompt in state
        await state.update_data(photo_caption_prompt=message.caption.strip())

        # Route to appropriate video service
        if service_name == "veo":
            await process_veo_video(message, user, state)
        elif service_name == "sora":
            await process_sora_video(message, user, state)
        elif service_name == "luma":
            await process_luma_video(message, user, state)
        elif service_name == "hailuo":
            await process_hailuo_video(message, user, state)
        elif service_name == "kling":
            await process_kling_video(message, user, state)
        elif service_name == "kling_effects":
            await process_kling_effects(message, user, state)
        elif service_name == "midjourney_video":
            await process_midjourney_video(message, user, state)
    else:
        # No caption
        # For kling_effects, we don't need a caption - the effect ID is the action
        if service_name == "kling_effects":
            await process_kling_effects(message, user, state)
        else:
            # Ask for description for other services
            await message.answer(
                "‚úÖ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
                "üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
                "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ \"–û–∂–∏–≤–∏ —ç—Ç–æ —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤—å –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ\"\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã –≤–æ–ª–æ—Å—ã —Ä–∞–∑–≤–µ–≤–∞–ª–∏—Å—å –Ω–∞ –≤–µ—Ç—Ä—É\"\n"
                "‚Ä¢ \"–î–æ–±–∞–≤—å –ø–∞–¥–∞—é—â–∏–µ —Å–Ω–µ–∂–∏–Ω–∫–∏ –∏ –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã\""
            )


@router.message(MediaState.waiting_for_video_prompt, F.text)
async def process_video_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    # Commands should NOT be processed as prompts
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    # Check message length (max 2000 characters)
    if message.text and len(message.text) > 2000:
        await message.answer(
            "‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 2000 —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    data = await state.get_data()
    service_name = data.get("service", "sora")

    display_names = {
        "veo": "Veo 3.1",
        "sora": "Sora 2",
        "luma": "Luma Dream Machine",
        "hailuo": "Hailuo",
        "kling": "Kling AI",
        "kling_effects": "Kling Effects",
        "midjourney_video": "Midjourney Video",
    }
    display = display_names.get(service_name, service_name)

    # Route to appropriate video service
    if service_name == "veo":
        await process_veo_video(message, user, state)
    elif service_name == "sora":
        await process_sora_video(message, user, state)
    elif service_name == "luma":
        await process_luma_video(message, user, state)
    elif service_name == "hailuo":
        await process_hailuo_video(message, user, state)
    elif service_name == "kling" or service_name == "kling_effects":
        await process_kling_video(message, user, state, is_effects=(service_name == "kling_effects"))
    elif service_name == "midjourney_video":
        await process_midjourney_video(message, user, state)
    else:
        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


# ======================
# FSM HANDLERS - KLING VIDEO GENERATION
# ======================

@router.message(MediaState.kling_waiting_for_prompt, F.photo)
async def process_kling_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for Kling video generation (supports up to 2 photos for v2.5)."""
    data = await state.get_data()
    kling_settings = KlingSettings.from_dict(data)

    # Get current images list
    kling_images = data.get("kling_images", [])

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    temp_path = get_temp_file_path(prefix="kling_input", suffix=".jpg", user_id=user.id)
    await message.bot.download_file(file.file_path, temp_path)

    # Resize image if needed
    resize_image_if_needed(str(temp_path), max_size_mb=10.0, max_dimension=2048)

    # Add image to list
    kling_images.append(str(temp_path))
    await state.update_data(kling_images=kling_images)

    # Check max images based on version
    max_images = 2 if kling_settings.version == "2.5" else 1

    if len(kling_images) > max_images:
        # Too many images - remove the last one and warn
        cleanup_temp_file(str(temp_path))
        kling_images.pop()
        await state.update_data(kling_images=kling_images)

        if max_images == 1:
            await message.answer(
                f"‚ö†Ô∏è –í–µ—Ä—Å–∏—è {kling_settings.version} –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n"
                "–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ—Å—å –Ω–∞ –≤–µ—Ä—Å–∏—é 2.5 –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–≤—É—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
            )
        else:
            await message.answer("‚ö†Ô∏è –ú–∞–∫—Å–∏–º—É–º 2 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤–µ—Ä—Å–∏–∏ 2.5.")
        return

    # Check if photo has caption (description) - process immediately
    if message.caption and message.caption.strip():
        await state.update_data(photo_caption_prompt=message.caption.strip())
        await process_kling_video(message, user, state)
    else:
        # No caption - show status
        photos_count = len(kling_images)

        if kling_settings.version == "2.5":
            if photos_count == 1:
                await message.answer(
                    f"‚úÖ –§–æ—Ç–æ {photos_count} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ! (–Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä)\n\n"
                    "üì∏ –í—ã –º–æ–∂–µ—Ç–µ:\n"
                    "‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ç–æ—Ä–æ–µ —Ñ–æ—Ç–æ (–∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä)\n"
                    "‚Ä¢ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n\n"
                    "üí° –í –≤–µ—Ä—Å–∏–∏ 2.5 –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 2 —Ñ–æ—Ç–æ –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—ã–π –∏ –∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä—ã."
                )
            else:
                await message.answer(
                    f"‚úÖ –§–æ—Ç–æ {photos_count} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ! (–∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä)\n\n"
                    "üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ."
                )
        else:
            await message.answer(
                "‚úÖ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
                "üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å."
            )


@router.message(MediaState.kling_waiting_for_prompt, F.text)
async def process_kling_prompt(message: Message, state: FSMContext, user: User):
    """Process Kling video generation prompt."""
    # Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    # Check message length (max 2500 characters for Kling)
    if message.text and len(message.text) > 2500:
        await message.answer(
            "‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 2500 —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    # Process Kling video generation
    await process_kling_video(message, user, state)


async def process_veo_video(message: Message, user: User, state: FSMContext):
    """Process Veo video generation with cost-guard protection."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    # COST-GUARD: –æ—Ü–µ–Ω–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å —ç–∫–æ–Ω–æ–º-—Ä–µ–∂–∏–º–æ–º (4 —Å–µ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å duration, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –º–∏–Ω–∏–º—É–º
    duration = data.get("duration", None)  # None = –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω default –∏–∑ cost_guard
    cost_estimate = cost_guard.estimate_cost("veo-3.1", duration=duration)

    # COST-GUARD: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å rate limit
    allowed, rate_error = await cost_guard.check_rate_limit(user.id, "veo-3.1")
    if not allowed:
        # Clean up image if exists
        cleanup_temp_file(image_path)
        await message.answer(rate_error)
        await state.clear()
        return

    estimated_tokens = cost_estimate.estimated_tokens
    actual_duration = cost_estimate.duration_seconds

    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    cost_warning = (
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Veo 3.1:**\n\n"
        f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {actual_duration} —Å–µ–∫\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤ (‚âà${cost_estimate.estimated_cost_usd:.2f})\n\n"
    )

    if cost_estimate.warning_message:
        cost_warning += f"{cost_estimate.warning_message}\n\n"

    # COST-GUARD: —Ç—Ä–µ–±–æ–≤–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è –¥–æ—Ä–æ–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if cost_estimate.requires_confirmation:
        # TODO: –í –±—É–¥—É—â–µ–º –¥–æ–±–∞–≤–∏—Ç—å inline –∫–Ω–æ–ø–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        cost_warning += "‚ö†Ô∏è –≠—Ç–æ –¥–æ—Ä–æ–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è! –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø—Ä–æ–º–ø—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.\n\n"

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            cleanup_temp_file(image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ!\n\n"
                f"{cost_warning}"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send improved progress message with cost info
    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(
        f"üé¨ –°–æ–∑–¥–∞—é –≤–∏–¥–µ–æ –≤ Veo 3.1 ({mode_text})...\n\n"
        f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {actual_duration} —Å–µ–∫\n"
        f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        f"‚è± –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~2-10 –º–∏–Ω—É—Ç.\n"
        f"‚ö°Ô∏è –û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–µ—Ä–≤–∏—Å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –ø–æ—è–≤–∏—Ç—å—Å—è –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ."
    )

    # Create service
    veo_service = VeoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º actual_duration –∏–∑ cost_estimate (—ç–∫–æ–Ω–æ–º-—Ä–µ–∂–∏–º)
    # Generate video
    result = await veo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress,
        duration=actual_duration,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º duration –∏–∑ cost_guard
        aspect_ratio="16:9",
        resolution="720p",
        image_path=image_path
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        mode_info = "image-to-video" if image_path else "text-to-video"
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Veo 3.1",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_info
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["veo"]["text"],
            action_callback=MODEL_ACTIONS["veo"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )

        # Clean up
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        cleanup_temp_file(image_path)

        # COST-GUARD: –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        await cost_guard.log_generation(
            user_id=user.id,
            model="veo-3.1",
            prompt=prompt,
            estimated_tokens=estimated_tokens,
            actual_tokens=result.tokens_used,
            estimated_cost_usd=cost_estimate.estimated_cost_usd,
            actual_cost_usd=(result.tokens_used / 1000) * 0.01,
            duration_seconds=actual_duration,
            status="success",
            mode=mode_info
        )

        await progress_msg.delete()

        # Clear image_path from state but keep service to allow new generation
        await state.update_data(image_path=None, photo_caption_prompt=None)
    else:
        # Clean up input image if exists
        cleanup_temp_file(image_path)

        # COST-GUARD: –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É
        await cost_guard.log_generation(
            user_id=user.id,
            model="veo-3.1",
            prompt=prompt,
            estimated_tokens=estimated_tokens,
            actual_tokens=0,
            estimated_cost_usd=cost_estimate.estimated_cost_usd,
            actual_cost_usd=0.0,
            duration_seconds=actual_duration,
            status="error",
            error=result.error
        )

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

        # Clear image_path from state but keep service to allow retry
        await state.update_data(image_path=None, photo_caption_prompt=None)


async def process_sora_video(message: Message, user: User, state: FSMContext):
    """Process Sora 2 video generation using callback-based flow.

    1. Reserve tokens
    2. Send createTask to Kie.ai with callBackUrl
    3. Save job to DB
    4. Return immediately ‚Äî callback handler delivers the result
    """
    from app.bot.states.media import SoraSettings
    from app.core.billing_config import get_sora_tokens_cost
    from app.services.video_job_service import VideoJobService

    # Get state data
    data = await state.get_data()
    sora_settings = SoraSettings.from_dict(data)

    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    api_model = sora_settings.get_api_model(has_image=bool(image_path))
    estimated_tokens = get_sora_tokens_cost(sora_settings.quality, sora_settings.duration)

    # Step 1: Reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.reserve_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            if image_path:
                cleanup_temp_file(image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    quality_text = "Pro" if sora_settings.quality == "pro" else "Stable"

    # Image-to-video not supported yet (needs CDN upload)
    if image_path:
        cleanup_temp_file(image_path)
        await message.answer(
            "‚ö†Ô∏è **Image-to-Video –¥–ª—è Sora 2 –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
            "Sora 2 API —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ CDN —Å–µ—Ä–≤–µ—Ä.\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ text-to-video —Ä–µ–∂–∏–º –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n"
            "‚Ä¢ üåä Veo 3.1 (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)\n"
            "‚Ä¢ üé• Hailuo (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)",
            parse_mode="Markdown"
        )
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            await sub_service.rollback_tokens(user.id, estimated_tokens)
        await state.update_data(image_path=None, photo_caption_prompt=None)
        return

    # Step 2: Send progress message
    mode_text = "text-to-video"
    progress_msg = await message.answer(
        f"‚è≥ –í–∞—à–µ –≤–∏–¥–µ–æ Sora 2 {quality_text} ({mode_text}, {sora_settings.duration}—Å) "
        f"–¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é!\n\n"
        f"–ú—ã –æ—Ç–ø—Ä–∞–≤–∏–º –≤–∞–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –æ–Ω –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤. "
        f"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.\n\n"
        f"–í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º."
    )

    # Step 3: Create task via Kie.ai API with callback
    sora_service = SoraService()
    try:
        task_id = await sora_service.create_task(
            prompt=prompt,
            model=api_model,
            aspect_ratio=sora_settings.aspect_ratio,
            n_frames=str(sora_settings.duration),
        )
    except Exception as e:
        logger.error("sora_create_task_failed", error=str(e), user_id=user.id)
        # Rollback tokens on API failure
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            await sub_service.rollback_tokens(user.id, estimated_tokens)
        await progress_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ Sora 2:\n{str(e)[:200]}\n\n"
            f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.",
            parse_mode=None,
        )
        await state.update_data(image_path=None, photo_caption_prompt=None)
        return

    # Step 4: Save job to database
    try:
        async with async_session_maker() as session:
            job_service = VideoJobService(session)
            job = await job_service.create_job(
                user_id=user.id,
                provider="sora",
                model_id=api_model,
                prompt=prompt,
                input_data={
                    "aspect_ratio": sora_settings.aspect_ratio,
                    "n_frames": str(sora_settings.duration),
                    "quality": sora_settings.quality,
                    "quality_text": quality_text,
                },
                chat_id=message.chat.id,
                tokens_cost=estimated_tokens,
                progress_message_id=progress_msg.message_id,
            )
            # Store task_id from Kie.ai
            await job_service.update_job_status(
                job.id,
                "processing",
                task_id=task_id,
            )
            logger.info(
                "sora_job_created",
                job_id=job.id,
                task_id=task_id,
                user_id=user.id,
                model=api_model,
                tokens=estimated_tokens,
            )
    except Exception as e:
        logger.error("sora_job_save_failed", error=str(e), user_id=user.id)
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            await sub_service.rollback_tokens(user.id, estimated_tokens)
        await progress_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏:\n{str(e)[:200]}\n\n"
            f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.",
            parse_mode=None,
        )
        await state.update_data(image_path=None, photo_caption_prompt=None)
        return

    # Done ‚Äî handler returns, callback will deliver the result
    await state.update_data(image_path=None, photo_caption_prompt=None)


async def process_luma_video(message: Message, user: User, state: FSMContext):
    """Process Luma Dream Machine video generation."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    image_path = data.get("image_path", None)

    luma_billing = get_video_model_billing("luma")
    estimated_tokens = luma_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path:
                cleanup_temp_file(image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Luma Dream Machine ({mode_text})...")
    luma_service = LumaService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Prepare keyframes if image provided
    # NOTE: Luma API —Ç—Ä–µ–±—É–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    # "You should upload and use your own cdn image urls, currently this is the only way to pass an image"
    # –î–ª—è —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º—ã –æ—Ç–∫–ª—é—á–∞–µ–º image-to-video –¥–ª—è Luma
    if image_path:
        # Clean up
        cleanup_temp_file(image_path)
        await progress_msg.edit_text(
            "‚ö†Ô∏è **Image-to-Video –¥–ª—è Luma –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
            "Luma API —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ CDN —Å–µ—Ä–≤–µ—Ä, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ text-to-video —Ä–µ–∂–∏–º –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:\n"
            "‚Ä¢ üåä Veo 3.1 (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)\n"
            "‚Ä¢ üé• Hailuo (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image-to-video)",
            parse_mode="Markdown"
        )
        await state.clear()
        return

    # Text-to-video mode (no keyframes needed)
    result = await luma_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        mode_info = "image-to-video" if image_path else "text-to-video"
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Luma Dream Machine",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_info
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["luma"]["text"],
            action_callback=MODEL_ACTIONS["luma"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path:
            cleanup_temp_file(image_path)

        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_hailuo_video(message: Message, user: User, state: FSMContext):
    """Process Hailuo (MiniMax) video generation."""
    # Get state data
    data = await state.get_data()
    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    hailuo_billing = get_video_model_billing("hailuo")
    estimated_tokens = hailuo_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Hailuo AI...")
    hailuo_service = HailuoService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await hailuo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name="Hailuo AI",
            tokens_used=result.tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["hailuo"]["text"],
            action_callback=MODEL_ACTIONS["hailuo"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )
        try:
            pass  # os.remove(result.video_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))
        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_kling_video(message: Message, user: User, state: FSMContext, is_effects: bool = False):
    """Process Kling AI video generation with configurable settings."""
    # Get state data (check if image was provided)
    data = await state.get_data()

    # Get Kling settings from FSM
    kling_settings = KlingSettings.from_dict(data)

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text

    # Get images (single image or list of images for multi-image mode)
    images = data.get("kling_images", [])
    single_image = data.get("image_path", None)
    if single_image and single_image not in images:
        images = [single_image]

    # Calculate tokens based on version and duration
    if is_effects:
        kling_billing = get_video_model_billing("kling-effects")
        estimated_tokens = kling_billing.tokens_per_generation
    else:
        estimated_tokens = get_kling_tokens_cost(kling_settings.version, kling_settings.duration)

    # Check if user has enough tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up images if exist
            for img_path in images:
                cleanup_temp_file(img_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {format_token_amount(estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {format_token_amount(e.details['available'])} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    # Validate image count based on version
    if len(images) > 2:
        for img_path in images:
            cleanup_temp_file(img_path)
        await message.answer("‚ùå –ú–∞–∫—Å–∏–º—É–º 2 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.")
        await state.clear()
        return

    if len(images) == 2 and kling_settings.version != "2.5":
        for img_path in images:
            cleanup_temp_file(img_path)
        await message.answer("‚ùå –î–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –≤–µ—Ä—Å–∏–∏ 2.5.")
        await state.clear()
        return

    # Determine mode
    if is_effects:
        service_name = "Kling Effects"
    else:
        service_name = f"Kling {kling_settings.version}"

    if len(images) == 0:
        mode_text = "text-to-video"
    elif len(images) == 1:
        mode_text = "image-to-video"
    else:
        mode_text = "multi-image-to-video"

    progress_msg = await message.answer(f"üé¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è {service_name} ({mode_text})...")
    kling_service = KlingService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Prepare kwargs for video generation
    api_model = get_kling_api_model(kling_settings.version) if not is_effects else "kling-v1.6-pro"

    result = await kling_service.generate_video(
        prompt=prompt,
        model=api_model,
        progress_callback=update_progress,
        images=images,
        duration=kling_settings.duration,
        aspect_ratio=kling_settings.aspect_ratio,
        version=kling_settings.version
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        tokens_used = estimated_tokens

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name=service_name,
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt,
            mode=mode_text
        )

        # Create action keyboard
        callback_key = "kling_effects" if is_effects else "kling"
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS[callback_key]["text"],
            action_callback=MODEL_ACTIONS[callback_key]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )

        # Clean up input images
        for img_path in images:
            cleanup_temp_file(img_path)

        await progress_msg.delete()
    else:
        # Clean up input images
        for img_path in images:
            cleanup_temp_file(img_path)

        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            pass

    await state.clear()


async def process_kling_effects(message: Message, user: User, state: FSMContext):
    """Process Kling Effects video generation from photo(s)."""
    data = await state.get_data()

    # Get effect settings from state
    effect_id = data.get("kling_effect_id")
    effect_name = data.get("kling_effect_name", effect_id)
    is_dual = data.get("kling_effect_is_dual", False)
    kling_effect_images = data.get("kling_effect_images", [])

    if not effect_id:
        await message.answer("‚ùå –≠—Ñ—Ñ–µ–∫—Ç –Ω–µ –≤—ã–±—Ä–∞–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç –∑–∞–Ω–æ–≤–æ.")
        await state.clear()
        return

    # Get the image path from state (saved by process_video_photo)
    image_path = data.get("image_path")
    if not image_path:
        await message.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–Ω–æ–≤–∞.")
        return

    # Add new image to the list
    kling_effect_images.append(image_path)
    await state.update_data(kling_effect_images=kling_effect_images)

    # Check if we have enough images
    required_images = 2 if is_dual else 1
    if len(kling_effect_images) < required_images:
        # Need more images
        await message.answer(
            f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(kling_effect_images)}/{required_images} —Ñ–æ—Ç–æ\n\n"
            f"üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â—ë {required_images - len(kling_effect_images)} —Ñ–æ—Ç–æ"
        )
        return

    # We have all required images - proceed with generation
    kling_effects_billing = get_video_model_billing("kling-effects")
    estimated_tokens = kling_effects_billing.tokens_per_generation

    # Check if user has enough tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up images
            for img_path in kling_effect_images:
                cleanup_temp_file(img_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {format_token_amount(estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {format_token_amount(e.details['available'])} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer(f"üé¨ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å —ç—Ñ—Ñ–µ–∫—Ç–æ–º ¬´{effect_name}¬ª...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate video with Kling Effects
    effects_service = KlingEffectsService()
    result = await effects_service.generate_effect_video(
        effect_scene=effect_id,
        image_paths=kling_effect_images,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        tokens_used = estimated_tokens

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["video"],
            model_name=f"Kling Effects ({effect_name})",
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=f"–≠—Ñ—Ñ–µ–∫—Ç: {effect_name}",
            mode="effect-video"
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["kling_effects"]["text"],
            action_callback=MODEL_ACTIONS["kling_effects"]["callback"],
            file_path=result.video_path,
            file_type="video"
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption,
            reply_markup=builder.as_markup()
        )

        # Clean up input images
        for img_path in kling_effect_images:
            cleanup_temp_file(img_path)

        await progress_msg.delete()
    else:
        # Clean up input images
        for img_path in kling_effect_images:
            cleanup_temp_file(img_path)

        try:
            await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {result.error}", parse_mode=None)
        except Exception:
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE GENERATION
# ======================

@router.message(MediaState.waiting_for_image_prompt, F.photo)
async def process_image_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-image generation (supports multiple photos for multi-image generation)."""
    data = await state.get_data()
    service_name = data.get("service", "nano_banana")
    multi_images_count = data.get("multi_images_count", 0)

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="image_input", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Resize image if needed (before sending to API)
    resize_image_if_needed(str(temp_path), max_size_mb=2.0, max_dimension=2048)

    # Check if we're in multi-image mode
    if multi_images_count > 0:
        # Multi-image mode: add photo to list
        reference_image_paths = data.get("reference_image_paths", [])
        reference_image_paths.append(str(temp_path))
        await state.update_data(reference_image_paths=reference_image_paths)

        photos_count = len(reference_image_paths)
        service_display = {
            "nano_banana": "Nano Banana",
            "dalle": "DALL-E",
            "seedream": "Seedream 4.5",
            "gemini_image": "Gemini",
            "recraft": "Recraft",
            "kling_image": "Kling AI"
        }.get(service_name, service_name)

        # Check if photo has caption (description) - if yes, process immediately
        if message.caption and message.caption.strip():
            await state.update_data(photo_caption_prompt=message.caption.strip())

            # Route to appropriate image service
            if service_name == "nano_banana":
                await process_nano_image(message, user, state)
            elif service_name == "dalle":
                await process_dalle_image(message, user, state)
            elif service_name == "seedream":
                await process_seedream_image(message, user, state)
            elif service_name == "recraft":
                await process_recraft_image(message, user, state)
            elif service_name == "gemini_image":
                await process_gemini_image(message, user, state)
            elif service_name == "kling_image":
                await process_kling_image(message, user, state)
        else:
            # No caption - show status and ask for more photos or prompt
            await message.answer(
                f"‚úÖ –§–æ—Ç–æ {photos_count} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
                f"üì∏ –í—ã –º–æ–∂–µ—Ç–µ:\n"
                f"‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë —Ñ–æ—Ç–æ (–≤—Å–µ–≥–æ: {photos_count}/{multi_images_count}+)\n"
                f"‚Ä¢ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è {service_display}:**\n"
                "‚Ä¢ \"–°–æ–∑–¥–∞–π –ø–æ—Ä—Ç—Ä–µ—Ç –∫–∞–∂–¥–æ–≥–æ –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —ç—Ç–æ–π —Å—Ü–µ–Ω—ã\"\n"
                "‚Ä¢ \"–ü—Ä–∏–º–µ–Ω–∏ —ç—Ç–æ—Ç —Å—Ç–∏–ª—å –∫ –∫–∞–∂–¥–æ–º—É —Ñ–æ—Ç–æ\""
            )
    else:
        # Single-image mode (backward compatibility)
        # Clean up old reference image if exists
        old_reference_path = data.get("reference_image_path")
        if old_reference_path:
            cleanup_temp_file(old_reference_path)

        # Save NEW image path to state
        await state.update_data(reference_image_path=str(temp_path))

        service_display = {
            "nano_banana": "Nano Banana",
            "dalle": "DALL-E",
            "seedream": "Seedream 4.5",
            "gemini_image": "Gemini",
            "recraft": "Recraft",
            "kling_image": "Kling AI"
        }.get(service_name, service_name)

        # Check if photo has caption (description)
        if message.caption and message.caption.strip():
            # User sent photo with description - process immediately
            # Save caption as prompt in state
            await state.update_data(photo_caption_prompt=message.caption.strip())

            # Route to appropriate image service
            if service_name == "dalle":
                await process_dalle_image(message, user, state)
            elif service_name == "gemini_image":
                await process_gemini_image(message, user, state)
            elif service_name == "nano_banana":
                await process_nano_image(message, user, state)
            elif service_name == "seedream":
                await process_seedream_image(message, user, state)
            elif service_name == "recraft":
                await process_recraft_image(message, user, state)
            elif service_name == "kling_image":
                await process_kling_image(message, user, state)
        else:
            # No caption - ask for description
            await message.answer(
                f"‚úÖ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
                f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
                f"**–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è {service_display}:**\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n"
                "‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–∫–≤–∞—Ä–µ–ª—å–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫\"\n"
                "‚Ä¢ \"–°–¥–µ–ª–∞–π —Ñ–æ–Ω –∫–æ—Å–º–∏—á–µ—Å–∫–∏–º\"\n"
                "‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ —Å—Ç–∏–ª—å –í–∞–Ω –ì–æ–≥–∞\""
            )


@router.message(MediaState.waiting_for_image_prompt, F.text)
async def process_image_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    # Check message length (max 2000 characters)
    if message.text and len(message.text) > 2000:
        await message.answer(
            "‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 2000 —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    data = await state.get_data()
    service_name = data.get("service", "dalle")

    if service_name == "dalle":
        await process_dalle_image(message, user, state)
    elif service_name == "gemini_image":
        await process_gemini_image(message, user, state)
    elif service_name == "nano_banana":
        await process_nano_image(message, user, state)
    elif service_name == "kling_image":
        await process_kling_image(message, user, state)
    elif service_name == "recraft":
        await process_recraft_image(message, user, state)
    elif service_name == "seedream":
        await process_seedream_image(message, user, state)
    elif service_name == "midjourney":
        await process_midjourney_image(message, user, state)
    else:
        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


async def process_dalle_image(message: Message, user: User, state: FSMContext):
    """Process DALL-E image generation or variation."""
    # Get state data (check if reference image was provided)
    data = await state.get_data()

    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)

    # Check and use tokens
    dalle_billing = get_image_model_billing("dalle3")
    estimated_tokens = dalle_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up reference image if exists
            if reference_image_path:
                cleanup_temp_file(reference_image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Create service
    dalle_service = DalleService()

    # Determine operation mode
    if reference_image_path:
        # Image variation mode (DALL-E 2 only)
        progress_msg = await message.answer("üé® –°–æ–∑–¥–∞—é –≤–∞—Ä–∏–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å DALL-E 2...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Create variation
        result = await dalle_service.create_variation(
            image_path=reference_image_path,
            progress_callback=update_progress,
            model="dall-e-2",
            size="1024x1024"
        )
    else:
        # Text-to-image mode
        progress_msg = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å DALL-E 3...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Generate image
        result = await dalle_service.generate_image(
            prompt=prompt,
            progress_callback=update_progress,
            model="dall-e-3",
            size="1024x1024",
            quality="standard",
            style="vivid"
        )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Build caption in unified format
        image_type = "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ" if not reference_image_path else "–≤–∞—Ä–∏–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        model_name = "DALL¬∑E 3" if not reference_image_path else "DALL¬∑E 2"

        caption_text = format_generation_message(
            content_type=image_type,
            model_name=model_name,
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["gpt_image"]["text"],
            action_callback=MODEL_ACTIONS["gpt_image"]["callback"],
            file_path=result.image_path,
            file_type="image"
        )

        # Send image
        image_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=image_file,
            caption=caption_text,
            reply_markup=builder.as_markup()
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        # Clean up reference image if exists
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        await progress_msg.delete()
    else:
        # Clean up reference image if exists
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    # Clear state after generation (success or failure)
    await state.clear()


async def process_gemini_image(message: Message, user: User, state: FSMContext):
    """Process Gemini/Imagen image generation."""
    # Get state data
    data = await state.get_data()
    # Get prompt from caption if available, otherwise from message text
    prompt = data.get("photo_caption_prompt") or message.text

    # Check and use tokens
    gemini_billing = get_image_model_billing("nano-banana-image")
    estimated_tokens = gemini_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Create service
    gemini_service = GeminiImageService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await gemini_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        aspect_ratio="1:1"
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Send image
        image_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=image_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!\n\n"
                    f"–ü—Ä–æ–º–ø—Ç: {prompt[:200]}\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used:,}"
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_nano_image(message: Message, user: User, state: FSMContext):
    """Process Nano Banana (Gemini 2.5 Flash Image or Gemini 3 Pro Image) image generation.

    Supports both single and multiple image generation modes.
    """
    data = await state.get_data()

    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)
    reference_image_paths = data.get("reference_image_paths", [])
    multi_images_count = data.get("multi_images_count", 0)
    nano_is_pro = data.get("nano_is_pro", False)
    aspect_ratio = data.get("nano_aspect_ratio", "auto")

    # Select model based on PRO flag
    model = "gemini-3-pro-image-preview" if nano_is_pro else "gemini-2.5-flash-image"

    # Determine generation count
    if multi_images_count > 0:
        # Multi-image mode
        images_to_generate = multi_images_count
    else:
        # Single-image mode (backward compatibility)
        images_to_generate = 1

    # Calculate cost
    nano_billing_id = "banana-pro" if nano_is_pro else "nano-banana-image"
    cost_per_image = get_image_model_billing(nano_billing_id).tokens_per_generation
    estimated_tokens = cost_per_image * images_to_generate

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Cleanup any reference images
            if reference_image_path:
                cleanup_temp_file(reference_image_path)
            for ref_path in reference_image_paths:
                cleanup_temp_file(ref_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤ ({images_to_generate} √ó {cost_per_image:,})\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    model_display = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"

    if images_to_generate > 1:
        # Multi-image mode
        progress_msg = await message.answer(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é {images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å {model_display}...\n"
            f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ..."
        )
    else:
        # Single-image mode
        mode_text = "image-to-image" if (reference_image_path or reference_image_paths) else "text-to-image"
        progress_msg = await message.answer(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å {model_display} ({mode_text})..."
        )

    nano_service = NanoBananaService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate images
    if images_to_generate > 1:
        # Multi-image generation mode: create multiple images in parallel
        import asyncio
        import re

        def create_unique_prompts(base_prompt: str, count: int) -> list[str]:
            """Create unique prompts for each image to ensure variety.

            Analyzes the prompt and creates variations for each generation.
            """
            # Check if prompt contains numbered scenes or variations
            # Pattern: "1. scene1, 2. scene2, 3. scene3" or "scene1, scene2, scene3"

            # Try to detect numbered list (handles multi-line scenes with commas)
            # Pattern: "1. scene text\n2. next scene" or "1) scene, more details\n2) next"
            numbered_pattern = r'(\d+)[\.\)]\s*(.*?)(?=\n\s*\d+[\.\)]|\Z)'
            numbered_matches = re.findall(numbered_pattern, base_prompt, re.MULTILINE | re.DOTALL)

            if numbered_matches and len(numbered_matches) >= count:
                # Extract base context (text before first numbered item)
                first_num_pos = re.search(r'\d+[\.\)]', base_prompt)
                base_context = base_prompt[:first_num_pos.start()].strip() if first_num_pos else ""

                # Define radically different camera and lighting setups for each scene
                # This forces variation even when user prompts are similar
                camera_setups = [
                    "Camera: Wide angle (24mm), natural soft daylight, centered composition, eye-level perspective",
                    "Camera: Macro lens (100mm), shallow depth of field, soft diffused backlight, 45-degree angle",
                    "Camera: Top-down view (bird's eye), dramatic side lighting with shadows, overhead perspective",
                    "Camera: Medium telephoto (85mm), three-quarter view, warm golden hour lighting, slightly tilted",
                    "Camera: Extreme close-up macro, bokeh background, bright key light from left, Dutch angle tilt",
                    "Camera: Ultra-wide angle (16mm), low angle looking up, cool morning light, dynamic composition",
                    "Camera: Standard lens (50mm), straight-on frontal view, high-key lighting, perfectly centered",
                    "Camera: Telephoto zoom (135mm), compressed perspective, backlit rim lighting, diagonal framing",
                    "Camera: Fish-eye lens, distorted perspective, colorful accent lighting, off-center placement",
                    "Camera: Tilt-shift lens, selective focus plane, sunset warm tones, asymmetric balance"
                ]

                # Use numbered scenes directly
                prompts = []
                for idx, (num, scene_text) in enumerate(numbered_matches[:count], 1):
                    scene = scene_text.strip()

                    # Get specific camera setup for this scene
                    camera_setup = camera_setups[idx % len(camera_setups)]

                    # Add strong technical specifications to force variation
                    technical_spec = (
                        f"\n\n[TECHNICAL REQUIREMENTS - Scene {idx}/{count}]:\n"
                        f"{camera_setup}\n"
                        f"CRITICAL: This scene MUST be visually DISTINCT from all other scenes. "
                        f"Different angle, different lighting direction, different composition style. "
                        f"Ignore any repetitive patterns from other scenes."
                    )

                    # Combine base context with specific scene
                    if base_context:
                        full_prompt = f"{base_context}. {scene}{technical_spec}"
                    else:
                        full_prompt = f"{scene}{technical_spec}"
                    prompts.append(full_prompt)
                return prompts

            # Try to detect comma-separated scenes (if more than 2 commas)
            comma_parts = [p.strip() for p in base_prompt.split(',') if p.strip()]
            if len(comma_parts) >= count:
                # Use comma-separated parts as separate scenes
                return comma_parts[:count]

            # Detect keywords that suggest multiple scenes
            scene_keywords = ['–Ω–∞ –∫–∞—Ñ–µ–ª–µ', '–Ω–∞ –≤–∞–Ω–Ω–æ–π', '–ª–µ–∂–∏—Ç', '—Å—Ç–æ–∏—Ç', '—Ä—è–¥–æ–º', '–¥–µ—Ä–∂–∏—Ç', '–ª—å–µ—Ç—Å—è']
            detected_scenes = []

            # Split by common separators
            separators = ['. ', ', ', '; ']
            parts = [base_prompt]
            for sep in separators:
                new_parts = []
                for part in parts:
                    new_parts.extend(part.split(sep))
                parts = new_parts

            # Extract scene descriptions
            for part in parts:
                part = part.strip()
                if any(keyword in part.lower() for keyword in scene_keywords):
                    detected_scenes.append(part)

            if detected_scenes and len(detected_scenes) >= count:
                # Use detected scenes
                base_instructions = base_prompt.split('.')[0] if '.' in base_prompt else ""
                prompts = []
                for scene in detected_scenes[:count]:
                    if base_instructions:
                        prompts.append(f"{base_instructions}. {scene}")
                    else:
                        prompts.append(scene)
                return prompts

            # Fallback: create variations by adding diversity instructions
            variations = []
            variation_angles = [
                "top-down aerial view with dramatic overhead lighting",
                "low angle close-up with shallow depth of field",
                "45-degree side angle with natural soft lighting",
                "extreme macro detail shot with bokeh background",
                "wide environmental shot showing full context",
                "dramatic side lighting with strong shadows",
                "backlit silhouette with rim lighting",
                "Dutch angle (tilted) perspective for dynamic feel",
                "straight-on centered composition with symmetry",
                "diagonal composition with leading lines"
            ]

            for i in range(count):
                angle_instruction = variation_angles[i % len(variation_angles)]
                variation = (
                    f"{base_prompt}\n\n"
                    f"VARIATION {i+1}: Use {angle_instruction}. "
                    f"Make this COMPLETELY DIFFERENT from other variations. "
                    f"UNIQUE angle, DIFFERENT background, DISTINCT atmosphere."
                )
                variations.append(variation)

            return variations

        # Create unique prompts for each image
        unique_prompts = create_unique_prompts(prompt, images_to_generate)

        # Log unique prompts for debugging
        logger.info(
            "nano_multi_prompts_created",
            count=len(unique_prompts),
            original_prompt=prompt[:200],
            prompts_lengths=[len(p) for p in unique_prompts],
            prompts_preview=[p[:300] for p in unique_prompts]
        )

        # Log each prompt separately for better visibility
        for idx, up in enumerate(unique_prompts, 1):
            logger.info(
                "nano_multi_prompt_detail",
                scene_index=idx,
                prompt_length=len(up),
                prompt_start=up[:400]
            )

        async def generate_single_image(index: int, image_prompt: str, ref_image: str = None):
            """Generate a single image with unique prompt."""
            try:
                result = await nano_service.generate_image(
                    prompt=image_prompt,
                    model=model,
                    progress_callback=None,  # Disable individual progress for parallel generation
                    aspect_ratio=aspect_ratio,
                    reference_image_path=ref_image
                )
                return (index, result, ref_image)
            except Exception as e:
                logger.error("nano_multi_image_generation_failed", index=index, error=str(e))
                return (index, None, ref_image)

        # Update progress: generating
        await update_progress(
            f"üçå –ì–µ–Ω–µ—Ä–∏—Ä—É—é {images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...\n"
            f"‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-60 —Å–µ–∫—É–Ω–¥..."
        )

        # Create tasks for parallel generation
        # Use reference image for ALL generations to maintain consistent product design
        tasks = []
        if reference_image_paths:
            # Use same reference for all images to keep bottle/product identical
            ref_path = reference_image_paths[0]
            for idx in range(images_to_generate):
                task_prompt = unique_prompts[idx] if idx < len(unique_prompts) else prompt
                tasks.append(generate_single_image(idx, task_prompt, ref_path))
        else:
            # No reference images: generate all as text-to-image with unique prompts
            for idx in range(images_to_generate):
                task_prompt = unique_prompts[idx] if idx < len(unique_prompts) else prompt
                tasks.append(generate_single_image(idx, task_prompt, None))

        # Execute all tasks in parallel
        results_with_indices = await asyncio.gather(*tasks)

        # Process results
        successful_results = []
        failed_count = 0

        for idx, result, ref_path in results_with_indices:
            if result and result.success:
                successful_results.append((idx, result))
            else:
                failed_count += 1
                logger.warning("nano_multi_image_failed", index=idx, error=result.error if result else "Unknown error")

        # Cleanup reference images
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        # Send results
        if successful_results:
            await update_progress(
                f"‚úÖ –ì–æ—Ç–æ–≤–æ: {len(successful_results)}/{images_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
                f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã..."
            )

            total_tokens_used = sum(r.metadata.get("tokens_used", cost_per_image) for _, r in successful_results)

            async with async_session_maker() as session:
                sub_service = SubscriptionService(session)
                user_tokens = await sub_service.get_available_tokens(user.id)

            # Send summary message first
            model_name = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"
            summary_text = (
                f"‚úÖ **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n\n"
                f"üçå –ú–æ–¥–µ–ª—å: {model_name}\n"
                f"üé® –°–æ–∑–¥–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(successful_results)}/{images_to_generate}\n"
                f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens_used:,}\n"
                f"üíé –û—Å—Ç–∞–ª–æ—Å—å —Ç–æ–∫–µ–Ω–æ–≤: {user_tokens:,}\n\n"
                f"üìù –ü—Ä–æ–º–ø—Ç: {prompt[:150]}{'...' if len(prompt) > 150 else ''}"
            )

            if failed_count > 0:
                summary_text += f"\n\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å: {failed_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

            await message.answer(summary_text, parse_mode="Markdown")

            # Send each image individually
            nano_callback = "bot.nano_pro" if nano_is_pro else "bot.nano"
            for idx, result in successful_results:
                try:
                    image_file = FSInputFile(result.image_path)
                    builder = create_action_keyboard(
                        action_text=MODEL_ACTIONS["nano_banana"]["text"],
                        action_callback=nano_callback,
                        file_path=result.image_path,
                        file_type="image"
                    )
                    await message.answer_photo(
                        photo=image_file,
                        caption=f"üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}/{images_to_generate}",
                        reply_markup=builder.as_markup()
                    )
                except Exception as send_error:
                    logger.error("nano_multi_image_send_failed", index=idx, error=str(send_error))

            await progress_msg.delete()
        else:
            # All failed
            for ref_path in reference_image_paths:
                cleanup_temp_file(ref_path)

            await progress_msg.edit_text(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.",
                parse_mode=None
            )

        await state.clear()
        return

    # Single-image generation mode (original code)
    result = await nano_service.generate_image(
        prompt=prompt,
        model=model,
        progress_callback=update_progress,
        aspect_ratio=aspect_ratio,
        reference_image_path=reference_image_path or (reference_image_paths[0] if reference_image_paths else None)
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        model_name = "Nano Banana PRO (Gemini 3)" if nano_is_pro else "Nano Banana (Gemini 2.5)"
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name=model_name,
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard - use correct callback based on PRO mode
        nano_callback = "bot.nano_pro" if nano_is_pro else "bot.nano"
        builder = create_action_keyboard(
            action_text=MODEL_ACTIONS["nano_banana"]["text"],
            action_callback=nano_callback,
            file_path=result.image_path,
            file_type="image"
        )

        try:
            file_size = os.path.getsize(result.image_path)
            logger.info("nano_image_file_size", path=result.image_path, size=file_size)

            if file_size > 2 * 1024 * 1024:
                logger.info("nano_image_optimizing", original_size=file_size)

                img = Image.open(result.image_path)

                if img.mode in ("RGBA", "LA", "P"):
                    background = Image.new("RGB", img.size, (255, 255, 255))
                    if img.mode == "P":
                        img = img.convert("RGBA")
                    background.paste(
                        img,
                        mask=img.split()[-1] if img.mode == "RGBA" else None
                    )
                    img = background

                buffer = io.BytesIO()
                img.save(buffer, format="JPEG", quality=85, optimize=True)
                buffer.seek(0)

                photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                await message.answer_photo(
                    photo=photo,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            else:
                try:
                    image_file = FSInputFile(result.image_path)
                    await message.answer_photo(
                        photo=image_file,
                        caption=info_text,
                        reply_markup=builder.as_markup()
                    )
                except Exception:
                    img = Image.open(result.image_path)

                    if img.mode in ("RGBA", "LA", "P"):
                        background = Image.new("RGB", img.size, (255, 255, 255))
                        if img.mode == "P":
                            img = img.convert("RGBA")
                        background.paste(
                            img,
                            mask=img.split()[-1] if img.mode == "RGBA" else None
                        )
                        img = background

                    buffer = io.BytesIO()
                    img.save(buffer, format="JPEG", quality=90, optimize=True)
                    buffer.seek(0)

                    photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                    await message.answer_photo(
                        photo=photo,
                        caption=info_text,
                        reply_markup=builder.as_markup()
                    )

        except Exception as send_error:
            logger.error("nano_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("nano_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("nano_image_cleanup_failed", error=str(e))

        # Cleanup reference images (both single and multiple)
        if reference_image_path:
            cleanup_temp_file(reference_image_path)
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        await progress_msg.delete()

    else:
        # Cleanup reference images on failure
        if reference_image_path:
            cleanup_temp_file(reference_image_path)
        for ref_path in reference_image_paths:
            cleanup_temp_file(ref_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    # Clear state after generation (success or failure)
    await state.clear()


async def process_kling_image(message: Message, user: User, state: FSMContext):
    """Process Kling AI image generation."""
    data = await state.get_data()

    # Get settings from FSM state
    kling_image_settings = KlingImageSettings.from_dict(data)

    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)

    # Auto-translate if enabled
    if kling_image_settings.auto_translate and prompt:
        from app.services.ai.openai_service import OpenAIService
        try:
            openai_service = OpenAIService()
            translated = await openai_service.translate_to_english(prompt)
            if translated:
                prompt = translated
        except Exception as e:
            logger.warning("kling_image_translate_failed", error=str(e))

    kling_image_billing = get_image_model_billing("kling-image")
    estimated_tokens = kling_image_billing.tokens_per_generation

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            if reference_image_path:
                cleanup_temp_file(reference_image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    mode_text = "image-to-image" if reference_image_path else "text-to-image"
    model_names = {"kling-v1": "v1", "kling-v1-5": "v1.5", "kling-v2": "v2"}
    model_display = model_names.get(kling_image_settings.model, kling_image_settings.model)
    progress_msg = await message.answer(
        f"üéû –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Kling AI {model_display} ({mode_text})..."
    )

    kling_service = KlingImageService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image with user settings
    result = await kling_service.generate_image(
        prompt=prompt,
        model=kling_image_settings.model,
        progress_callback=update_progress,
        aspect_ratio=kling_image_settings.aspect_ratio,
        resolution=kling_image_settings.resolution,
        image_path=reference_image_path  # For image-to-image mode (None for text-to-image)
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="Kling AI",
            mode="text-to-image" if not reference_image_path else "image-to-image",
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text="üéû –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            action_callback="bot.kling_image",
            file_path=result.image_path,
            file_type="image"
        )

        try:
            photo = FSInputFile(result.image_path)
            await message.answer_photo(
                photo=photo,
                caption=info_text,
                reply_markup=builder.as_markup()
            )

        except Exception as send_error:
            logger.error("kling_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("kling_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("kling_image_cleanup_failed", error=str(e))

        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        await progress_msg.delete()

    else:
        if reference_image_path:
            cleanup_temp_file(reference_image_path)

        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    await state.clear()


async def process_recraft_image(message: Message, user: User, state: FSMContext):
    """Process Recraft AI image generation."""
    data = await state.get_data()
    prompt = data.get("photo_caption_prompt") or message.text

    recraft_billing = get_image_model_billing("recraft")
    estimated_tokens = recraft_billing.tokens_per_generation

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    progress_msg = await message.answer(
        "üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Recraft AI..."
    )

    recraft_service = RecraftService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await recraft_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        model="recraftv2",  # Use V2 for better price
        style="realistic_image",  # Default style
        size="1024x1024"
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        info_text = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="Recraft AI",
            tokens_used=tokens_used,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Create action keyboard
        builder = create_action_keyboard(
            action_text="üé® –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            action_callback="bot.recraft",
            file_path=result.image_path,
            file_type="image"
        )

        try:
            photo = FSInputFile(result.image_path)
            await message.answer_photo(
                photo=photo,
                caption=info_text,
                reply_markup=builder.as_markup()
            )

        except Exception as send_error:
            logger.error("recraft_image_send_failed", error=str(send_error))
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=info_text,
                    reply_markup=builder.as_markup()
                )
            except Exception as doc_error:
                logger.error("recraft_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    info_text,
                    reply_markup=builder.as_markup()
                )

        # Cleanup
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("recraft_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
        await state.update_data(photo_caption_prompt=None)

    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            pass

    # Don't clear state - keep service so user can generate more images
    await state.update_data(photo_caption_prompt=None)


# ======================
# FSM HANDLERS - AUDIO
# ======================

@router.message(MediaState.waiting_for_audio_prompt, F.text)
async def process_audio_prompt(message: Message, state: FSMContext, user: User):
    # CRITICAL FIX: Ignore commands (text starting with /)
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    service_name = data.get("service", "suno")

    if service_name == "suno":
        await process_suno_audio(message, user, state)
    elif service_name == "tts":
        await process_tts_audio(message, user, state)
    else:
        display = {
            "suno": "Suno AI",
            "tts": "OpenAI TTS"
        }.get(service_name, service_name)

        await message.answer(
            f"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            f"–í–∞—à —Ç–µ–∫—Å—Ç –ø–æ–ª—É—á–µ–Ω: {message.text[:100]}..."
        )
        await state.clear()


async def process_suno_audio(message: Message, user: User, state: FSMContext):
    """Process Suno AI music generation."""
    prompt = message.text

    # Check and use tokens
    estimated_tokens = 5000  # Suno AI cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üéµ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –º—É–∑—ã–∫–∏ —Å Suno AI...")

    # Create service
    suno_service = SunoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate music
    result = await suno_service.generate_audio(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate unified notification message
        caption = format_generation_message(
            content_type=CONTENT_TYPES["audio"],
            model_name="Suno AI",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=prompt
        )

        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=caption,
            title=f"Suno AI - {prompt[:50]}"
        )

        # Clean up
        try:
            pass  # os.remove(result.audio_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("suno_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE PROCESSING
# ======================

@router.message(MediaState.waiting_for_replace_bg_image, F.photo)
async def process_replace_bg_image(message: Message, state: FSMContext, user: User):
    """Process image for background replacement."""
    # Get the largest photo
    photo = message.photo[-1]

    # Download photo
    file = await message.bot.get_file(photo.file_id)
    temp_path = get_temp_file_path(prefix="replace_bg", suffix=".jpg", user_id=user.id)
    await message.bot.download_file(file.file_path, temp_path)

    # Resize if needed
    temp_path = resize_image_if_needed(temp_path, max_size_mb=3.0, max_dimension=2048)

    # Save to state
    await state.update_data(replace_bg_image_path=str(temp_path))

    # Ask for background description
    await message.answer(
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "üìù –¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏—Ç–µ –Ω–æ–≤—ã–π —Ñ–æ–Ω:\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ \"–ë–µ–ª—ã–π —Ñ–æ–Ω\"\n"
        "‚Ä¢ \"–ü–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏ –Ω–∞ –∑–∞–∫–∞—Ç–µ\"\n"
        "‚Ä¢ \"–ì–æ—Ä–æ–¥—Å–∫–∞—è —É–ª–∏—Ü–∞ –Ω–æ—á—å—é\"\n"
        "‚Ä¢ \"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç –æ—Ç —Å–∏–Ω–µ–≥–æ –∫ —Ñ–∏–æ–ª–µ—Ç–æ–≤–æ–º—É\"",
        parse_mode="Markdown"
    )

    await state.set_state(MediaState.waiting_for_replace_bg_prompt)


@router.message(MediaState.waiting_for_replace_bg_prompt, F.text)
async def process_replace_bg_prompt(message: Message, state: FSMContext, user: User):
    """Process background replacement with new background description."""
    # CRITICAL FIX: Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    image_path = data.get("replace_bg_image_path")
    background_description = message.text.strip()

    if not image_path:
        await message.answer("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ —Å /start")
        await state.clear()
        return

    # Check tokens
    estimated_tokens = 2000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            cleanup_temp_file(image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ó–∞–º–µ–Ω—è—é —Ñ–æ–Ω...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Use Nano Banana service with image-to-image
    nano_service = NanoBananaService()

    # Create prompt for background replacement
    prompt = f"–ó–∞–º–µ–Ω–∏ —Ñ–æ–Ω –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∞: {background_description}. –°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏ —Ñ–æ–Ω."

    # Generate with reference image
    result = await nano_service.generate_image(
        prompt=prompt,
        reference_image_path=image_path,
        progress_callback=update_progress
    )

    # Clean up original image
    cleanup_temp_file(image_path)

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate caption
        caption = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash)",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=background_description,
            mode="background-replacement"
        )

        # Send image
        await message.answer_photo(
            photo=FSInputFile(result.image_path),
            caption=caption,
            reply_markup=create_action_keyboard(
                action_text="üîÑ –ó–∞–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω –µ—â–µ —Ä–∞–∑",
                action_callback="bot.pi_repb",
                file_path=result.image_path,
                file_type="image"
            ).as_markup()
        )

        await progress_msg.delete()

        # Clean up generated image
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("replace_bg_cleanup_failed", error=str(e))

        logger.info(
            "replace_bg_completed",
            user_id=user.id,
            background=background_description[:50],
            tokens=estimated_tokens
        )
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

        logger.error("replace_bg_failed", user_id=user.id, error=result.error)

    await state.clear()


@router.message(MediaState.waiting_for_image, F.photo)
async def process_image(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service = data.get("service", "remove_bg")

    display = {
        "remove_bg": "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞",
        "replace_bg": "–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞"
    }.get(service, service)

    await message.answer(
        f"–§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({display}) –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!"
    )
    await state.clear()


@router.message(MediaState.waiting_for_upscale_image, F.photo)
async def process_upscale(message: Message, state: FSMContext, user: User):
    """Process image upscaling."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 2000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="upscale", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    stability_service = StabilityService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Upscale image
    result = await stability_service.upscale_image(
        image_path=str(temp_path),
        scale_factor=2,
        progress_callback=update_progress
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:

        # Send upscaled image
        upscaled_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=upscaled_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–æ!\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("upscale_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - WHISPER (VOICE TRANSCRIPTION)
# ======================

@router.message(MediaState.waiting_for_whisper_audio, F.voice | F.audio)
async def process_whisper_audio(message: Message, state: FSMContext, user: User):
    """Process Whisper audio transcription."""

    # Check and use tokens
    estimated_tokens = 1000  # Whisper cost per minute

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ...")

    # Download audio
    if message.voice:
        file = await message.bot.get_file(message.voice.file_id)
        file_ext = "ogg"
    else:
        file = await message.bot.get_file(message.audio.file_id)
        file_ext = "mp3"

    # Create temp path
    temp_path = get_temp_file_path(prefix="audio", suffix=f".{file_ext}")

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    whisper_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    await update_progress("üéôÔ∏è –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –∞—É–¥–∏–æ...")

    # Transcribe audio
    result = await whisper_service.transcribe(
        audio_path=str(temp_path),
        language="ru"  # Russian language
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:
        # Send transcription
        await message.answer(
            f"‚úÖ **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ—Ç–æ–≤–∞!**\n\n"
            f"üìù **–¢–µ–∫—Å—Ç:**\n{result.text}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - TTS UPDATE
# ======================

async def process_tts_audio(message: Message, user: User, state: FSMContext):
    """Process OpenAI TTS generation."""
    text = message.text

    if len(text) > 4096:
        await message.answer("‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π! –ú–∞–∫—Å–∏–º—É–º 4096 —Å–∏–º–≤–æ–ª–æ–≤.")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 200  # TTS cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∫—Å—Ç–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üéôÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–µ—á—å...")

    # Create service
    tts_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate audio (default voice: alloy)
    result = await tts_service.generate_audio(
        prompt=text,
        voice="alloy",
        model="tts-1",
        progress_callback=update_progress
    )

    if result.success:
        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=f"‚úÖ –û–∑–≤—É—á–∫–∞ –≥–æ—Ç–æ–≤–∞!\n\n"
                    f"–ì–æ–ª–æ—Å: alloy\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}",
            title="OpenAI TTS"
        )

        # Clean up
        try:
            pass  # os.remove(result.audio_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("tts_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - GPT VISION (IMAGE ANALYSIS)
# ======================

@router.message(MediaState.waiting_for_vision_image, F.photo)
async def process_vision_image(message: Message, state: FSMContext, user: User):
    """Receive image and ask for analysis prompt."""
    # Get the largest photo
    photo = message.photo[-1]

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="vision", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Store image path in state
    await state.update_data(image_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_vision_prompt)

    await progress_msg.edit_text(
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
        "‚Ä¢ –ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ?\n"
        "‚Ä¢ –û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ\n"
        "‚Ä¢ –ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –µ—Å—Ç—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?\n"
        "‚Ä¢ –ß—Ç–æ –∑–∞ –æ–±—ä–µ–∫—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã?"
    )


@router.message(MediaState.waiting_for_vision_prompt, F.text)
async def process_vision_prompt(message: Message, state: FSMContext, user: User):
    """Process GPT Vision image analysis."""
    data = await state.get_data()
    image_path = data.get("image_path")
    prompt = message.text

    if not image_path or not os.path.exists(image_path):
        await message.answer("‚ùå –û—à–∏–±–∫–∞: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 1000  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up temp file
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üëÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1000,
        detail="auto"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        # Send analysis
        await message.answer(
            f"‚úÖ **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤!**\n\n"
            f"üìù **–û—Ç–≤–µ—Ç:**\n{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# PHOTO TOOLS HANDLERS
# ======================

@router.message(MediaState.waiting_for_photo_upscale, F.photo)
async def process_photo_upscale(message: Message, state: FSMContext, user: User):
    """Process photo quality improvement using PIL image enhancement."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens (basic image processing is cheap)
    estimated_tokens = 500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="enhance", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    try:
        # Progress update
        await progress_msg.edit_text("üé® –£–ª—É—á—à–∞—é –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", parse_mode=None)

        # Open image with PIL
        from PIL import Image, ImageEnhance, ImageFilter

        img = Image.open(temp_path)

        # Convert to RGB if needed
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            if img.mode in ('RGBA', 'LA'):
                background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = background

        # 1. Enhance sharpness
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.5)  # Increase sharpness by 50%

        # 2. Enhance contrast
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.2)  # Increase contrast by 20%

        # 3. Enhance color
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(1.1)  # Increase color saturation by 10%

        # 4. Enhance brightness slightly
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(1.05)  # Increase brightness by 5%

        # 5. Apply subtle unsharp mask for additional sharpness
        img = img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))

        # Save enhanced image
        enhanced_path = get_temp_file_path(prefix="enhanced", suffix=".jpg")

        # Save with high quality
        img.save(str(enhanced_path), 'JPEG', quality=95, optimize=True)

        # Check file size and optimize if needed
        file_size = os.path.getsize(enhanced_path)
        max_size = 10 * 1024 * 1024  # 10 MB Telegram limit

        if file_size > max_size:
            logger.info("enhanced_image_too_large", size=file_size, max_size=max_size)
            # Reduce quality gradually until it fits
            quality = 90
            while file_size > max_size and quality > 60:
                img.save(str(enhanced_path), 'JPEG', quality=quality, optimize=True)
                file_size = os.path.getsize(enhanced_path)
                quality -= 5
                logger.info("enhanced_image_compressed", new_size=file_size, quality=quality)

        # Clean up original temp file
        cleanup_temp_file(temp_path)

        # Send enhanced image
        enhanced_file = FSInputFile(enhanced_path)
        await message.answer_photo(
            photo=enhanced_file,
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–æ!\n\n"
                    f"–ü—Ä–∏–º–µ–Ω–µ–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è: —Ä–µ–∑–∫–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç, —Ü–≤–µ—Ç–∞, —è—Ä–∫–æ—Å—Ç—å.\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
        )

        # Clean up enhanced file
        cleanup_temp_file(enhanced_path)

        await progress_msg.delete()

    except Exception as e:
        # Clean up temp files on error
        cleanup_temp_file(temp_path)

        logger.error("photo_quality_improvement_failed", error=str(e))

        try:
            from app.core.error_handlers import format_user_error
            user_message = format_user_error(e, provider="Image Enhancement", user_id=user.id)
            await progress_msg.edit_text(f"‚ùå {user_message}")
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_replace_bg, F.photo)
async def process_photo_replace_bg(message: Message, state: FSMContext, user: User):
    """Process background replacement."""
    # First, save the photo and ask for background description
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    # Save to state
    await state.update_data(saved_image_path=image_path)

    # Ask for background description
    await message.answer(
        "üì§ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "‚úèÔ∏è –¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫–æ–π —Ñ–æ–Ω –≤—ã —Ö–æ—Ç–∏—Ç–µ:\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ –ì–æ—Ä–Ω—ã–π –ø–µ–π–∑–∞–∂ —Å –∑–∞—Å–Ω–µ–∂–µ–Ω–Ω—ã–º–∏ –≤–µ—Ä—à–∏–Ω–∞–º–∏\n"
        "‚Ä¢ –¢—Ä–æ–ø–∏—á–µ—Å–∫–∏–π –ø–ª—è–∂ —Å –ø–∞–ª—å–º–∞–º–∏\n"
        "‚Ä¢ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ—Ñ–∏—Å\n"
        "‚Ä¢ –ö–æ—Å–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å –∑–≤–µ–∑–¥–∞–º–∏",
        reply_markup=back_to_main_keyboard()
    )


@router.message(MediaState.waiting_for_photo_replace_bg, F.text)
async def process_photo_replace_bg_prompt(message: Message, state: FSMContext, user: User):
    """Process background replacement with Gemini (NanoBananaService)."""
    # CRITICAL FIX: Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    data = await state.get_data()
    image_path = data.get("saved_image_path")

    if not image_path or not os.path.exists(image_path):
        await message.answer("‚ùå –û—à–∏–±–∫–∞: —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        await state.clear()
        return

    bg_description = message.text

    # Check and use tokens (Gemini image-to-image)
    nano_billing = get_image_model_billing("nano-banana-image")
    estimated_tokens = nano_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up saved image
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üé® –ó–∞–º–µ–Ω—è—é —Ñ–æ–Ω —Å Gemini 2.5 Flash...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Use Nano Banana service with image-to-image
    nano_service = NanoBananaService()

    # Create prompt for background replacement
    prompt = f"–ó–∞–º–µ–Ω–∏ —Ñ–æ–Ω –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∞: {bg_description}. –°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏ —Ñ–æ–Ω."

    # Generate with reference image using Gemini 2.5 Flash Image
    result = await nano_service.generate_image(
        prompt=prompt,
        model="gemini-2.5-flash-image",
        reference_image_path=image_path,
        progress_callback=update_progress
    )

    # Clean up original image
    cleanup_temp_file(image_path)

    if result.success:
        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Generate caption
        caption = format_generation_message(
            content_type=CONTENT_TYPES["image"],
            model_name="–ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞ (Gemini 2.5 Flash)",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=bg_description,
            mode="background-replacement"
        )

        # Send image
        await message.answer_photo(
            photo=FSInputFile(result.image_path),
            caption=caption,
            reply_markup=create_action_keyboard(
                action_text="üîÑ –ó–∞–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω –µ—â–µ —Ä–∞–∑",
                action_callback="bot.pi_repb",
                file_path=result.image_path,
                file_type="image"
            ).as_markup()
        )

        await progress_msg.delete()

        # Clean up generated image
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("replace_bg_cleanup_failed", error=str(e))

        logger.info(
            "photo_replace_bg_completed",
            user_id=user.id,
            background=bg_description[:50],
            tokens=estimated_tokens
        )
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

        logger.error("photo_replace_bg_failed", user_id=user.id, error=result.error)

    await state.clear()


@router.message(MediaState.waiting_for_photo_remove_bg, F.photo)
async def process_photo_remove_bg(message: Message, state: FSMContext, user: User):
    """Process background removal using Remove.bg API."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="removebg", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Remove background
    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=str(temp_path),
        progress_callback=update_progress,
        size="auto",  # auto, preview, full
        type="auto"   # auto, person, product, car
    )

    # Clean up temp file
    cleanup_temp_file(temp_path)

    if result.success:
        # Send image with removed background
        result_file = FSInputFile(result.image_path)

        # Try sending as photo first
        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )
        except Exception:
            # If photo fails (transparent images sometimes do), send as document
            await message.answer_document(
                document=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n"
                        f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º (PNG).\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )

        # Clean up
        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception as e:
            logger.error("removebg_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞:\n{result.error}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_vectorize, F.photo)
async def process_photo_vectorize(message: Message, state: FSMContext, user: User):
    """Process photo vectorization."""
    await _process_photo_tool(
        message, state, user,
        tool_name="–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è",
        prompt=(
            "Analyze this image and describe how to convert it to a vector format. "
            "Provide recommendations for: tracing method, color palette reduction, "
            "path simplification, and optimal settings for this specific image type. "
            "Suggest the best vectorization approach (outline, centerline, or full color)."
        ),
        emoji="üìê"
    )


async def _process_photo_tool(message: Message, state: FSMContext, user: User,
                              tool_name: str, prompt: str, emoji: str):
    """Helper function to process photo with GPT Vision."""
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    await _process_photo_with_path(message, state, user, image_path, tool_name, prompt, emoji)


async def _process_photo_with_path(message: Message, state: FSMContext, user: User,
                                   image_path: str, tool_name: str, prompt: str, emoji: str):
    """Process photo with given path."""
    # Check and use tokens
    estimated_tokens = 1500  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            # Clean up temp file
            cleanup_temp_file(image_path)
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer(f"{emoji} –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–æ—Ç–æ...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        # Send analysis
        await message.answer(
            f"‚úÖ **{tool_name} - –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤!**\n\n"
            f"üìù **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()

# ======================
# KLING MOTION CONTROL - Photo handler (must be before catch-all)
# ======================

@router.message(MediaState.kling_mc_waiting_for_image, F.photo)
async def kling_mc_receive_image(message: Message, state: FSMContext, user: User):
    """Receive reference image for Motion Control."""
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    temp_path = get_temp_file_path(prefix="kling_mc_image", suffix=".jpg")
    await message.bot.download_file(file.file_path, temp_path)

    # Resize if needed
    resize_image_if_needed(str(temp_path), max_size_mb=10.0, max_dimension=4096)

    await state.update_data(kling_mc_image_path=str(temp_path))
    await state.set_state(MediaState.kling_mc_waiting_for_video)

    await message.answer(
        "‚úÖ –§–æ—Ç–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "üé¨ –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ —Å –¥–≤–∏–∂–µ–Ω–∏—è–º–∏ (URL).\n\n"
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–∏–¥–µ–æ:\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç: MP4/MOV (–¥–æ 100 –ú–ë)\n"
        "‚Ä¢ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 3-30 —Å–µ–∫—É–Ω–¥\n"
        "‚Ä¢ –ü–µ—Ä—Å–æ–Ω–∞–∂ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∏–¥–µ–Ω\n"
        "‚Ä¢ –ë–µ–∑ —Ä–µ–∑–∫–∏—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –∏ –¥–≤–∏–∂–µ–Ω–∏–π –∫–∞–º–µ—Ä—ã\n"
        "‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è"
    )


# ======================
# SMART INPUT HANDLING - No model selected
# ======================

@router.message(F.photo, ~F.state(None))
async def handle_photo_in_wrong_state(message: Message, state: FSMContext):
    """Handle photo sent in unsupported state - redirect to correct handler."""
    current_state = await state.get_state()

    # If in video/image prompt state, pass to existing handlers
    if current_state in [
        MediaState.waiting_for_video_prompt,
        MediaState.waiting_for_image_prompt,
    ]:
        return  # Let other handlers process it

    # Otherwise, clear state and treat as new photo
    await state.clear()
    await handle_photo_no_model(message, state)


@router.message(F.photo)
async def handle_photo_no_model(message: Message, state: FSMContext):
    """Handle photo sent without selecting a model first."""
    # Download and save photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_path = get_temp_file_path(prefix="unsorted", suffix=".jpg")

    await message.bot.download_file(file.file_path, temp_path)

    # Save to state
    await state.update_data(saved_photo_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_photo_action_choice)

    # Create inline keyboard for choosing action
    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ", callback_data="photo_action:video"),
            InlineKeyboardButton(text="üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="photo_action:image")
        ],
        [
            InlineKeyboardButton(text="üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ", callback_data="photo_action:vision"),
            InlineKeyboardButton(text="üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ", callback_data="photo_action:tools")
        ],
        [
            InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="photo_action:cancel")
        ]
    ])

    await message.answer_photo(
        photo=photo.file_id,
        caption="üì∏ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
                "–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ?\n\n"
                "üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ç–æ\n"
                "üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Ñ–æ—Ç–æ –≤ –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
                "üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
                "üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ - —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, —É–ª—É—á—à–µ–Ω–∏–µ –∏ —Ç.–¥.",
        reply_markup=keyboard
    )


@router.callback_query(F.data.startswith("photo_action:"))
async def handle_photo_action_choice(callback: CallbackQuery, state: FSMContext):
    """Handle user's choice of what to do with the photo."""
    veo_billing = get_video_model_billing("veo-3.1-fast")
    luma_billing = get_video_model_billing("luma")
    kling_billing = get_video_model_billing("kling-video")
    nano_billing = get_image_model_billing("nano-banana-image")
    dalle_billing = get_image_model_billing("dalle3")
    action = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if action == "cancel":
        # Clean up photo
        if saved_photo_path:
            cleanup_temp_file(saved_photo_path)
        await state.clear()
        try:
            await callback.message.edit_caption(
                caption="‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞."
            )
        except Exception:
            pass
        await callback.answer()
        return

    if action == "video":
        # Show video models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üåä Veo 3.1", callback_data="photo_video:veo"),
                InlineKeyboardButton(text="üåô Luma", callback_data="photo_video:luma")
            ],
            [
                InlineKeyboardButton(text="‚ú® Kling AI", callback_data="photo_video:kling")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        caption_text = (
            f"üé¨ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ:\n\n"
            f"‚Ä¢ Veo 3.1 - Google, HD –∫–∞—á–µ—Å—Ç–≤–æ ({format_token_amount(veo_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤)\n"
            f"‚Ä¢ Luma - Dream Machine ({format_token_amount(luma_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤)\n"
            f"‚Ä¢ Kling AI - –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ ({format_token_amount(kling_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤)"
        )

        try:
            await callback.message.edit_caption(caption=caption_text, reply_markup=keyboard)
        except Exception:
            try:
                await callback.message.answer(caption_text, reply_markup=keyboard)
            except Exception:
                pass
        await callback.answer()

    elif action == "image":
        # Show image models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üçå Nano Banana", callback_data="photo_image:nano"),
                InlineKeyboardButton(text="üñº DALL-E", callback_data="photo_image:dalle")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        caption_text = (
            f"üñº –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n\n"
            f"‚Ä¢ Nano Banana - Gemini 2.5 Flash, image-to-image ({format_token_amount(nano_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤)\n"
            f"‚Ä¢ DALL-E - Image variation ({format_token_amount(dalle_billing.tokens_per_generation)} —Ç–æ–∫–µ–Ω–æ–≤)"
        )

        try:
            await callback.message.edit_caption(caption=caption_text, reply_markup=keyboard)
        except Exception:
            try:
                await callback.message.answer(caption_text, reply_markup=keyboard)
            except Exception:
                pass
        await callback.answer()

    elif action == "vision":
        # Move photo to vision state and start analysis
        if saved_photo_path:
            # Actually process vision directly
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    # Default prompt for analysis
                    prompt = "Provide a detailed analysis of this image. Describe what you see, including objects, people, scenery, colors, composition, and any notable details."
                    await _process_vision_with_path(callback.message, state, user, saved_photo_path, prompt)
                else:
                    await callback.message.edit_caption("‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    await state.clear()
        else:
            await callback.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", show_alert=True)
            await state.clear()

    elif action == "tools":
        # Show photo tools
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üö´ –£–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω", callback_data="photo_tool:remove_bg")
            ],
            [
                InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="photo_action:back")
            ]
        ])

        try:
            await callback.message.edit_caption(
                caption="üé® –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n\n"
                        "‚Ä¢ –£–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω - –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω (~1,000 —Ç–æ–∫–µ–Ω–æ–≤)",
                reply_markup=keyboard
            )
        except Exception:
            try:
                await callback.message.answer(
                    "üé® –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n\n"
                    "‚Ä¢ –£–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω - –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω (~1,000 —Ç–æ–∫–µ–Ω–æ–≤)",
                    reply_markup=keyboard
                )
            except Exception:
                pass
        await callback.answer()

    elif action == "back":
        # Go back to main choice - resend the photo with choices
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ", callback_data="photo_action:video"),
                InlineKeyboardButton(text="üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="photo_action:image")
            ],
            [
                InlineKeyboardButton(text="üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ", callback_data="photo_action:vision"),
                InlineKeyboardButton(text="üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ", callback_data="photo_action:tools")
            ],
            [
                InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="photo_action:cancel")
            ]
        ])

        caption_text = (
            "üì∏ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
            "–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ?\n\n"
            "üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ç–æ\n"
            "üñº –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Ñ–æ—Ç–æ –≤ –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
            "üëÅ –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ\n"
            "üé® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ - —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, —É–ª—É—á—à–µ–Ω–∏–µ –∏ —Ç.–¥."
        )

        try:
            await callback.message.edit_caption(caption=caption_text, reply_markup=keyboard)
        except Exception:
            try:
                await callback.message.answer(caption_text, reply_markup=keyboard)
            except Exception:
                pass
        await callback.answer()


@router.callback_query(F.data.startswith("photo_video:"))
async def handle_photo_video_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle video model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Move photo to image_path for video generation
    await state.update_data(image_path=saved_photo_path, service=model)
    await state.set_state(MediaState.waiting_for_video_prompt)

    model_names = {
        "veo": "Veo 3.1",
        "luma": "Luma Dream Machine",
        "kling": "Kling AI"
    }

    caption_text = (
        f"‚úÖ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
        f"üé¨ {model_names.get(model, model)}\n\n"
        f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
        f"–ü—Ä–∏–º–µ—Ä—ã:\n"
        f"‚Ä¢ \"–û–∂–∏–≤–∏ —ç—Ç–æ —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤—å –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ\"\n"
        f"‚Ä¢ \"–°–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã –≤–æ–ª–æ—Å—ã —Ä–∞–∑–≤–µ–≤–∞–ª–∏—Å—å –Ω–∞ –≤–µ—Ç—Ä—É\"\n"
        f"‚Ä¢ \"–î–æ–±–∞–≤—å –ø–∞–¥–∞—é—â–∏–µ —Å–Ω–µ–∂–∏–Ω–∫–∏ –∏ –ø–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã\""
    )

    try:
        await callback.message.edit_caption(caption=caption_text)
    except Exception:
        try:
            await callback.message.answer(caption_text)
        except Exception:
            pass
    await callback.answer()


@router.callback_query(F.data.startswith("photo_image:"))
async def handle_photo_image_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle image model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Map service names
    service_map = {
        "nano": "nano_banana",
        "dalle": "dalle"
    }

    # Move photo to reference_image_path for image generation
    await state.update_data(reference_image_path=saved_photo_path, service=service_map.get(model, model))
    await state.set_state(MediaState.waiting_for_image_prompt)

    model_names = {
        "nano": "Nano Banana",
        "dalle": "DALL-E"
    }

    examples = {
        "nano": "‚Ä¢ \"–°–¥–µ–ª–∞–π –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ\"\n‚Ä¢ \"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–∫–≤–∞—Ä–µ–ª—å–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫\"\n‚Ä¢ \"–°–¥–µ–ª–∞–π —Ñ–æ–Ω –∫–æ—Å–º–∏—á–µ—Å–∫–∏–º\"",
        "dalle": "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–∏"
    }

    caption_text = (
        f"‚úÖ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!\n\n"
        f"üñº {model_names.get(model, model)}\n\n"
        f"üìù –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ñ–æ—Ç–æ.\n\n"
        f"–ü—Ä–∏–º–µ—Ä—ã:\n{examples.get(model, '')}"
    )

    try:
        await callback.message.edit_caption(caption=caption_text)
    except Exception:
        try:
            await callback.message.answer(caption_text)
        except Exception:
            pass
    await callback.answer()


@router.callback_query(F.data.startswith("photo_tool:"))
async def handle_photo_tool_choice(callback: CallbackQuery, state: FSMContext):
    """Handle photo tool choice."""
    tool = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if tool == "remove_bg":
        # Trigger processing with saved photo
        if saved_photo_path and os.path.exists(saved_photo_path):
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    await _process_remove_bg_with_path(callback.message, state, user, saved_photo_path)
                else:
                    await callback.message.edit_caption("‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    await state.clear()
        else:
            await callback.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", show_alert=True)
            await state.clear()

    await callback.answer()


async def _process_remove_bg_with_path(message: Message, state: FSMContext, user: User, image_path: str):
    """Process background removal with given path."""
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üö´ –£–¥–∞–ª—è—é —Ñ–æ–Ω...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=image_path,
        progress_callback=update_progress,
        size="auto",
        type="auto"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        result_file = FSInputFile(result.image_path)

        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )
        except Exception:
            await message.answer_document(
                document=result_file,
                caption=f"‚úÖ –§–æ–Ω —É–¥–∞–ª—ë–Ω!\n\n–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º (PNG).\n\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {estimated_tokens:,}"
            )

        try:
            pass  # os.remove(result.image_path) - DISABLED: files managed by file_cache
        except Exception:
            pass

        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞:\n{result.error}")

    await state.clear()


async def _process_vision_with_path(message: Message, state: FSMContext, user: User, image_path: str, prompt: str):
    """Process vision analysis with given path."""
    estimated_tokens = 1500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            cleanup_temp_file(image_path)
            await state.clear()
            return

    progress_msg = await message.answer("üëÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    vision_service = VisionService()
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    cleanup_temp_file(image_path)

    if result.success:
        await message.answer(
            f"‚úÖ **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤!**\n\n"
            f"{result.content}\n\n"
            f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used:,}"
        )
        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:\n{result.error}")

    await state.clear()


# ======================
# KLING MOTION CONTROL HANDLERS
# ======================

@router.callback_query(F.data == "bot.kling_motion_control")
async def start_kling_motion_control(callback: CallbackQuery, state: FSMContext, user: User):
    """Start Kling Motion Control flow."""
    mc_billing = get_video_model_billing("kling-motion-control")
    total_tokens = await get_available_tokens(user.id)
    tokens_per_request = mc_billing.tokens_per_generation
    videos_available = int(total_tokens / tokens_per_request) if total_tokens > 0 else 0

    # Get settings from state
    data = await state.get_data()
    mode = data.get("kling_mc_mode", "std")
    orientation = data.get("kling_mc_orientation", "image")
    keep_sound = data.get("kling_mc_sound", "yes")

    mode_display = "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π" if mode == "std" else "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π"
    orientation_display = "–ü–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é" if orientation == "image" else "–ü–æ –≤–∏–¥–µ–æ"
    sound_display = "–î–∞" if keep_sound == "yes" else "–ù–µ—Ç"

    text = (
        "üï∫ Kling AI ‚Äî Motion Control\n\n"
        "–ü–µ—Ä–µ–Ω–µ—Å–∏—Ç–µ –¥–≤–∏–∂–µ–Ω–∏—è –∏–∑ –≤–∏–¥–µ–æ –Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ).\n\n"
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–æ—Ç–æ:\n"
        "‚Ä¢ –ü–µ—Ä—Å–æ–Ω–∞–∂ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∏–¥–µ–Ω (—Ç–µ–ª–æ –∏ –≥–æ–ª–æ–≤–∞)\n"
        "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏\n"
        "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: JPG, JPEG, PNG (–¥–æ 10 –ú–ë)\n\n"
        f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\n"
        f"‚Ä¢ –†–µ–∂–∏–º: {mode_display}\n"
        f"‚Ä¢ –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞: {orientation_display}\n"
        f"‚Ä¢ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–≤—É–∫: {sound_display}\n\n"
        f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: {format_token_amount(tokens_per_request)} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ {videos_available} –≤–∏–¥–µ–æ"
    )

    await state.set_state(MediaState.kling_mc_waiting_for_image)
    await state.update_data(
        service="kling_motion_control",
        kling_mc_mode=mode,
        kling_mc_orientation=orientation,
        kling_mc_sound=keep_sound,
    )

    try:
        await callback.message.edit_text(
            text,
            reply_markup=kling_motion_control_keyboard(mode, orientation, keep_sound)
        )
    except Exception:
        await callback.message.answer(
            text,
            reply_markup=kling_motion_control_keyboard(mode, orientation, keep_sound)
        )
    await callback.answer()


@router.callback_query(F.data == "kling_mc.settings")
async def kling_mc_settings_menu(callback: CallbackQuery, state: FSMContext):
    """Show Motion Control settings menu."""
    text = "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Motion Control\n\n–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:"

    try:
        await callback.message.edit_text(text, reply_markup=kling_mc_settings_keyboard())
    except Exception:
        await callback.message.answer(text, reply_markup=kling_mc_settings_keyboard())
    await callback.answer()


@router.callback_query(F.data == "kling_mc.settings.mode")
async def kling_mc_mode_settings(callback: CallbackQuery, state: FSMContext):
    """Show Motion Control mode selection."""
    data = await state.get_data()
    current_mode = data.get("kling_mc_mode", "std")

    text = (
        "üéØ –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n\n"
        "‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π (std) ‚Äî –±—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
        "‚Ä¢ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π (pro) ‚Äî –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –¥–æ–ª—å—à–µ"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_mc_mode_keyboard(current_mode))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_mc_mode_keyboard(current_mode))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_mc.set.mode:"))
async def kling_mc_set_mode(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Motion Control mode."""
    new_mode = callback.data.split(":")[1]
    await state.update_data(kling_mc_mode=new_mode)
    await callback.answer(f"–†–µ–∂–∏–º: {'–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π' if new_mode == 'std' else '–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π'}")
    await start_kling_motion_control(callback, state, user)


@router.callback_query(F.data == "kling_mc.settings.orientation")
async def kling_mc_orientation_settings(callback: CallbackQuery, state: FSMContext):
    """Show Motion Control orientation selection."""
    data = await state.get_data()
    current = data.get("kling_mc_orientation", "image")

    text = (
        "üßç –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞\n\n"
        "‚Ä¢ –ü–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Äî –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –∫–∞–∫ –Ω–∞ —Ñ–æ—Ç–æ (–º–∞–∫—Å. 10 —Å–µ–∫. –≤–∏–¥–µ–æ)\n"
        "‚Ä¢ –ü–æ –≤–∏–¥–µ–æ ‚Äî –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –∫–∞–∫ –≤ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–º –≤–∏–¥–µ–æ (–º–∞–∫—Å. 30 —Å–µ–∫. –≤–∏–¥–µ–æ)"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_mc_orientation_keyboard(current))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_mc_orientation_keyboard(current))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_mc.set.orientation:"))
async def kling_mc_set_orientation(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Motion Control orientation."""
    new_val = callback.data.split(":")[1]
    await state.update_data(kling_mc_orientation=new_val)
    await callback.answer(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: {'–ü–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é' if new_val == 'image' else '–ü–æ –≤–∏–¥–µ–æ'}")
    await start_kling_motion_control(callback, state, user)


@router.callback_query(F.data == "kling_mc.settings.sound")
async def kling_mc_sound_settings(callback: CallbackQuery, state: FSMContext):
    """Show Motion Control sound selection."""
    data = await state.get_data()
    current = data.get("kling_mc_sound", "yes")

    text = (
        "üîä –ó–≤—É–∫ –∏–∑ –≤–∏–¥–µ–æ\n\n"
        "‚Ä¢ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–≤—É–∫ ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–≤—É–∫ –∏–∑ –≤–∏–¥–µ–æ –±—É–¥–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ\n"
        "‚Ä¢ –ë–µ–∑ –∑–≤—É–∫–∞ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –∞—É–¥–∏–æ"
    )

    try:
        await callback.message.edit_text(text, reply_markup=kling_mc_sound_keyboard(current))
    except Exception:
        await callback.message.answer(text, reply_markup=kling_mc_sound_keyboard(current))
    await callback.answer()


@router.callback_query(F.data.startswith("kling_mc.set.sound:"))
async def kling_mc_set_sound(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Motion Control sound setting."""
    new_val = callback.data.split(":")[1]
    await state.update_data(kling_mc_sound=new_val)
    await callback.answer(f"–ó–≤—É–∫: {'–°–æ—Ö—Ä–∞–Ω–∏—Ç—å' if new_val == 'yes' else '–ë–µ–∑ –∑–≤—É–∫–∞'}")
    await start_kling_motion_control(callback, state, user)


@router.message(MediaState.kling_mc_waiting_for_video, F.text)
async def kling_mc_receive_video_url(message: Message, state: FSMContext, user: User):
    """Receive reference video URL for Motion Control."""
    # Ignore commands
    if message.text and message.text.startswith('/'):
        await state.clear()
        return

    video_url = message.text.strip()

    # Basic URL validation
    if not video_url.startswith("http"):
        await message.answer(
            "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ (URL).\n"
            "–°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://"
        )
        return

    await state.update_data(kling_mc_video_url=video_url)
    await state.set_state(MediaState.kling_mc_waiting_for_prompt)

    await message.answer(
        "‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ –ø–æ–ª—É—á–µ–Ω–∞!\n\n"
        "üìù –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).\n"
        "–ü—Ä–æ–º–ø—Ç –ø–æ–º–æ–∂–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –∏ —ç—Ñ—Ñ–µ–∫—Ç—ã –¥–≤–∏–∂–µ–Ω–∏—è.\n\n"
        "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /skip —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏ –Ω–∞—á–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."
    )


@router.message(MediaState.kling_mc_waiting_for_prompt, F.text)
async def kling_mc_receive_prompt(message: Message, state: FSMContext, user: User):
    """Receive optional prompt and start Motion Control generation."""
    prompt = None
    if message.text and not message.text.startswith('/'):
        prompt = message.text.strip()
    # /skip or any command means no prompt

    data = await state.get_data()
    image_path = data.get("kling_mc_image_path")
    video_url = data.get("kling_mc_video_url")
    mode = data.get("kling_mc_mode", "std")
    orientation = data.get("kling_mc_orientation", "image")
    keep_sound = data.get("kling_mc_sound", "yes")

    if not image_path or not video_url:
        await message.answer("‚ùå –û—à–∏–±–∫–∞: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∞—á–∞–ª–∞.")
        await state.clear()
        return

    # Check and use tokens
    mc_billing = get_video_model_billing("kling-motion-control")
    estimated_tokens = mc_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            cleanup_temp_file(image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é Motion Control –≤–∏–¥–µ–æ —Å Kling AI...")

    await state.clear()

    # Generate video
    kling_service = KlingService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await kling_service.generate_motion_control(
        image_path=image_path,
        video_url=video_url,
        mode=mode,
        character_orientation=orientation,
        prompt=prompt,
        keep_original_sound=keep_sound,
        progress_callback=update_progress,
    )

    # Cleanup temp image
    cleanup_temp_file(image_path)

    if result.success:
        from aiogram.types import FSInputFile

        # Get user's remaining tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        caption_text = format_generation_message(
            content_type="–≤–∏–¥–µ–æ (Motion Control)",
            model_name="Kling AI Motion Control",
            tokens_used=estimated_tokens,
            user_tokens=user_tokens,
            prompt=prompt
        )

        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=caption_text
        )
        await progress_msg.delete()

    else:
        # Refund tokens
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            await sub_service.add_eternal_tokens(user.id, estimated_tokens, "refund")

        await progress_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ Motion Control:\n\n{result.error}\n\n"
            f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å."
        )


@router.message(MediaState.kling_mc_waiting_for_video, F.video)
async def kling_mc_receive_video_file(message: Message, state: FSMContext, user: User):
    """Handle video file upload for Motion Control - inform user to send URL instead."""
    await message.answer(
        "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É (URL) –Ω–∞ –≤–∏–¥–µ–æ, –∞ –Ω–µ —Å–∞–º —Ñ–∞–π–ª.\n\n"
        "Motion Control API –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ URL –≤–∏–¥–µ–æ.\n"
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ –Ω–∞ –ª—é–±–æ–π —Ö–æ—Å—Ç–∏–Ω–≥ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É."
    )


# ======================
# SEEDREAM HANDLERS
# ======================

@router.callback_query(F.data == "bot.seedream_4.5")
async def start_seedream_45(callback: CallbackQuery, state: FSMContext, user: User):
    """Seedream 4.5 image generation."""
    try:
        await cleanup_temp_images(state)
        await _show_seedream_menu(callback, state, user)
    except Exception as e:
        logger.error("seedream_start_error", error=str(e))
        try:
            await callback.message.answer(
                "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ Seedream. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–µ–Ω—é."
            )
        except Exception:
            pass
        await callback.answer()


async def _show_seedream_menu(callback: CallbackQuery, state: FSMContext, user: User):
    """Show Seedream 4.5 menu with current settings."""
    # Get current settings from state
    data = await state.get_data()
    current_size = data.get("seedream_size", "2K")
    batch_mode = data.get("seedream_batch_mode", False)
    batch_count = data.get("seedream_batch_count", 3)

    # Get billing info
    seedream_billing = get_image_model_billing("seedream-4.5")
    total_tokens = await get_available_tokens(user.id)
    tokens_per_image = seedream_billing.tokens_per_generation
    requests_available = int(total_tokens / tokens_per_image) if total_tokens > 0 else 0

    # Model info
    model_info = SeedreamService.get_model_info()

    text = (
        f"‚ú® **Seedream 4.5** ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n"
        f"üìù **–û–ø–∏—Å–∞–Ω–∏–µ:** {model_info['description']}\n\n"
        f"üéØ **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
    )

    for cap in model_info['capabilities']:
        text += f"‚Ä¢ {cap}\n"

    text += (
        f"\n‚öôÔ∏è **–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**\n"
        f"‚Ä¢ –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {current_size}\n"
        f"‚Ä¢ –ü–∞–∫–µ—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {'–í–ö–õ (' + str(batch_count) + ' —à—Ç.)' if batch_mode else '–í–´–ö–õ'}\n\n"
        f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** {format_token_amount(tokens_per_image)} —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
        f"üîπ –¢–æ–∫–µ–Ω–æ–≤ —Ö–≤–∞—Ç–∏—Ç –Ω–∞ **{requests_available}** –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n"
        f"üì∏ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ:**\n"
        f"‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç—É\n"
        f"‚Ä¢ –§–æ—Ç–æ + –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ñ–æ—Ç–æ"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(
        service="seedream",
        seedream_version="4.5",
        seedream_size=current_size,
        seedream_batch_mode=batch_mode,
        seedream_batch_count=batch_count,
        reference_image_path=None,
        photo_caption_prompt=None
    )

    # Check if message has photo (can't edit_text on photo messages)
    try:
        if callback.message.photo:
            # Message is a photo - send new message instead of editing
            await callback.message.answer(
                text,
                reply_markup=seedream_keyboard(current_size, batch_mode),
                parse_mode="Markdown"
            )
        else:
            await callback.message.edit_text(
                text,
                reply_markup=seedream_keyboard(current_size, batch_mode),
                parse_mode="Markdown"
            )
    except Exception:
        # Fallback: send new message if edit fails
        await callback.message.answer(
            text,
            reply_markup=seedream_keyboard(current_size, batch_mode),
            parse_mode="Markdown"
        )
    await callback.answer()


@router.callback_query(F.data == "seedream.settings.size")
async def seedream_size_settings(callback: CallbackQuery, state: FSMContext):
    """Show Seedream size selection."""
    data = await state.get_data()
    current_size = data.get("seedream_size", "2K")

    text = (
        f"üìê **–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è**\n\n"
        f"‚Ä¢ **2K/4K** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é\n"
        f"‚Ä¢ **1:1, 16:9, 9:16...** ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω\n\n"
        f"–¢–µ–∫—É—â–∏–π –≤—ã–±–æ—Ä: **{current_size}**"
    )

    await callback.message.edit_text(
        text,
        reply_markup=seedream_size_keyboard(current_size),
        parse_mode="Markdown"
    )
    await callback.answer()


@router.callback_query(F.data.startswith("seedream.set.size|"))
async def seedream_set_size(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Seedream size."""
    parts = callback.data.split("|")
    new_size = parts[1]

    await state.update_data(seedream_size=new_size)
    await callback.answer(f"–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {new_size}")

    await _show_seedream_menu(callback, state, user)


@router.callback_query(F.data.startswith("seedream.toggle.batch|"))
async def seedream_toggle_batch(callback: CallbackQuery, state: FSMContext, user: User):
    """Toggle Seedream batch mode."""
    parts = callback.data.split("|")
    action = parts[1]

    new_batch_mode = (action == "on")
    await state.update_data(seedream_batch_mode=new_batch_mode)

    if new_batch_mode:
        await callback.answer("–ü–∞–∫–µ—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
    else:
        await callback.answer("–ü–∞–∫–µ—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–∫–ª—é—á–µ–Ω–∞")

    await _show_seedream_menu(callback, state, user)


@router.callback_query(F.data == "seedream.settings.batch_count")
async def seedream_batch_count_settings(callback: CallbackQuery, state: FSMContext):
    """Show Seedream batch count selection."""
    data = await state.get_data()
    current_count = data.get("seedream_batch_count", 3)

    text = (
        f"üî¢ **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–∫–µ—Ç–µ**\n\n"
        f"–ü—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞—Å—Ç —Å–µ—Ä–∏—é —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.\n\n"
        f"‚ö†Ô∏è –°—Ç–æ–∏–º–æ—Å—Ç—å = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ √ó —Ü–µ–Ω–∞ –∑–∞ 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n\n"
        f"–¢–µ–∫—É—â–∏–π –≤—ã–±–æ—Ä: **{current_count} —à—Ç.**"
    )

    await callback.message.edit_text(
        text,
        reply_markup=seedream_batch_count_keyboard(current_count),
        parse_mode="Markdown"
    )
    await callback.answer()


@router.callback_query(F.data.startswith("seedream.set.batch_count|"))
async def seedream_set_batch_count(callback: CallbackQuery, state: FSMContext, user: User):
    """Set Seedream batch count."""
    parts = callback.data.split("|")
    new_count = int(parts[1])

    await state.update_data(seedream_batch_count=new_count)
    await callback.answer(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {new_count}")

    await _show_seedream_menu(callback, state, user)


async def process_seedream_image(message: Message, user: User, state: FSMContext):
    """Process Seedream 4.5 image generation."""
    data = await state.get_data()
    prompt = data.get("photo_caption_prompt") or message.text
    size = data.get("seedream_size", "2K")
    batch_mode = data.get("seedream_batch_mode", False)
    batch_count = data.get("seedream_batch_count", 3)
    reference_image_path = data.get("reference_image_path")

    # Get billing info
    seedream_billing = get_image_model_billing("seedream-4.5")

    # Calculate estimated tokens
    images_count = batch_count if batch_mode else 1
    estimated_tokens = seedream_billing.tokens_per_generation * images_count

    # Check and reserve tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up reference image if exists
            if reference_image_path:
                cleanup_temp_file(reference_image_path)

            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {format_token_amount(estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {format_token_amount(e.details['available'])} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
                f"–ö—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É: /start ‚Üí üíé –ü–æ–¥–ø–∏—Å–∫–∞"
            )
            await state.clear()
            return

    # Progress message
    mode_text = "–ø–æ —Ñ–æ—Ç–æ" if reference_image_path else "–ø–æ —Ç–µ–∫—Å—Ç—É"
    progress_msg = await message.answer(
        f"‚ú® –ì–µ–Ω–µ—Ä–∏—Ä—É—é {'–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' if batch_mode else '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'} {mode_text} —Å Seedream 4.5..."
    )

    seedream_service = SeedreamService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image(s)
    result = await seedream_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        size=size,
        reference_image=reference_image_path,
        batch_mode=batch_mode,
        max_images=batch_count if batch_mode else 1,
        watermark=False
    )

    # Clean up reference image
    if reference_image_path:
        cleanup_temp_file(reference_image_path)

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)
        images_count = result.metadata.get("images_count", 1)
        all_images = result.metadata.get("all_images", [{"path": result.image_path}])

        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            user_tokens = await sub_service.get_available_tokens(user.id)

        # Send all images
        for idx, img_info in enumerate(all_images):
            img_path = img_info.get("path")
            if not img_path:
                continue

            try:
                # Generate caption for this image
                if idx == len(all_images) - 1:
                    # Last image - show full info
                    info_text = format_generation_message(
                        content_type=CONTENT_TYPES["image"],
                        model_name="Seedream 4.5",
                        tokens_used=tokens_used,
                        user_tokens=user_tokens,
                        prompt=prompt
                    )
                    if images_count > 1:
                        info_text = f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}/{images_count}\n\n" + info_text

                    # Create action keyboard
                    builder = create_action_keyboard(
                        action_text="‚ú® –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                        action_callback="bot.seedream_4.5",
                        file_path=img_path,
                        file_type="image"
                    )

                    photo = FSInputFile(img_path)
                    await message.answer_photo(
                        photo=photo,
                        caption=info_text,
                        reply_markup=builder.as_markup()
                    )
                else:
                    # Not the last image - simple caption
                    photo = FSInputFile(img_path)
                    await message.answer_photo(
                        photo=photo,
                        caption=f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}/{images_count}"
                    )

            except Exception as send_error:
                logger.error("seedream_image_send_failed", error=str(send_error), idx=idx)
                try:
                    doc_file = FSInputFile(img_path)
                    await message.answer_document(
                        document=doc_file,
                        caption=f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}/{images_count}"
                    )
                except Exception:
                    pass

        await progress_msg.delete()

    else:
        # Refund tokens on error
        async with async_session_maker() as session:
            sub_service = SubscriptionService(session)
            await sub_service.add_eternal_tokens(user.id, estimated_tokens, "refund")

        await progress_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Seedream 4.5:\n\n{result.error}\n\n"
            f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å."
        )

    await state.clear()


# ======================
# MIDJOURNEY IMAGE HANDLER
# ======================

async def process_midjourney_image(message: Message, user: User, state: FSMContext):
    """Process Midjourney image generation."""
    data = await state.get_data()
    prompt = data.get("photo_caption_prompt") or message.text
    reference_image_path = data.get("reference_image_path", None)

    mj_billing = get_image_model_billing("midjourney")
    estimated_tokens = mj_billing.tokens_per_generation

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            if reference_image_path:
                cleanup_temp_file(reference_image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Midjourney...")
    mj_service = MidjourneyService()

    # Run generation in background to not block the bot
    asyncio.create_task(
        _midjourney_generation_task(
            bot=message.bot,
            chat_id=message.chat.id,
            user_id=user.id,
            prompt=prompt,
            estimated_tokens=estimated_tokens,
            progress_msg_id=progress_msg.message_id,
            mj_service=mj_service,
        )
    )

    await state.clear()


async def _midjourney_generation_task(
    bot,
    chat_id: int,
    user_id: int,
    prompt: str,
    estimated_tokens: int,
    progress_msg_id: int,
    mj_service,
):
    """Background task for Midjourney image generation. Runs without blocking the bot."""
    try:
        async def update_progress(text: str):
            try:
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=progress_msg_id,
                    text=text,
                    parse_mode=None,
                )
            except Exception:
                pass

        result = await mj_service.generate_image(
            prompt=prompt,
            task_type="mj_txt2img",
            progress_callback=update_progress,
            aspect_ratio="16:9",
        )

        if result.success and result.image_paths:
            async with async_session_maker() as session:
                sub_service = SubscriptionService(session)
                user_tokens = await sub_service.get_available_tokens(user_id)

            caption = format_generation_message(
                content_type=CONTENT_TYPES["image"],
                model_name="Midjourney",
                tokens_used=estimated_tokens,
                user_tokens=user_tokens,
                prompt=prompt,
            )

            builder = create_action_keyboard(
                action_text=MODEL_ACTIONS["midjourney"]["text"],
                action_callback=MODEL_ACTIONS["midjourney"]["callback"],
                file_path=result.image_paths[0],
                file_type="image",
            )

            image_file = FSInputFile(result.image_paths[0])
            await bot.send_photo(
                chat_id=chat_id,
                photo=image_file,
                caption=caption,
                reply_markup=builder.as_markup(),
            )
            try:
                await bot.delete_message(chat_id=chat_id, message_id=progress_msg_id)
            except TelegramBadRequest as e:
                # Ignore expected errors when message can't be deleted
                if "message can't be deleted" not in str(e) and "message to delete not found" not in str(e):
                    from app.core.logger import get_logger
                    logger = get_logger(__name__)
                    logger.warning("media_delete_message_failed", error=str(e))
            except Exception as e:
                from app.core.logger import get_logger
                logger = get_logger(__name__)
                logger.warning("media_delete_message_error", error=str(e))
        else:
            # Refund tokens
            async with async_session_maker() as session:
                sub_service = SubscriptionService(session)
                await sub_service.add_eternal_tokens(user_id, estimated_tokens, "refund")

            try:
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=progress_msg_id,
                    text=f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Midjourney:\n{result.error}\n\n"
                         f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.",
                    parse_mode=None,
                )
            except Exception:
                pass

    except Exception as e:
        logger.error("midjourney_background_task_failed", error=str(e), user_id=user_id)
        try:
            async with async_session_maker() as session:
                sub_service = SubscriptionService(session)
                await sub_service.add_eternal_tokens(user_id, estimated_tokens, "refund")
        except Exception:
            pass

        try:
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=progress_msg_id,
                text=f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Midjourney:\n{str(e)[:200]}\n\n"
                     f"üí∞ –¢–æ–∫–µ–Ω—ã –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.",
                parse_mode=None,
            )
        except Exception:
            pass


# ======================
# MIDJOURNEY VIDEO HANDLER
# ======================

async def process_midjourney_video(message: Message, user: User, state: FSMContext):
    """Process Midjourney Video (image-to-video) generation using mj_video task type."""
    data = await state.get_data()
    prompt = data.get("photo_caption_prompt") or message.text or ""
    image_path = data.get("image_path", None)

    mj_billing = get_image_model_billing("midjourney")
    estimated_tokens = mj_billing.tokens_per_generation

    if not image_path:
        await message.answer(
            "‚ö†Ô∏è Midjourney Video —Ç—Ä–µ–±—É–µ—Ç —Ñ–æ—Ç–æ.\n\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–≤–∏–∂–µ–Ω–∏—è –≤ –ø–æ–¥–ø–∏—Å–∏."
        )
        return

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            cleanup_temp_file(image_path)
            await message.answer(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤!\n\n"
                f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤\n"
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {e.details['available']:,} —Ç–æ–∫–µ–Ω–æ–≤"
            )
            await state.clear()
            return

    progress_msg = await message.answer("üé¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–¥–µ–æ —Å Midjourney Video...")
    mj_service = MidjourneyService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Midjourney Video requires image URL - same limitation as Sora i2v
    cleanup_temp_file(image_path)
    await progress_msg.edit_text(
        "‚ö†Ô∏è **Midjourney Video –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
        "API —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ CDN —Å–µ—Ä–≤–µ—Ä.\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –¥–ª—è image-to-video:\n"
        "‚Ä¢ üåä Veo 3.1\n"
        "‚Ä¢ üé• Hailuo\n"
        "‚Ä¢ üéû Kling",
        parse_mode="Markdown"
    )
    # Refund tokens
    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        await sub_service.add_eternal_tokens(user.id, estimated_tokens, "refund")

    await state.update_data(image_path=None, photo_caption_prompt=None)
