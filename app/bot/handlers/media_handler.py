#!/usr/bin/env python3
# coding: utf-8

"""
Media handlers for video, audio, and image generation.
"""

from aiogram import Router, F
from aiogram.types import CallbackQuery, Message, FSInputFile, BufferedInputFile
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
import os
from pathlib import Path
from PIL import Image
import io

from app.bot.keyboards.inline import back_to_main_keyboard
from app.database.models.user import User
from app.database.database import async_session_maker
from app.core.logger import get_logger
from app.core.exceptions import InsufficientTokensError
from app.services.video import VeoService, SoraService, LumaService, HailuoService, KlingService
from app.services.image import DalleService, GeminiImageService, StabilityService, RemoveBgService, NanoBananaService
from app.services.audio import SunoService, OpenAIAudioService
from app.services.ai.vision_service import VisionService
from app.services.subscription.subscription_service import SubscriptionService

logger = get_logger(__name__)

router = Router(name="media")


class MediaState(StatesGroup):
    waiting_for_video_prompt = State()
    waiting_for_audio_prompt = State()
    waiting_for_image_prompt = State()
    waiting_for_image = State()
    waiting_for_upscale_image = State()
    waiting_for_whisper_audio = State()
    waiting_for_vision_image = State()
    waiting_for_vision_prompt = State()
    # Photo tools states
    waiting_for_photo_upscale = State()
    waiting_for_photo_replace_bg = State()
    waiting_for_photo_remove_bg = State()
    waiting_for_photo_vectorize = State()
    # Smart input handling states
    waiting_for_photo_action_choice = State()  # User sent photo, need to choose what to do


# ======================
# VIDEO SERVICES
# ======================

@router.callback_query(F.data == "bot.veo")
async def start_veo(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸŒŠ **Veo 3.1 - Video Generation**\n\n"
        "Google Veo ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ HD Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "ðŸ“Š **ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:**\n"
        "â€¢ Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: 8 ÑÐµÐºÑƒÐ½Ð´\n"
        "â€¢ Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ: 720p\n"
        "â€¢ Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: 16:9, 9:16, 1:1, 4:3, 3:4\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~15,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ðŸŽ¨ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**\n"
        "â€¢ **Text-to-Video:** ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾\n"
        "â€¢ **Image-to-Video:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (ÑÐ¾Ð·Ð´Ð°ÑÑ‚ Ð²Ð¸Ð´ÐµÐ¾ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ„Ð¾Ñ‚Ð¾)\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð˜Ð›Ð˜ Ñ„Ð¾Ñ‚Ð¾**\n"
        "_Ð§ÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÐµÐµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ, Ñ‚ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚!_\n\n"
        "**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n"
        "â€¢ \"Ð—Ð¾Ð»Ð¾Ñ‚Ð¾Ð¹ Ñ€ÐµÑ‚Ñ€Ð¸Ð²ÐµÑ€ Ð¸Ð³Ñ€Ð°ÐµÑ‚ Ð² Ð¿Ð¾Ð»Ðµ Ð¿Ð¾Ð´ÑÐ¾Ð»Ð½ÑƒÑ…Ð¾Ð²\"\n"
        "â€¢ \"Ð§Ð°ÑˆÐºÐ° ÐºÐ¾Ñ„Ðµ Ð½Ð° Ð´ÐµÑ€ÐµÐ²ÑÐ½Ð½Ð¾Ð¼ ÑÑ‚Ð¾Ð»Ðµ, ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ ÑÐ²ÐµÑ‚\"\n"
        "â€¢ \"ÐÐ¾Ñ‡Ð½Ð¾Ð¹ Ð³Ð¾Ñ€Ð¾Ð´ Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°Ð¼Ð¸ ÑÐ²ÐµÑ‚Ð° Ð¼Ð°ÑˆÐ¸Ð½\"\n"
        "â€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾ + \"ÐžÐ¶Ð¸Ð²Ð¸ ÑÑ‚Ð¾ Ñ„Ð¾Ñ‚Ð¾, Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ\""
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="veo")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.sora")
async def start_sora(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "**Sora 2 - Video Generation**\n\n"
        "Sora 2 Ð¼Ð¾Ð¶ÐµÑ‚ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ Ð´Ð¾ 20 ÑÐµÐºÑƒÐ½Ð´ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~15,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="sora")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.luma")
async def start_luma(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸŒ™ **Luma Dream Machine**\n\n"
        "Luma ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~8,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ðŸŽ¨ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**\n"
        "â€¢ **Text-to-Video:** ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾\n"
        "â€¢ **Image-to-Video:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð˜Ð›Ð˜ Ñ„Ð¾Ñ‚Ð¾**"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="luma")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.hailuo")
async def start_hailuo(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Hailuo (MiniMax)\n\n"
        "Hailuo ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾.\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~7,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="hailuo")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.kling")
async def start_kling(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "âœ¨ **Kling AI**\n\n"
        "Kling ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð²Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾.\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~9,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ðŸŽ¨ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**\n"
        "â€¢ **Text-to-Video:** ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾\n"
        "â€¢ **Image-to-Video:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð˜Ð›Ð˜ Ñ„Ð¾Ñ‚Ð¾**"
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="kling")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.kling_effects")
async def start_kling_effects(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Kling Effects\n\n"
        "Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð°Ð¼Ð¸ Ð¾Ñ‚ Kling AI.\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~10,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð²Ð¸Ð´ÐµÐ¾\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¾Ð¼."
    )

    await state.set_state(MediaState.waiting_for_video_prompt)
    await state.update_data(service="kling_effects")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# IMAGE GENERATION
# ======================

@router.callback_query(F.data == "bot.gpt_image")
async def start_gpt_image(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "**GPT Image (DALL-E 3)**\n\n"
        "Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "ðŸ“Š **ÐœÐ¾Ð´ÐµÐ»Ð¸:**\n"
        "â€¢ DALL-E 3 (HD ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾)\n"
        "â€¢ DALL-E 3 (ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚)\n"
        "â€¢ DALL-E 2\n\n"
        "**Ð Ð°Ð·Ð¼ÐµÑ€Ñ‹:** 1024x1024, 1792x1024, 1024x1792\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** 4,000-8,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
        "ðŸŽ¨ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**\n"
        "â€¢ **Text-to-Image:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ\n"
        "â€¢ **Image Variation (DALL-E 2):** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¹\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð˜Ð›Ð˜ Ñ„Ð¾Ñ‚Ð¾**"
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="dalle")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.nano")
async def start_nano(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸŒ **Nano Banana (Gemini 2.5 Flash Image)**\n\n"
        "Gemini 2.5 Flash Image ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "ðŸ“Š **ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:**\n"
        "â€¢ Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: 1:1, 16:9, 9:16, 3:4, 4:3\n"
        "â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~3,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
        "ðŸŽ¨ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**\n"
        "â€¢ **Text-to-Image:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ\n"
        "â€¢ **Image-to-Image:** ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (ÑÐ¾Ð·Ð´Ð°ÑÑ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐµÐ³Ð¾ Ñ„Ð¾Ñ‚Ð¾)\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð˜Ð›Ð˜ Ñ„Ð¾Ñ‚Ð¾**\n\n"
        "**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n"
        "â€¢ \"ÐšÐ¾Ñ‚ Ð² ÐºÐ¾ÑÐ¼Ð¾ÑÐµ ÑÑ€ÐµÐ´Ð¸ Ð·Ð²Ñ‘Ð·Ð´\"\n"
        "â€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾ + \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð² ÑÑ‚Ð¸Ð»Ðµ Ð°Ð½Ð¸Ð¼Ðµ\""
    )

    await state.set_state(MediaState.waiting_for_image_prompt)
    await state.update_data(service="nano_banana")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.midjourney")
async def start_midjourney(callback: CallbackQuery):
    """Midjourney stub - under development."""
    text = (
        "ðŸŒ† **Midjourney**\n\n"
        "âš ï¸ **Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ**\n\n"
        "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Midjourney Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.\n"
        "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐµÑ€Ð²Ð¸ÑÑ‹:\n\n"
        "â€¢ ðŸŒ Nano Banana (Gemini 2.5 Flash)\n"
        "â€¢ ðŸ–¼ DALLÂ·E 3\n\n"
        "Ð¡Ð»ÐµÐ´Ð¸Ñ‚Ðµ Ð·Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸ÑÐ¼Ð¸!"
    )
    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("âš ï¸ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ", show_alert=False)


@router.callback_query(F.data == "bot_stable_diffusion")
async def start_stable_diffusion(callback: CallbackQuery):
    """Stable Diffusion stub - under development."""
    text = (
        "ðŸ–Œ **Stable Diffusion**\n\n"
        "âš ï¸ **Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ**\n\n"
        "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Stable Diffusion Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.\n"
        "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐµÑ€Ð²Ð¸ÑÑ‹:\n\n"
        "â€¢ ðŸŒ Nano Banana (Gemini 2.5 Flash)\n"
        "â€¢ ðŸ–¼ DALLÂ·E 3\n\n"
        "Ð¡Ð»ÐµÐ´Ð¸Ñ‚Ðµ Ð·Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸ÑÐ¼Ð¸!"
    )
    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("âš ï¸ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ", show_alert=False)


@router.callback_query(F.data == "bot.recraft")
async def start_recraft(callback: CallbackQuery):
    """Recraft stub - under development."""
    text = (
        "ðŸŽ¨ **Recraft**\n\n"
        "âš ï¸ **Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ**\n\n"
        "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Recraft Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.\n"
        "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐµÑ€Ð²Ð¸ÑÑ‹:\n\n"
        "â€¢ ðŸŒ Nano Banana (Gemini 2.5 Flash)\n"
        "â€¢ ðŸ–¼ DALLÂ·E 3\n\n"
        "Ð¡Ð»ÐµÐ´Ð¸Ñ‚Ðµ Ð·Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸ÑÐ¼Ð¸!"
    )
    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer("âš ï¸ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ", show_alert=False)


# ======================
# AUDIO SERVICES
# ======================

@router.callback_query(F.data == "bot.suno")
async def start_suno(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Suno AI â€“ Music Generation\n\n"
        "Suno ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½ÑƒÑŽ Ð¼ÑƒÐ·Ñ‹ÐºÑƒ Ð¸ Ð¿ÐµÑÐ½Ð¸ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~5,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ñ‚Ñ€ÐµÐº\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸.\n\n"
        "ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\n"
        "- Ð­Ð½ÐµÑ€Ð³Ð¸Ñ‡Ð½Ð°Ñ Ñ€Ð¾Ðº-ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ\n"
        "- Ð¡Ð¿Ð¾ÐºÐ¾Ð¹Ð½Ð°Ñ Ð´Ð¶Ð°Ð·Ð¾Ð²Ð°Ñ Ð¼ÐµÐ»Ð¾Ð´Ð¸Ñ\n"
        "- Ð¢Ð°Ð½Ñ†ÐµÐ²Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ»ÐµÐºÑ‚Ñ€Ð¾-Ñ‚Ñ€ÐµÐº"
    )

    await state.set_state(MediaState.waiting_for_audio_prompt)
    await state.update_data(service="suno")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.whisper")
async def start_whisper(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸŽ™ **Whisper - Ð Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ° Ð³Ð¾Ð»Ð¾ÑÐ°**\n\n"
        "OpenAI Whisper Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÐµÑ‚ Ñ€ÐµÑ‡ÑŒ Ð¸ Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐµÑ‘ Ð² Ñ‚ÐµÐºÑÑ‚.\n\n"
        "ðŸ“Š **Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸:**\n"
        "â€¢ Ð¢Ð¾Ñ‡Ð½Ð°Ñ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ° Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÑÐ·Ñ‹ÐºÐ°Ñ…\n"
        "â€¢ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð²\n"
        "â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~1,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ Ð°ÑƒÐ´Ð¸Ð¾\n\n"
        "ðŸŽµ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸Ð»Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ**"
    )

    await state.set_state(MediaState.waiting_for_whisper_audio)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.whisper_tts")
async def start_tts(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸ—£ **OpenAI TTS â€“ Text to Speech**\n\n"
        "ÐŸÑ€ÐµÐ²Ñ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ð² ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ.\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~200 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð·Ð°Ð¿Ñ€Ð¾Ñ\n\n"
        "ðŸŽ¤ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð³Ð¾Ð»Ð¾ÑÐ°:**\n"
        "â€¢ alloy - ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð³Ð¾Ð»Ð¾Ñ\n"
        "â€¢ echo - ÐœÑƒÐ¶ÑÐºÐ¾Ð¹ Ð³Ð¾Ð»Ð¾Ñ\n"
        "â€¢ fable - Ð‘Ñ€Ð¸Ñ‚Ð°Ð½ÑÐºÐ¸Ð¹ Ð°ÐºÑ†ÐµÐ½Ñ‚\n"
        "â€¢ onyx - Ð“Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹ Ð¼ÑƒÐ¶ÑÐºÐ¾Ð¹\n"
        "â€¢ nova - Ð–ÐµÐ½ÑÐºÐ¸Ð¹ Ð³Ð¾Ð»Ð¾Ñ\n"
        "â€¢ shimmer - ÐœÑÐ³ÐºÐ¸Ð¹ Ð¶ÐµÐ½ÑÐºÐ¸Ð¹\n\n"
        "âœï¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸**"
    )

    await state.set_state(MediaState.waiting_for_audio_prompt)
    await state.update_data(service="tts")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.gpt_vision")
async def start_gpt_vision(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "ðŸ‘ **GPT Image 1 - ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹**\n\n"
        "GPT-4 Vision Ð¼Ð¾Ð¶ÐµÑ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾ Ð½Ð¸Ñ….\n\n"
        "ðŸ“Š **Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸:**\n"
        "â€¢ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð³Ð¾\n"
        "â€¢ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°\n"
        "â€¢ ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²\n"
        "â€¢ ÐžÑ‚Ð²ÐµÑ‚Ñ‹ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾Ð± Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸\n\n"
        "ðŸ’° **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~1,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð·Ð° Ð·Ð°Ð¿Ñ€Ð¾Ñ\n\n"
        "ðŸ“¸ **ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°**"
    )

    await state.set_state(MediaState.waiting_for_vision_image)

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# IMAGE PROCESSING
# ======================

@router.callback_query(F.data == "bot.pi_upscale")
async def start_upscale(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ñ„Ð¾Ñ‚Ð¾\n\n"
        "Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸ ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~2,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ."
    )

    await state.set_state(MediaState.waiting_for_upscale_image)
    await state.update_data(service="upscale")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_remb")
async def start_remove_bg(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð½Ð°\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~500 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð°."
    )

    await state.set_state(MediaState.waiting_for_image)
    await state.update_data(service="remove_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


@router.callback_query(F.data == "bot.pi_repb")
async def start_replace_bg(callback: CallbackQuery, state: FSMContext, user: User):
    text = (
        "Ð—Ð°Ð¼ÐµÐ½Ð° Ñ„Ð¾Ð½Ð°\n\n"
        "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ~500 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ, Ð·Ð°Ñ‚ÐµÐ¼ ÑƒÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚ Ñ„Ð¾Ð½Ð° (white, black, #FF5733)."
    )

    await state.set_state(MediaState.waiting_for_image)
    await state.update_data(service="replace_bg")

    await callback.message.edit_text(text, reply_markup=back_to_main_keyboard())
    await callback.answer()


# ======================
# FSM HANDLERS - VIDEO
# ======================

@router.message(MediaState.waiting_for_video_prompt, F.photo)
async def process_video_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-video generation."""
    data = await state.get_data()
    service_name = data.get("service", "veo")

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"video_input_{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Save image path to state
    await state.update_data(image_path=str(temp_path))

    # Check if photo has caption (description)
    if message.caption and message.caption.strip():
        # User sent photo with description - process immediately
        # Update message text to be the caption for processing
        original_text = message.text
        message.text = message.caption.strip()

        # Route to appropriate video service
        if service_name == "veo":
            await process_veo_video(message, user, state)
        elif service_name == "sora":
            await process_sora_video(message, user, state)
        elif service_name == "luma":
            await process_luma_video(message, user, state)
        elif service_name == "hailuo":
            await process_hailuo_video(message, user, state)
        elif service_name == "kling":
            await process_kling_video(message, user, state)
        elif service_name == "kling_effects":
            await process_kling_effects(message, user, state)

        # Restore original text
        message.text = original_text
    else:
        # No caption - ask for description
        await message.answer(
            "âœ… Ð¤Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!\n\n"
            "ðŸ“ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾.\n\n"
            "**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n"
            "â€¢ \"ÐžÐ¶Ð¸Ð²Ð¸ ÑÑ‚Ð¾ Ñ„Ð¾Ñ‚Ð¾, Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð¿Ð»Ð°Ð²Ð½Ð¾Ðµ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ\"\n"
            "â€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ‚Ð°Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð¾Ð»Ð¾ÑÑ‹ Ñ€Ð°Ð·Ð²ÐµÐ²Ð°Ð»Ð¸ÑÑŒ Ð½Ð° Ð²ÐµÑ‚Ñ€Ñƒ\"\n"
            "â€¢ \"Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¿Ð°Ð´Ð°ÑŽÑ‰Ð¸Ðµ ÑÐ½ÐµÐ¶Ð¸Ð½ÐºÐ¸ Ð¸ Ð¿Ð»Ð°Ð²Ð½Ð¾Ðµ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ð¼ÐµÑ€Ñ‹\""
        )


@router.message(MediaState.waiting_for_video_prompt, F.text)
async def process_video_prompt(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service_name = data.get("service", "sora")

    display_names = {
        "veo": "Veo 3.1",
        "sora": "Sora 2",
        "luma": "Luma Dream Machine",
        "hailuo": "Hailuo",
        "kling": "Kling AI",
        "kling_effects": "Kling Effects"
    }
    display = display_names.get(service_name, service_name)

    # Route to appropriate video service
    if service_name == "veo":
        await process_veo_video(message, user, state)
    elif service_name == "sora":
        await process_sora_video(message, user, state)
    elif service_name == "luma":
        await process_luma_video(message, user, state)
    elif service_name == "hailuo":
        await process_hailuo_video(message, user, state)
    elif service_name == "kling" or service_name == "kling_effects":
        await process_kling_video(message, user, state, is_effects=(service_name == "kling_effects"))
    else:
        await message.answer(
            f"Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ({display}) Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ.\n"
            f"Ð’Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½: {message.text[:100]}..."
        )
        await state.clear()


async def process_veo_video(message: Message, user: User, state: FSMContext):
    """Process Veo video generation."""
    prompt = message.text

    # Get state data (check if image was provided)
    data = await state.get_data()
    image_path = data.get("image_path", None)

    # Check and use tokens
    estimated_tokens = 15000  # Veo is expensive

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path and os.path.exists(image_path):
                try:
                    os.remove(image_path)
                except Exception:
                    pass

            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"ðŸŽ¬ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Veo 3.1 ({mode_text})...")

    # Create service
    veo_service = VeoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate video
    result = await veo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress,
        duration=8,
        aspect_ratio="16:9",
        resolution="720p",
        image_path=image_path
    )

    if result.success:

        # Send video
        video_file = FSInputFile(result.video_path)
        mode_info = "Image-to-Video" if image_path else "Text-to-Video"
        await message.answer_video(
            video=video_file,
            caption=f"âœ… Ð’Ð¸Ð´ÐµÐ¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                    f"Ð ÐµÐ¶Ð¸Ð¼: {mode_info}\n"
                    f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )

        # Clean up
        try:
            os.remove(result.video_path)
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_sora_video(message: Message, user: User, state: FSMContext):
    """Process Sora 2 video generation."""
    prompt = message.text
    estimated_tokens = 15000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²"
            )
            await state.clear()
            return

    progress_msg = await message.answer("ðŸŽ¬ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Sora 2...")
    sora_service = SoraService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await sora_service.generate_video(
        prompt=prompt,
        model="sora-2",
        progress_callback=update_progress
    )

    if result.success:
        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=f"âœ… Ð’Ð¸Ð´ÐµÐ¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\nÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\nÐ¢Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )
        try:
            os.remove(result.video_path)
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))
        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_luma_video(message: Message, user: User, state: FSMContext):
    """Process Luma Dream Machine video generation."""
    prompt = message.text

    # Get state data (check if image was provided)
    data = await state.get_data()
    image_path = data.get("image_path", None)

    estimated_tokens = 8000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path and os.path.exists(image_path):
                try:
                    os.remove(image_path)
                except Exception:
                    pass

            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²"
            )
            await state.clear()
            return

    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"ðŸŽ¬ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Luma Dream Machine ({mode_text})...")
    luma_service = LumaService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Prepare keyframes if image provided
    keyframes = None
    if image_path:
        try:
            # For Luma, we need to create keyframes dict with image
            # According to Luma API, keyframes can be {"frame0": {"type": "image", "url": "..."}}
            # Since we have local file, we'll need to upload it or convert to base64
            # For now, we'll just pass the image_path and let the service handle it
            keyframes = {"frame0": {"type": "image", "path": image_path}}
        except Exception as e:
            logger.error("luma_keyframes_preparation_failed", error=str(e))

    result = await luma_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress,
        keyframes=keyframes
    )

    if result.success:
        video_file = FSInputFile(result.video_path)
        mode_info = "Image-to-Video" if image_path else "Text-to-Video"
        await message.answer_video(
            video=video_file,
            caption=f"âœ… Ð’Ð¸Ð´ÐµÐ¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\nÐ ÐµÐ¶Ð¸Ð¼: {mode_info}\nÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\nÐ¢Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )
        try:
            os.remove(result.video_path)
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        try:
            await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_hailuo_video(message: Message, user: User, state: FSMContext):
    """Process Hailuo (MiniMax) video generation."""
    prompt = message.text
    estimated_tokens = 7000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²"
            )
            await state.clear()
            return

    progress_msg = await message.answer("ðŸŽ¬ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Hailuo AI...")
    hailuo_service = HailuoService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    result = await hailuo_service.generate_video(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        video_file = FSInputFile(result.video_path)
        await message.answer_video(
            video=video_file,
            caption=f"âœ… Ð’Ð¸Ð´ÐµÐ¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\nÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\nÐ¢Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )
        try:
            os.remove(result.video_path)
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))
        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_kling_video(message: Message, user: User, state: FSMContext, is_effects: bool = False):
    """Process Kling AI video generation."""
    prompt = message.text

    # Get state data (check if image was provided)
    data = await state.get_data()
    image_path = data.get("image_path", None)

    estimated_tokens = 10000 if is_effects else 9000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)
        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up image if exists
            if image_path and os.path.exists(image_path):
                try:
                    os.remove(image_path)
                except Exception:
                    pass

            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²"
            )
            await state.clear()
            return

    service_name = "Kling Effects" if is_effects else "Kling AI"
    mode_text = "image-to-video" if image_path else "text-to-video"
    progress_msg = await message.answer(f"ðŸŽ¬ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ {service_name} ({mode_text})...")
    kling_service = KlingService()

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # For Kling, we would need to upload the image first or provide URL
    # For simplicity, we'll pass image_path and let service handle upload if needed
    kwargs = {}
    if image_path:
        # Note: Kling API expects image_url, so service needs to handle upload
        # For now, we'll pass the local path as image_url parameter
        kwargs["image_url"] = image_path

    result = await kling_service.generate_video(
        prompt=prompt,
        model="kling-v1.6-pro",
        progress_callback=update_progress,
        **kwargs
    )

    if result.success:
        video_file = FSInputFile(result.video_path)
        mode_info = "Image-to-Video" if image_path else "Text-to-Video"
        await message.answer_video(
            video=video_file,
            caption=f"âœ… Ð’Ð¸Ð´ÐµÐ¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\nÐ ÐµÐ¶Ð¸Ð¼: {mode_info}\nÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\nÐ¢Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )
        try:
            os.remove(result.video_path)
        except Exception as e:
            logger.error("video_cleanup_failed", error=str(e))

        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        # Clean up input image if exists
        if image_path and os.path.exists(image_path):
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error("input_image_cleanup_failed", error=str(e))

        try:
            await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {result.error}", parse_mode=None)
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE GENERATION
# ======================

@router.message(MediaState.waiting_for_image_prompt, F.photo)
async def process_image_photo(message: Message, state: FSMContext, user: User):
    """Handle photo for image-to-image generation."""
    data = await state.get_data()
    service_name = data.get("service", "nano_banana")

    # Download the photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"image_input_{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Save image path to state
    await state.update_data(reference_image_path=str(temp_path))

    service_display = {
        "nano_banana": "Nano Banana",
        "dalle": "DALL-E"
    }.get(service_name, service_name)

    # Check if photo has caption (description)
    if message.caption and message.caption.strip():
        # User sent photo with description - process immediately
        # Update message text to be the caption for processing
        original_text = message.text
        message.text = message.caption.strip()

        # Route to appropriate image service
        if service_name == "dalle":
            await process_dalle_image(message, user, state)
        elif service_name == "gemini_image":
            await process_gemini_image(message, user, state)
        elif service_name == "nano_banana":
            await process_nano_image(message, user, state)

        # Restore original text
        message.text = original_text
    else:
        # No caption - ask for description
        await message.answer(
            f"âœ… Ð¤Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!\n\n"
            f"ðŸ“ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾.\n\n"
            f"**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð´Ð»Ñ {service_display}:**\n"
            "â€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð² ÑÑ‚Ð¸Ð»Ðµ Ð°Ð½Ð¸Ð¼Ðµ\"\n"
            "â€¢ \"ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐ¹ Ð² Ð°ÐºÐ²Ð°Ñ€ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð¸ÑÑƒÐ½Ð¾Ðº\"\n"
            "â€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ„Ð¾Ð½ ÐºÐ¾ÑÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼\"\n"
            "â€¢ \"ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐ¹ Ð² ÑÑ‚Ð¸Ð»ÑŒ Ð’Ð°Ð½ Ð“Ð¾Ð³Ð°\""
        )


@router.message(MediaState.waiting_for_image_prompt, F.text)
async def process_image_prompt(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service_name = data.get("service", "dalle")

    if service_name == "dalle":
        await process_dalle_image(message, user, state)
    elif service_name == "gemini_image":
        await process_gemini_image(message, user, state)
    elif service_name == "nano_banana":
        await process_nano_image(message, user, state)
    else:
        await message.answer(
            f"Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ.\n"
            f"Ð’Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½: {message.text[:100]}..."
        )
        await state.clear()


async def process_dalle_image(message: Message, user: User, state: FSMContext):
    """Process DALL-E image generation or variation."""
    prompt = message.text

    # Get state data (check if reference image was provided)
    data = await state.get_data()
    reference_image_path = data.get("reference_image_path", None)

    # Check and use tokens
    estimated_tokens = 2000 if reference_image_path else 4000  # Variations are cheaper

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up reference image if exists
            if reference_image_path and os.path.exists(reference_image_path):
                try:
                    os.remove(reference_image_path)
                except Exception:
                    pass

            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Create service
    dalle_service = DalleService()

    # Determine operation mode
    if reference_image_path:
        # Image variation mode (DALL-E 2 only)
        progress_msg = await message.answer("ðŸŽ¨ Ð¡Ð¾Ð·Ð´Ð°ÑŽ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ DALL-E 2...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Create variation
        result = await dalle_service.create_variation(
            image_path=reference_image_path,
            progress_callback=update_progress,
            model="dall-e-2",
            size="1024x1024"
        )
    else:
        # Text-to-image mode
        progress_msg = await message.answer("ðŸŽ¨ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ DALL-E 3...")

        # Progress callback
        async def update_progress(text: str):
            try:
                await progress_msg.edit_text(text, parse_mode=None)
            except Exception:
                pass

        # Generate image
        result = await dalle_service.generate_image(
            prompt=prompt,
            progress_callback=update_progress,
            model="dall-e-3",
            size="1024x1024",
            quality="standard",
            style="vivid"
        )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Send image
        image_file = FSInputFile(result.image_path)
        caption_text = "âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
        if reference_image_path:
            caption_text += "Ð ÐµÐ¶Ð¸Ð¼: Image Variation (DALL-E 2)\n"
        else:
            caption_text += f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
        caption_text += f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"

        await message.answer_photo(
            photo=image_file,
            caption=caption_text
        )

        # Clean up
        try:
            os.remove(result.image_path)
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        # Clean up reference image if exists
        if reference_image_path and os.path.exists(reference_image_path):
            try:
                os.remove(reference_image_path)
            except Exception as e:
                logger.error("reference_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        # Clean up reference image if exists
        if reference_image_path and os.path.exists(reference_image_path):
            try:
                os.remove(reference_image_path)
            except Exception as e:
                logger.error("reference_image_cleanup_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_gemini_image(message: Message, user: User, state: FSMContext):
    """Process Gemini/Imagen image generation."""
    prompt = message.text

    # Check and use tokens
    estimated_tokens = 3000  # Imagen 3

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸŽ¨ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Create service
    gemini_service = GeminiImageService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await gemini_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        aspect_ratio="1:1"
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Send image
        image_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=image_file,
            caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                    f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
        )

        # Clean up
        try:
            os.remove(result.image_path)
        except Exception as e:
            logger.error("image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


async def process_nano_image(message: Message, user: User, state: FSMContext):
    """Process Nano Banana (Gemini 2.5 Flash Image) image generation."""
    prompt = message.text

    # Get state data (check if reference image was provided)
    data = await state.get_data()
    reference_image_path = data.get("reference_image_path", None)

    # Check and use tokens
    estimated_tokens = 3000  # Nano Banana cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            # Clean up reference image if exists
            if reference_image_path and os.path.exists(reference_image_path):
                try:
                    os.remove(reference_image_path)
                except Exception:
                    pass

            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    mode_text = "image-to-image" if reference_image_path else "text-to-image"
    progress_msg = await message.answer(f"ðŸŒ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Nano Banana ({mode_text})...")

    # Create service
    nano_service = NanoBananaService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate image
    result = await nano_service.generate_image(
        prompt=prompt,
        progress_callback=update_progress,
        aspect_ratio="1:1",
        reference_image_path=reference_image_path
    )

    if result.success:
        tokens_used = result.metadata.get("tokens_used", estimated_tokens)

        # Optimize and send image
        try:
            # Check file size
            file_size = os.path.getsize(result.image_path)
            logger.info("nano_image_file_size", path=result.image_path, size=file_size)

            # If file is too large (>2MB) or to ensure compatibility, optimize it
            if file_size > 2 * 1024 * 1024:  # 2MB
                logger.info("nano_image_optimizing", original_size=file_size)

                # Open image with PIL
                img = Image.open(result.image_path)

                # Convert RGBA to RGB if needed (for JPEG)
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                    img = background

                # Save as JPEG with quality reduction
                buffer = io.BytesIO()
                quality = 85
                img.save(buffer, format='JPEG', quality=quality, optimize=True)
                buffer.seek(0)

                optimized_size = buffer.getbuffer().nbytes
                logger.info("nano_image_optimized", original_size=file_size, new_size=optimized_size, quality=quality)

                # Send optimized image
                photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                await message.answer_photo(
                    photo=photo,
                    caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                            f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                            f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
                )
            else:
                # Try sending original PNG first
                try:
                    image_file = FSInputFile(result.image_path)
                    await message.answer_photo(
                        photo=image_file,
                        caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                                f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                                f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
                    )
                except Exception as send_error:
                    logger.warning("nano_image_send_as_photo_failed", error=str(send_error))

                    # If sending as photo fails, try optimizing and re-sending
                    img = Image.open(result.image_path)

                    # Convert to RGB if needed
                    if img.mode in ('RGBA', 'LA', 'P'):
                        background = Image.new('RGB', img.size, (255, 255, 255))
                        if img.mode == 'P':
                            img = img.convert('RGBA')
                        background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                        img = background

                    # Save as JPEG
                    buffer = io.BytesIO()
                    img.save(buffer, format='JPEG', quality=90, optimize=True)
                    buffer.seek(0)

                    logger.info("nano_image_converted_to_jpeg", original_format="PNG")

                    photo = BufferedInputFile(buffer.read(), filename="image.jpg")
                    await message.answer_photo(
                        photo=photo,
                        caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                                f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                                f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
                    )

        except Exception as send_error:
            logger.error("nano_image_send_failed", error=str(send_error))
            # Last resort: try sending as document
            try:
                doc_file = FSInputFile(result.image_path)
                await message.answer_document(
                    document=doc_file,
                    caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ (Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾ ÐºÐ°Ðº Ñ„Ð°Ð¹Ð»)!\n\n"
                            f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                            f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
                )
            except Exception as doc_error:
                logger.error("nano_image_send_as_document_failed", error=str(doc_error))
                await message.answer(
                    f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¾, Ð½Ð¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ.\n"
                    f"Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ.\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used:,}"
                )

        # Clean up
        try:
            os.remove(result.image_path)
        except Exception as e:
            logger.error("nano_image_cleanup_failed", error=str(e))

        # Clean up reference image if exists
        if reference_image_path and os.path.exists(reference_image_path):
            try:
                os.remove(reference_image_path)
            except Exception as e:
                logger.error("reference_image_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        # Clean up reference image if exists
        if reference_image_path and os.path.exists(reference_image_path):
            try:
                os.remove(reference_image_path)
            except Exception as e:
                logger.error("reference_image_cleanup_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - AUDIO
# ======================

@router.message(MediaState.waiting_for_audio_prompt, F.text)
async def process_audio_prompt(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service_name = data.get("service", "suno")

    if service_name == "suno":
        await process_suno_audio(message, user, state)
    elif service_name == "tts":
        await process_tts_audio(message, user, state)
    else:
        display = {
            "suno": "Suno AI",
            "tts": "OpenAI TTS"
        }.get(service_name, service_name)

        await message.answer(
            f"Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð°ÑƒÐ´Ð¸Ð¾ ({display}) Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ.\n"
            f"Ð’Ð°Ñˆ Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½: {message.text[:100]}..."
        )
        await state.clear()


async def process_suno_audio(message: Message, user: User, state: FSMContext):
    """Process Suno AI music generation."""
    prompt = message.text

    # Check and use tokens
    estimated_tokens = 5000  # Suno AI cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸŽµ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸ Ñ Suno AI...")

    # Create service
    suno_service = SunoService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate music
    result = await suno_service.generate_audio(
        prompt=prompt,
        progress_callback=update_progress
    )

    if result.success:
        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=f"âœ… ÐœÑƒÐ·Ñ‹ÐºÐ° Ð³Ð¾Ñ‚Ð¾Ð²Ð°!\n\n"
                    f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt[:200]}\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}",
            title=f"Suno AI - {prompt[:50]}"
        )

        # Clean up
        try:
            os.remove(result.audio_path)
        except Exception as e:
            logger.error("suno_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - IMAGE PROCESSING
# ======================

@router.message(MediaState.waiting_for_image, F.photo)
async def process_image(message: Message, state: FSMContext, user: User):
    data = await state.get_data()
    service = data.get("service", "remove_bg")

    display = {
        "remove_bg": "Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð½Ð°",
        "replace_bg": "Ð—Ð°Ð¼ÐµÐ½Ð° Ñ„Ð¾Ð½Ð°"
    }.get(service, service)

    await message.answer(
        f"Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ({display}) Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ.\n"
        "Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!"
    )
    await state.clear()


@router.message(MediaState.waiting_for_upscale_image, F.photo)
async def process_upscale(message: Message, state: FSMContext, user: User):
    """Process image upscaling."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 2000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    stability_service = StabilityService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Upscale image
    result = await stability_service.upscale_image(
        image_path=str(temp_path),
        scale_factor=2,
        progress_callback=update_progress
    )

    # Clean up temp file
    try:
        os.remove(temp_path)
    except Exception:
        pass

    if result.success:

        # Send upscaled image
        upscaled_file = FSInputFile(result.image_path)
        await message.answer_photo(
            photo=upscaled_file,
            caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¾!\n\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
        )

        # Clean up
        try:
            os.remove(result.image_path)
        except Exception as e:
            logger.error("upscale_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - WHISPER (VOICE TRANSCRIPTION)
# ======================

@router.message(MediaState.waiting_for_whisper_audio, F.voice | F.audio)
async def process_whisper_audio(message: Message, state: FSMContext, user: User):
    """Process Whisper audio transcription."""

    # Check and use tokens
    estimated_tokens = 1000  # Whisper cost per minute

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð°ÑƒÐ´Ð¸Ð¾...")

    # Download audio
    if message.voice:
        file = await message.bot.get_file(message.voice.file_id)
        file_ext = "ogg"
    else:
        file = await message.bot.get_file(message.audio.file_id)
        file_ext = "mp3"

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"{file.file_id}.{file_ext}"

    await message.bot.download_file(file.file_path, temp_path)

    # Create service
    whisper_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    await update_progress("ðŸŽ™ï¸ Ð Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ñ‹Ð²Ð°ÑŽ Ð°ÑƒÐ´Ð¸Ð¾...")

    # Transcribe audio
    result = await whisper_service.transcribe(
        audio_path=str(temp_path),
        language="ru"  # Russian language
    )

    # Clean up temp file
    try:
        os.remove(temp_path)
    except Exception:
        pass

    if result.success:
        # Send transcription
        await message.answer(
            f"âœ… **Ð Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ° Ð³Ð¾Ñ‚Ð¾Ð²Ð°!**\n\n"
            f"ðŸ“ **Ð¢ÐµÐºÑÑ‚:**\n{result.text}\n\n"
            f"ðŸ’° Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - TTS UPDATE
# ======================

async def process_tts_audio(message: Message, user: User, state: FSMContext):
    """Process OpenAI TTS generation."""
    text = message.text

    if len(text) > 4096:
        await message.answer("âŒ Ð¢ÐµÐºÑÑ‚ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹! ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 4096 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 200  # TTS cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸŽ™ï¸ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ...")

    # Create service
    tts_service = OpenAIAudioService()

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Generate audio (default voice: alloy)
    result = await tts_service.generate_audio(
        prompt=text,
        voice="alloy",
        model="tts-1",
        progress_callback=update_progress
    )

    if result.success:
        # Send audio
        audio_file = FSInputFile(result.audio_path)
        await message.answer_audio(
            audio=audio_file,
            caption=f"âœ… ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° Ð³Ð¾Ñ‚Ð¾Ð²Ð°!\n\n"
                    f"Ð“Ð¾Ð»Ð¾Ñ: alloy\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}",
            title="OpenAI TTS"
        )

        # Clean up
        try:
            os.remove(result.audio_path)
        except Exception as e:
            logger.error("tts_audio_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð°ÑƒÐ´Ð¸Ð¾:\n{result.error}",
                parse_mode=None
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# FSM HANDLERS - GPT VISION (IMAGE ANALYSIS)
# ======================

@router.message(MediaState.waiting_for_vision_image, F.photo)
async def process_vision_image(message: Message, state: FSMContext, user: User):
    """Receive image and ask for analysis prompt."""
    # Get the largest photo
    photo = message.photo[-1]

    # Send progress message
    progress_msg = await message.answer("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Store image path in state
    await state.update_data(image_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_vision_prompt)

    await progress_msg.edit_text(
        "âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!\n\n"
        "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸Ð»Ð¸ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.\n\n"
        "**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n"
        "â€¢ Ð§Ñ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¾ Ð½Ð° ÑÑ‚Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐµ?\n"
        "â€¢ ÐžÐ¿Ð¸ÑˆÐ¸ ÑÑ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾\n"
        "â€¢ ÐšÐ°ÐºÐ¾Ð¹ Ñ‚ÐµÐºÑÑ‚ ÐµÑÑ‚ÑŒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸?\n"
        "â€¢ Ð§Ñ‚Ð¾ Ð·Ð° Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ñ‹?"
    )


@router.message(MediaState.waiting_for_vision_prompt, F.text)
async def process_vision_prompt(message: Message, state: FSMContext, user: User):
    """Process GPT Vision image analysis."""
    data = await state.get_data()
    image_path = data.get("image_path")
    prompt = message.text

    if not image_path or not os.path.exists(image_path):
        await message.answer("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.")
        await state.clear()
        return

    # Check and use tokens
    estimated_tokens = 1000  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            # Clean up temp file
            try:
                os.remove(image_path)
            except Exception:
                pass
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸ‘ ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1000,
        detail="auto"
    )

    # Clean up temp file
    try:
        os.remove(image_path)
    except Exception as e:
        logger.error("vision_image_cleanup_failed", error=str(e))

    if result.success:
        # Send analysis
        await message.answer(
            f"âœ… **ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð³Ð¾Ñ‚Ð¾Ð²!**\n\n"
            f"ðŸ“ **ÐžÑ‚Ð²ÐµÑ‚:**\n{result.content}\n\n"
            f"ðŸ’° Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()


# ======================
# PHOTO TOOLS HANDLERS
# ======================

@router.message(MediaState.waiting_for_photo_upscale, F.photo)
async def process_photo_upscale(message: Message, state: FSMContext, user: User):
    """Process photo quality improvement using PIL image enhancement."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens (basic image processing is cheap)
    estimated_tokens = 500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    try:
        # Progress update
        await progress_msg.edit_text("ðŸŽ¨ Ð£Ð»ÑƒÑ‡ÑˆÐ°ÑŽ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ...", parse_mode=None)

        # Open image with PIL
        from PIL import Image, ImageEnhance, ImageFilter

        img = Image.open(temp_path)

        # Convert to RGB if needed
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            if img.mode in ('RGBA', 'LA'):
                background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = background

        # 1. Enhance sharpness
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.5)  # Increase sharpness by 50%

        # 2. Enhance contrast
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.2)  # Increase contrast by 20%

        # 3. Enhance color
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(1.1)  # Increase color saturation by 10%

        # 4. Enhance brightness slightly
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(1.05)  # Increase brightness by 5%

        # 5. Apply subtle unsharp mask for additional sharpness
        img = img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))

        # Save enhanced image
        enhanced_path = temp_dir / f"enhanced_{photo.file_id}.jpg"

        # Save with high quality
        img.save(str(enhanced_path), 'JPEG', quality=95, optimize=True)

        # Check file size and optimize if needed
        file_size = os.path.getsize(enhanced_path)
        max_size = 10 * 1024 * 1024  # 10 MB Telegram limit

        if file_size > max_size:
            logger.info("enhanced_image_too_large", size=file_size, max_size=max_size)
            # Reduce quality gradually until it fits
            quality = 90
            while file_size > max_size and quality > 60:
                img.save(str(enhanced_path), 'JPEG', quality=quality, optimize=True)
                file_size = os.path.getsize(enhanced_path)
                quality -= 5
                logger.info("enhanced_image_compressed", new_size=file_size, quality=quality)

        # Clean up original temp file
        try:
            os.remove(temp_path)
        except Exception:
            pass

        # Send enhanced image
        enhanced_file = FSInputFile(enhanced_path)
        await message.answer_photo(
            photo=enhanced_file,
            caption=f"âœ… Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¾!\n\n"
                    f"ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ñ‹ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ: Ñ€ÐµÐ·ÐºÐ¾ÑÑ‚ÑŒ, ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚, Ñ†Ð²ÐµÑ‚Ð°, ÑÑ€ÐºÐ¾ÑÑ‚ÑŒ.\n\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
        )

        # Clean up enhanced file
        try:
            os.remove(enhanced_path)
        except Exception as e:
            logger.error("enhanced_image_cleanup_failed", error=str(e))

        await progress_msg.delete()

    except Exception as e:
        # Clean up temp files on error
        try:
            os.remove(temp_path)
        except Exception:
            pass

        logger.error("photo_quality_improvement_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{str(e)}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_replace_bg, F.photo)
async def process_photo_replace_bg(message: Message, state: FSMContext, user: User):
    """Process background replacement."""
    # First, save the photo and ask for background description
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    # Save to state
    await state.update_data(saved_image_path=image_path)

    # Ask for background description
    await message.answer(
        "ðŸ“¤ Ð¤Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!\n\n"
        "âœï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ, ÐºÐ°ÐºÐ¾Ð¹ Ñ„Ð¾Ð½ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ:\n\n"
        "ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\n"
        "â€¢ Ð“Ð¾Ñ€Ð½Ñ‹Ð¹ Ð¿ÐµÐ¹Ð·Ð°Ð¶ Ñ Ð·Ð°ÑÐ½ÐµÐ¶ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð²ÐµÑ€ÑˆÐ¸Ð½Ð°Ð¼Ð¸\n"
        "â€¢ Ð¢Ñ€Ð¾Ð¿Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð»ÑÐ¶ Ñ Ð¿Ð°Ð»ÑŒÐ¼Ð°Ð¼Ð¸\n"
        "â€¢ Ð¡Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ð¾Ñ„Ð¸Ñ\n"
        "â€¢ ÐšÐ¾ÑÐ¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð¾ Ñ Ð·Ð²ÐµÐ·Ð´Ð°Ð¼Ð¸",
        reply_markup=back_to_main_keyboard()
    )


@router.message(MediaState.waiting_for_photo_replace_bg, F.text)
async def process_photo_replace_bg_prompt(message: Message, state: FSMContext, user: User):
    """Process background replacement with user-specified background."""
    data = await state.get_data()
    image_path = data.get("saved_image_path")

    if not image_path or not os.path.exists(image_path):
        await message.answer("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ„Ð¾Ñ‚Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.")
        await state.clear()
        return

    bg_description = message.text

    # Check and use tokens (RemoveBG ~1000 + DALL-E ~4000)
    estimated_tokens = 5000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ñ„Ð¾Ð½Ð°!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            # Clean up saved image
            try:
                os.remove(image_path)
            except Exception:
                pass
            await state.clear()
            return

    progress_msg = await message.answer("ðŸ–¼ï¸ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    try:
        # Step 1: Remove background
        await update_progress("ðŸ–¼ï¸ Ð£Ð´Ð°Ð»ÑÑŽ Ñ„Ð¾Ð½ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ...")

        removebg_service = RemoveBgService()
        remove_result = await removebg_service.process_image(
            image_path=image_path,
            size="auto",
            type="auto"
        )

        if not remove_result.success:
            raise Exception(f"Background removal failed: {remove_result.error}")

        # Step 2: Generate new background with DALL-E
        await update_progress("ðŸŽ¨ Ð¡Ð¾Ð·Ð´Ð°ÑŽ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ð¾Ð½...")

        background_prompt = f"A high-quality background image: {bg_description}. Professional photography, suitable as a background."

        dalle_service = DalleService()
        bg_result = await dalle_service.generate_image(
            prompt=background_prompt,
            model="dall-e-3",
            size="1024x1024",
            quality="standard",
            style="natural"
        )

        if not bg_result.success:
            # Clean up removed bg image
            try:
                os.remove(remove_result.image_path)
            except Exception:
                pass
            raise Exception(f"Background generation failed: {bg_result.error}")

        # Step 3: Composite subject onto new background
        await update_progress("ðŸ–Œï¸ ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ...")

        from PIL import Image

        # Open images
        subject_img = Image.open(remove_result.image_path)  # RGBA
        background_img = Image.open(bg_result.image_path)  # RGB

        # Resize background to match subject size
        background_img = background_img.resize(subject_img.size, Image.Resampling.LANCZOS)

        # Convert background to RGBA
        background_img = background_img.convert('RGBA')

        # Composite
        final_img = Image.alpha_composite(background_img, subject_img)

        # Convert to RGB for JPEG
        final_rgb = Image.new('RGB', final_img.size, (255, 255, 255))
        final_rgb.paste(final_img, mask=final_img.split()[3])  # Use alpha as mask

        # Save final image
        temp_dir = Path("./storage/temp")
        final_path = temp_dir / f"replaced_{os.path.basename(image_path)}"
        final_rgb.save(str(final_path), 'JPEG', quality=95, optimize=True)

        # Clean up intermediate files
        try:
            os.remove(image_path)
            os.remove(remove_result.image_path)
            os.remove(bg_result.image_path)
        except Exception as e:
            logger.error("temp_files_cleanup_failed", error=str(e))

        # Send final image
        final_file = FSInputFile(final_path)
        await message.answer_photo(
            photo=final_file,
            caption=f"âœ… Ð¤Ð¾Ð½ Ð·Ð°Ð¼ÐµÐ½Ñ‘Ð½!\n\n"
                    f"ÐÐ¾Ð²Ñ‹Ð¹ Ñ„Ð¾Ð½: {bg_description}\n\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
        )

        # Clean up final file
        try:
            os.remove(final_path)
        except Exception as e:
            logger.error("final_image_cleanup_failed", error=str(e))

        await progress_msg.delete()

    except Exception as e:
        # Clean up all temp files on error
        try:
            os.remove(image_path)
        except Exception:
            pass

        logger.error("photo_replace_bg_failed", error=str(e))

        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ñ„Ð¾Ð½Ð°:\n{str(e)}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_remove_bg, F.photo)
async def process_photo_remove_bg(message: Message, state: FSMContext, user: User):
    """Process background removal using Remove.bg API."""
    # Get the largest photo
    photo = message.photo[-1]

    # Check and use tokens
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð°!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    # Download photo
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Progress callback
    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    # Remove background
    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=str(temp_path),
        progress_callback=update_progress,
        size="auto",  # auto, preview, full
        type="auto"   # auto, person, product, car
    )

    # Clean up temp file
    try:
        os.remove(temp_path)
    except Exception:
        pass

    if result.success:
        # Send image with removed background
        result_file = FSInputFile(result.image_path)

        # Try sending as photo first
        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"âœ… Ð¤Ð¾Ð½ ÑƒÐ´Ð°Ð»Ñ‘Ð½!\n\n"
                        f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
            )
        except Exception:
            # If photo fails (transparent images sometimes do), send as document
            await message.answer_document(
                document=result_file,
                caption=f"âœ… Ð¤Ð¾Ð½ ÑƒÐ´Ð°Ð»Ñ‘Ð½!\n\n"
                        f"Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ Ñ„Ð¾Ð½Ð¾Ð¼ (PNG).\n\n"
                        f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
            )

        # Clean up
        try:
            os.remove(result.image_path)
        except Exception as e:
            logger.error("removebg_cleanup_failed", error=str(e))

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð°:\n{result.error}"
            )
        except Exception:
            pass

    await state.clear()


@router.message(MediaState.waiting_for_photo_vectorize, F.photo)
async def process_photo_vectorize(message: Message, state: FSMContext, user: User):
    """Process photo vectorization."""
    await _process_photo_tool(
        message, state, user,
        tool_name="Ð’ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ",
        prompt=(
            "Analyze this image and describe how to convert it to a vector format. "
            "Provide recommendations for: tracing method, color palette reduction, "
            "path simplification, and optimal settings for this specific image type. "
            "Suggest the best vectorization approach (outline, centerline, or full color)."
        ),
        emoji="ðŸ“"
    )


async def _process_photo_tool(message: Message, state: FSMContext, user: User,
                              tool_name: str, prompt: str, emoji: str):
    """Helper function to process photo with GPT Vision."""
    photo = message.photo[-1]
    file_info = await message.bot.get_file(photo.file_id)

    # Download photo
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
        await message.bot.download_file(file_info.file_path, tmp_file.name)
        image_path = tmp_file.name

    await _process_photo_with_path(message, state, user, image_path, tool_name, prompt, emoji)


async def _process_photo_with_path(message: Message, state: FSMContext, user: User,
                                   image_path: str, tool_name: str, prompt: str, emoji: str):
    """Process photo with given path."""
    # Check and use tokens
    estimated_tokens = 1500  # GPT-4 Vision cost

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ„Ð¾Ñ‚Ð¾!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            # Clean up temp file
            try:
                os.remove(image_path)
            except Exception:
                pass
            await state.clear()
            return

    # Send progress message
    progress_msg = await message.answer(f"{emoji} ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ„Ð¾Ñ‚Ð¾...")

    # Create service
    vision_service = VisionService()

    # Analyze image
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    try:
        os.remove(image_path)
    except Exception as e:
        logger.error("photo_tool_cleanup_failed", error=str(e))

    if result.success:
        # Send analysis
        await message.answer(
            f"âœ… **{tool_name} - ÐÐ½Ð°Ð»Ð¸Ð· Ð³Ð¾Ñ‚Ð¾Ð²!**\n\n"
            f"ðŸ“ **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸:**\n{result.content}\n\n"
            f"ðŸ’° Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )

        await progress_msg.delete()
    else:
        try:
            await progress_msg.edit_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:\n{result.error}"
            )
        except Exception:
            # Ignore errors when message is not modified
            pass

    await state.clear()

# ======================
# SMART INPUT HANDLING - No model selected
# ======================

@router.message(F.photo, ~F.state(None))
async def handle_photo_in_wrong_state(message: Message, state: FSMContext):
    """Handle photo sent in unsupported state - redirect to correct handler."""
    current_state = await state.get_state()

    # If in video/image prompt state, pass to existing handlers
    if current_state in [MediaState.waiting_for_video_prompt, MediaState.waiting_for_image_prompt]:
        return  # Let other handlers process it

    # Otherwise, clear state and treat as new photo
    await state.clear()
    await handle_photo_no_model(message, state)


@router.message(F.photo)
async def handle_photo_no_model(message: Message, state: FSMContext):
    """Handle photo sent without selecting a model first."""
    # Download and save photo
    photo = message.photo[-1]
    file = await message.bot.get_file(photo.file_id)

    # Create temp path
    temp_dir = Path("./storage/temp")
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / f"unsorted_{photo.file_id}.jpg"

    await message.bot.download_file(file.file_path, temp_path)

    # Save to state
    await state.update_data(saved_photo_path=str(temp_path))
    await state.set_state(MediaState.waiting_for_photo_action_choice)

    # Create inline keyboard for choosing action
    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ðŸŽ¬ Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾", callback_data="photo_action:video"),
            InlineKeyboardButton(text="ðŸ–¼ Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", callback_data="photo_action:image")
        ],
        [
            InlineKeyboardButton(text="ðŸ‘ ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾", callback_data="photo_action:vision"),
            InlineKeyboardButton(text="ðŸŽ¨ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð¾Ñ‚Ð¾", callback_data="photo_action:tools")
        ],
        [
            InlineKeyboardButton(text="âŒ ÐžÑ‚Ð¼ÐµÐ½Ð°", callback_data="photo_action:cancel")
        ]
    ])

    await message.answer_photo(
        photo=photo.file_id,
        caption="ðŸ“¸ **Ð¤Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!**\n\n"
                "Ð§Ñ‚Ð¾ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ñ ÑÑ‚Ð¸Ð¼ Ñ„Ð¾Ñ‚Ð¾?\n\n"
                "ðŸŽ¬ **Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾** - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ„Ð¾Ñ‚Ð¾\n"
                "ðŸ–¼ **Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ** - Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ñ„Ð¾Ñ‚Ð¾ Ð² Ð½Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\n"
                "ðŸ‘ **ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾** - Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð³Ð¾\n"
                "ðŸŽ¨ **ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð¾Ñ‚Ð¾** - ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð½Ð°, ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð¸ Ñ‚.Ð´.",
        reply_markup=keyboard
    )


@router.callback_query(F.data.startswith("photo_action:"))
async def handle_photo_action_choice(callback: CallbackQuery, state: FSMContext):
    """Handle user's choice of what to do with the photo."""
    action = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if action == "cancel":
        # Clean up photo
        if saved_photo_path and os.path.exists(saved_photo_path):
            try:
                os.remove(saved_photo_path)
            except Exception:
                pass
        await state.clear()
        await callback.message.edit_caption(
            caption="âŒ ÐžÐ¿ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð°."
        )
        await callback.answer()
        return

    if action == "video":
        # Show video models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="ðŸŒŠ Veo 3.1", callback_data="photo_video:veo"),
                InlineKeyboardButton(text="ðŸŒ™ Luma", callback_data="photo_video:luma")
            ],
            [
                InlineKeyboardButton(text="âœ¨ Kling AI", callback_data="photo_video:kling")
            ],
            [
                InlineKeyboardButton(text="â—€ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="ðŸŽ¬ **Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾:**\n\n"
                    "â€¢ **Veo 3.1** - Google, HD ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ (~15,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)\n"
                    "â€¢ **Luma** - Dream Machine (~8,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)\n"
                    "â€¢ **Kling AI** - Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ (~9,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "image":
        # Show image models
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="ðŸŒ Nano Banana", callback_data="photo_image:nano"),
                InlineKeyboardButton(text="ðŸ–¼ DALL-E", callback_data="photo_image:dalle")
            ],
            [
                InlineKeyboardButton(text="â—€ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="ðŸ–¼ **Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:**\n\n"
                    "â€¢ **Nano Banana** - Gemini 2.5 Flash, image-to-image (~3,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)\n"
                    "â€¢ **DALL-E** - Image variation (~2,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "vision":
        # Move photo to vision state and start analysis
        if saved_photo_path:
            # Actually process vision directly
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    # Default prompt for analysis
                    prompt = "Provide a detailed analysis of this image. Describe what you see, including objects, people, scenery, colors, composition, and any notable details."
                    await _process_vision_with_path(callback.message, state, user, saved_photo_path, prompt)
                else:
                    await callback.message.edit_caption("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
                    await state.clear()
        else:
            await callback.answer("âŒ Ð¤Ð¾Ñ‚Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.", show_alert=True)
            await state.clear()

    elif action == "tools":
        # Show photo tools
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="ðŸš« Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ñ„Ð¾Ð½", callback_data="photo_tool:remove_bg")
            ],
            [
                InlineKeyboardButton(text="â—€ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="photo_action:back")
            ]
        ])

        await callback.message.edit_caption(
            caption="ðŸŽ¨ **Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸:**\n\n"
                    "â€¢ **Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ñ„Ð¾Ð½** - Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¹ Ñ„Ð¾Ð½ (~1,000 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)",
            reply_markup=keyboard
        )
        await callback.answer()

    elif action == "back":
        # Go back to main choice - resend the photo with choices
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="ðŸŽ¬ Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾", callback_data="photo_action:video"),
                InlineKeyboardButton(text="ðŸ–¼ Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", callback_data="photo_action:image")
            ],
            [
                InlineKeyboardButton(text="ðŸ‘ ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾", callback_data="photo_action:vision"),
                InlineKeyboardButton(text="ðŸŽ¨ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð¾Ñ‚Ð¾", callback_data="photo_action:tools")
            ],
            [
                InlineKeyboardButton(text="âŒ ÐžÑ‚Ð¼ÐµÐ½Ð°", callback_data="photo_action:cancel")
            ]
        ])

        await callback.message.edit_caption(
            caption="ðŸ“¸ **Ð¤Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾!**\n\n"
                    "Ð§Ñ‚Ð¾ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ñ ÑÑ‚Ð¸Ð¼ Ñ„Ð¾Ñ‚Ð¾?\n\n"
                    "ðŸŽ¬ **Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾** - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ„Ð¾Ñ‚Ð¾\n"
                    "ðŸ–¼ **Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ** - Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ñ„Ð¾Ñ‚Ð¾ Ð² Ð½Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\n"
                    "ðŸ‘ **ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾** - Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð³Ð¾\n"
                    "ðŸŽ¨ **ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð¾Ñ‚Ð¾** - ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð½Ð°, ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð¸ Ñ‚.Ð´.",
            reply_markup=keyboard
        )
        await callback.answer()


@router.callback_query(F.data.startswith("photo_video:"))
async def handle_photo_video_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle video model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Move photo to image_path for video generation
    await state.update_data(image_path=saved_photo_path, service=model)
    await state.set_state(MediaState.waiting_for_video_prompt)

    model_names = {
        "veo": "Veo 3.1",
        "luma": "Luma Dream Machine",
        "kling": "Kling AI"
    }

    await callback.message.edit_caption(
        caption=f"âœ… Ð¤Ð¾Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾!\n\n"
                f"ðŸŽ¬ **{model_names.get(model, model)}**\n\n"
                f"ðŸ“ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾.\n\n"
                f"**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n"
                f"â€¢ \"ÐžÐ¶Ð¸Ð²Ð¸ ÑÑ‚Ð¾ Ñ„Ð¾Ñ‚Ð¾, Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð¿Ð»Ð°Ð²Ð½Ð¾Ðµ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ\"\n"
                f"â€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ‚Ð°Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð¾Ð»Ð¾ÑÑ‹ Ñ€Ð°Ð·Ð²ÐµÐ²Ð°Ð»Ð¸ÑÑŒ Ð½Ð° Ð²ÐµÑ‚Ñ€Ñƒ\"\n"
                f"â€¢ \"Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¿Ð°Ð´Ð°ÑŽÑ‰Ð¸Ðµ ÑÐ½ÐµÐ¶Ð¸Ð½ÐºÐ¸ Ð¸ Ð¿Ð»Ð°Ð²Ð½Ð¾Ðµ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ð¼ÐµÑ€Ñ‹\""
    )
    await callback.answer()


@router.callback_query(F.data.startswith("photo_image:"))
async def handle_photo_image_model_choice(callback: CallbackQuery, state: FSMContext):
    """Handle image model choice after photo upload."""
    model = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    # Map service names
    service_map = {
        "nano": "nano_banana",
        "dalle": "dalle"
    }

    # Move photo to reference_image_path for image generation
    await state.update_data(reference_image_path=saved_photo_path, service=service_map.get(model, model))
    await state.set_state(MediaState.waiting_for_image_prompt)

    model_names = {
        "nano": "Nano Banana",
        "dalle": "DALL-E"
    }

    examples = {
        "nano": "â€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð² ÑÑ‚Ð¸Ð»Ðµ Ð°Ð½Ð¸Ð¼Ðµ\"\nâ€¢ \"ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐ¹ Ð² Ð°ÐºÐ²Ð°Ñ€ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð¸ÑÑƒÐ½Ð¾Ðº\"\nâ€¢ \"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ„Ð¾Ð½ ÐºÐ¾ÑÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼\"",
        "dalle": "â€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð»ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸"
    }

    await callback.message.edit_caption(
        caption=f"âœ… Ð¤Ð¾Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾!\n\n"
                f"ðŸ–¼ **{model_names.get(model, model)}**\n\n"
                f"ðŸ“ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾.\n\n"
                f"**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n{examples.get(model, '')}"
    )
    await callback.answer()


@router.callback_query(F.data.startswith("photo_tool:"))
async def handle_photo_tool_choice(callback: CallbackQuery, state: FSMContext):
    """Handle photo tool choice."""
    tool = callback.data.split(":")[1]

    data = await state.get_data()
    saved_photo_path = data.get("saved_photo_path")

    if tool == "remove_bg":
        # Trigger processing with saved photo
        if saved_photo_path and os.path.exists(saved_photo_path):
            from app.database.models.user import User
            async with async_session_maker() as session:
                from sqlalchemy import select
                result = await session.execute(select(User).where(User.telegram_id == callback.from_user.id))
                user = result.scalar_one_or_none()

                if user:
                    await _process_remove_bg_with_path(callback.message, state, user, saved_photo_path)
                else:
                    await callback.message.edit_caption("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
                    await state.clear()
        else:
            await callback.answer("âŒ Ð¤Ð¾Ñ‚Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾", show_alert=True)
            await state.clear()

    await callback.answer()


async def _process_remove_bg_with_path(message: Message, state: FSMContext, user: User, image_path: str):
    """Process background removal with given path."""
    estimated_tokens = 1000

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð°!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            await state.clear()
            return

    progress_msg = await message.answer("ðŸš« Ð£Ð´Ð°Ð»ÑÑŽ Ñ„Ð¾Ð½...")

    async def update_progress(text: str):
        try:
            await progress_msg.edit_text(text, parse_mode=None)
        except Exception:
            pass

    removebg_service = RemoveBgService()
    result = await removebg_service.process_image(
        image_path=image_path,
        progress_callback=update_progress,
        size="auto",
        type="auto"
    )

    # Clean up temp file
    try:
        os.remove(image_path)
    except Exception:
        pass

    if result.success:
        result_file = FSInputFile(result.image_path)

        try:
            await message.answer_photo(
                photo=result_file,
                caption=f"âœ… Ð¤Ð¾Ð½ ÑƒÐ´Ð°Ð»Ñ‘Ð½!\n\nÐ˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
            )
        except Exception:
            await message.answer_document(
                document=result_file,
                caption=f"âœ… Ð¤Ð¾Ð½ ÑƒÐ´Ð°Ð»Ñ‘Ð½!\n\nÐ˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ Ñ„Ð¾Ð½Ð¾Ð¼ (PNG).\n\nÐ˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {estimated_tokens:,}"
            )

        try:
            os.remove(result.image_path)
        except Exception:
            pass

        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð°:\n{result.error}")

    await state.clear()


async def _process_vision_with_path(message: Message, state: FSMContext, user: User, image_path: str, prompt: str):
    """Process vision analysis with given path."""
    estimated_tokens = 1500

    async with async_session_maker() as session:
        sub_service = SubscriptionService(session)

        try:
            await sub_service.check_and_use_tokens(user.id, estimated_tokens)
        except InsufficientTokensError as e:
            await message.answer(
                f"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²!\n\n"
                f"Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ: {estimated_tokens:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
                f"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾: {e.details['available']:,} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n\n"
                f"ÐšÑƒÐ¿Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ: /start â†’ ðŸ’Ž ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
            )
            try:
                os.remove(image_path)
            except Exception:
                pass
            await state.clear()
            return

    progress_msg = await message.answer("ðŸ‘ ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...")

    vision_service = VisionService()
    result = await vision_service.analyze_image(
        image_path=image_path,
        prompt=prompt,
        model="gpt-4o",
        max_tokens=1500,
        detail="high"
    )

    # Clean up temp file
    try:
        os.remove(image_path)
    except Exception:
        pass

    if result.success:
        await message.answer(
            f"âœ… **ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð³Ð¾Ñ‚Ð¾Ð²!**\n\n"
            f"{result.content}\n\n"
            f"ðŸ’° Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {result.tokens_used:,}"
        )
        await progress_msg.delete()
    else:
        await progress_msg.edit_text(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:\n{result.error}")

    await state.clear()
